<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>NoKV Docs</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon-de23e50b.svg">
        <link rel="shortcut icon" href="favicon-8114d1fc.png">
        <link rel="stylesheet" href="css/variables-8adf115d.css">
        <link rel="stylesheet" href="css/general-2459343d.css">
        <link rel="stylesheet" href="css/chrome-ae938929.css">
        <link rel="stylesheet" href="css/print-9e4910d8.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="fonts/fonts-9644e21d.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="mdbook-highlight-css" href="highlight-493f70e1.css">
        <link rel="stylesheet" id="mdbook-tomorrow-night-css" href="tomorrow-night-4c0ae647.css">
        <link rel="stylesheet" id="mdbook-ayu-highlight-css" href="ayu-highlight-3fdfc3ac.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="docs/custom-7218a61a.css">


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex-e13d5ae5.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc-982873a5.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>â†</kbd> or <kbd>â†’</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="mdbook-body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="mdbook-sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("mdbook-sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="mdbook-sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="mdbook-sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="mdbook-page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="mdbook-menu-bar-hover-placeholder"></div>
                <div id="mdbook-menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="mdbook-sidebar-toggle" class="icon-button" for="mdbook-sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="mdbook-sidebar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"/></svg></span>
                        </label>
                        <button id="mdbook-theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="mdbook-theme-list">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M371.3 367.1c27.3-3.9 51.9-19.4 67.2-42.9L600.2 74.1c12.6-19.5 9.4-45.3-7.6-61.2S549.7-4.4 531.1 9.6L294.4 187.2c-24 18-38.2 46.1-38.4 76.1L371.3 367.1zm-19.6 25.4l-116-104.4C175.9 290.3 128 339.6 128 400c0 3.9 .2 7.8 .6 11.6c1.8 17.5-10.2 36.4-27.8 36.4H96c-17.7 0-32 14.3-32 32s14.3 32 32 32H240c61.9 0 112-50.1 112-112c0-2.5-.1-5-.2-7.5z"/></svg></span>
                        </button>
                        <ul id="mdbook-theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-ayu">Ayu</button></li>
                        </ul>
                        <button id="mdbook-search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="mdbook-searchbar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352c79.5 0 144-64.5 144-144s-64.5-144-144-144S64 128.5 64 208s64.5 144 144 144z"/></svg></span>
                        </button>
                    </div>

                    <h1 class="menu-title">NoKV Docs</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <span class=fa-svg id="print-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M128 0C92.7 0 64 28.7 64 64v96h64V64H354.7L384 93.3V160h64V93.3c0-17-6.7-33.3-18.7-45.3L400 18.7C388 6.7 371.7 0 354.7 0H128zM384 352v32 64H128V384 368 352H384zm64 32h32c17.7 0 32-14.3 32-32V256c0-35.3-28.7-64-64-64H64c-35.3 0-64 28.7-64 64v96c0 17.7 14.3 32 32 32H64v64c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V384zm-16-88c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg></span>
                        </a>
                        <a href="https://github.com/feichai0017/NoKV" title="Git repository" aria-label="Git repository">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span>
                        </a>

                    </div>
                </div>

                <div id="mdbook-search-wrapper" class="hidden">
                    <form id="mdbook-searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="mdbook-searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="mdbook-searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <span class=fa-svg id="fa-spin"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M304 48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zm0 416c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM48 304c26.5 0 48-21.5 48-48s-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48zm464-48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM142.9 437c18.7-18.7 18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zm0-294.2c18.7-18.7 18.7-49.1 0-67.9S93.7 56.2 75 75s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zM369.1 437c18.7 18.7 49.1 18.7 67.9 0s18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9z"/></svg></span>
                            </div>
                        </div>
                    </form>
                    <div id="mdbook-searchresults-outer" class="searchresults-outer hidden">
                        <div id="mdbook-searchresults-header" class="searchresults-header"></div>
                        <ul id="mdbook-searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('mdbook-sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('mdbook-sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#mdbook-sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="mdbook-content" class="content">
                    <main>
                        <h1 id="overview"><a class="header" href="#overview">Overview</a></h1>
<div align="center">
  <img src="https://raw.githubusercontent.com/feichai0017/NoKV/main/img/logo.svg" width="180" alt="NoKV Logo">
  
<h1>NoKV</h1>

  
<p style="font-size: 1.2em; color: #666;">
    <strong>High-Performance, Cloud-Native Distributed Key-Value Database</strong>
  </p>

  
<p>
    <!-- Build / Quality -->
    <a href="https://github.com/feichai0017/NoKV/actions">
      <img alt="CI" src="https://img.shields.io/github/actions/workflow/status/feichai0017/NoKV/go.yml?branch=main" />
    </a>
    <a href="https://codecov.io/gh/feichai0017/NoKV">
      <img alt="Coverage" src="https://img.shields.io/codecov/c/gh/feichai0017/NoKV" />
    </a>
    <a href="https://goreportcard.com/report/github.com/feichai0017/NoKV">
      <img alt="Go Report Card" src="https://img.shields.io/badge/go%20report-A+-brightgreen" />
    </a>
    <a href="https://pkg.go.dev/github.com/feichai0017/NoKV">
      <img alt="Go Reference" src="https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&amp;logoColor=white" />
    </a>
    <a href="https://github.com/avelino/awesome-go#databases-implemented-in-go">
      <img alt="Mentioned in Awesome" src="https://awesome.re/mentioned-badge.svg" />
    </a>
  </p>

  
<p>
    <!-- Meta -->
    <img alt="Go Version" src="https://img.shields.io/badge/go-1.26%2B-00ADD8?logo=go&amp;logoColor=white" />
    <img alt="License" src="https://img.shields.io/badge/license-Apache--2.0-yellow" />
    <a href="https://deepwiki.com/feichai0017/NoKV">
      <img alt="DeepWiki" src="https://img.shields.io/badge/DeepWiki-Ask-6f42c1" />
    </a>
  </p>

  
<p>
    <a href="#getting-started" style="text-decoration: none;">
      <button style="background-color: #007bff; color: white; border: none; padding: 10px 20px; border-radius: 5px; cursor: pointer; font-size: 1em;">ğŸš€ Quick Start</button>
    </a>
    Â Â 
    <a href="#nokv-architecture-overview" style="text-decoration: none;">
      <button style="background-color: #6c757d; color: white; border: none; padding: 10px 20px; border-radius: 5px; cursor: pointer; font-size: 1em;">ğŸ—ï¸ Architecture</button>
    </a>
  </p>

</div>

<br>
<hr>
<h2 id="-why-nokv"><a class="header" href="#-why-nokv">ğŸ”¥ Why NoKV?</a></h2>
<p>NoKV is designed for <strong>modern hardware</strong> and <strong>distributed workloads</strong>. It combines the best of academic research (WiscKey, W-TinyLFU) with industrial-grade engineering (Raft, Percolator).</p>
<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; margin-top: 20px;">
  
<div style="border: 1px solid #e1e4e8; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); background-color: var(--bg);">
    
<h3 style="margin-top: 0;">ğŸï¸ Extreme Performance</h3>

    
<p><strong>Lock-light</strong> commit queue and <strong>Batch WAL</strong> writing deliver write throughput that saturates NVMe SSDs.</p>

  </div>

  
<div style="border: 1px solid #e1e4e8; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); background-color: var(--bg);">
    
<h3 style="margin-top: 0;">ğŸ§  Smart Caching</h3>

    
<p>Built-in <strong>W-TinyLFU</strong> Block Cache (via Ristretto) and <strong>HotRing</strong> implementation ensure 99% cache hit rates and adapt to skew access patterns.</p>

  </div>

  
<div style="border: 1px solid #e1e4e8; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); background-color: var(--bg);">
    
<h3 style="margin-top: 0;">ğŸŒ Distributed Consistency</h3>

    
<p><strong>Multi-Raft</strong> replication for high availability. <strong>Percolator</strong> model for cross-row ACID transactions. Snapshot Isolation by default.</p>

  </div>

  
<div style="border: 1px solid #e1e4e8; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); background-color: var(--bg);">
    
<h3 style="margin-top: 0;">ğŸ”Œ Redis Compatible</h3>

    
<p>Drop-in replacement for Redis. Supports the <strong>RESP protocol</strong> so you can use your existing tools and client libraries.</p>

  </div>

</div>

<br>
<h2 id="-performance-benchmark"><a class="header" href="#-performance-benchmark">ğŸ“Š Performance Benchmark</a></h2>
<p>NoKV outperforms BadgerDB significantly in read-heavy and mixed workloads.</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th style="text-align: left">Workload</th><th style="text-align: left">Operation</th><th style="text-align: left">NoKV (OPS)</th><th style="text-align: left">Badger (OPS)</th><th style="text-align: left">Improvement</th></tr>
</thead>
<tbody>
<tr><td style="text-align: left"><strong>YCSB-C</strong></td><td style="text-align: left">100% Read</td><td style="text-align: left"><strong>1,540,744</strong></td><td style="text-align: left">521,586</td><td style="text-align: left"><span style="color:green"><strong>+195%</strong></span> ğŸš€</td></tr>
<tr><td style="text-align: left"><strong>YCSB-B</strong></td><td style="text-align: left">95% Read</td><td style="text-align: left"><strong>911,199</strong></td><td style="text-align: left">349,608</td><td style="text-align: left"><span style="color:green"><strong>+160%</strong></span></td></tr>
<tr><td style="text-align: left"><strong>YCSB-A</strong></td><td style="text-align: left">50% Update</td><td style="text-align: left"><strong>410,578</strong></td><td style="text-align: left">262,153</td><td style="text-align: left"><span style="color:green"><strong>+56%</strong></span></td></tr>
<tr><td style="text-align: left"><strong>YCSB-D</strong></td><td style="text-align: left">5% Insert</td><td style="text-align: left"><strong>1,270,717</strong></td><td style="text-align: left">707,607</td><td style="text-align: left"><span style="color:green"><strong>+79%</strong></span></td></tr>
</tbody>
</table>
</div>
<details>
<summary><em>Click to view detailed latency stats</em></summary>
<pre><code class="language-text">Summary:
ENGINE  OPERATION  MODE                          OPS/S    AVG LATENCY  P99
NoKV    YCSB-C     100% read                     1540744  649ns        128Âµs
NoKV    YCSB-A     50/50 read/update             410578   2.435Âµs      155Âµs
Badger  YCSB-C     100% read                     521586   1.917Âµs      427Âµs
Badger  YCSB-A     50/50 read/update             262153   3.814Âµs      160Âµs
</code></pre>
</details>
<br>
<h2 id="-architecture"><a class="header" href="#-architecture">ğŸ—ï¸ Architecture</a></h2>
<pre class="mermaid">graph TD
    Client["Client / Redis"] --&gt;|RESP Protocol| Gateway["Redis Gateway"]
    Gateway --&gt;|RaftCmd| RaftStore
    
    subgraph "RaftStore (Distributed Layer)"
        RaftStore --&gt;|Propose| RaftLog["Raft Log (WAL)"]
        RaftLog --&gt;|Consensus| Apply["Apply Worker"]
    end
    
    subgraph "Storage Engine (LSM)"
        Apply --&gt;|Batch Set| MemTable
        MemTable --&gt;|Flush| SSTable["SSTables (L0-L6)"]
        SSTable --&gt;|Compact| SSTable
        
        Apply --&gt;|Large Value| VLog["Value Log"]
    end
    
    subgraph "Cache Layer"
        BlockCache["Block Cache (Ristretto)"] -.-&gt; SSTable
        IndexCache["Index Cache (W-TinyLFU)"] -.-&gt; SSTable
    end
</pre>

<h2 id="-roadmap"><a class="header" href="#-roadmap">ğŸ—ºï¸ Roadmap</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""> <strong>Core</strong>: LSM Tree, VLog, WAL</li>
<li><input disabled="" type="checkbox" checked=""> <strong>Distributed</strong>: Multi-Raft, Split/Merge</li>
<li><input disabled="" type="checkbox" checked=""> <strong>Transaction</strong>: Percolator (Snapshot Isolation)</li>
<li><input disabled="" type="checkbox"> <strong>Optimization</strong>: Async Apply, SSTable-based Snapshot</li>
<li><input disabled="" type="checkbox"> <strong>Redis</strong>: Hash/Set/ZSet support</li>
</ul>
<h2 id="-contributing"><a class="header" href="#-contributing">ğŸ¤ Contributing</a></h2>
<p>We welcome contributions! Please see <a href="CONTRIBUTING.html">CONTRIBUTING.md</a> for details.</p>
<div align="center">
  <sub>Built with â¤ï¸ by <a href="https://github.com/feichai0017">feichai0017</a> and contributors.</sub>
</div>

<div style="break-before: page; page-break-before: always;"></div>
<h1 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h1>
<p>This guide gets you from zero to a running NoKV cluster (or an embedded DB) in a few minutes.</p>
<h2 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h2>
<ul>
<li>Go 1.26+</li>
<li>Git</li>
<li>(Optional) Docker + Docker Compose for containerized runs</li>
</ul>
<h2 id="option-a-local-cluster-recommended-for-dev"><a class="header" href="#option-a-local-cluster-recommended-for-dev">Option A: Local Cluster (recommended for dev)</a></h2>
<p>This launches a 3-node Raft cluster plus the optional TSO helper.</p>
<pre><code class="language-bash">./scripts/run_local_cluster.sh --config ./raft_config.example.json
</code></pre>
<p>Start the Redis-compatible gateway in another shell:</p>
<pre><code class="language-bash">go run ./cmd/nokv-redis --addr 127.0.0.1:6380 --raft-config raft_config.example.json
</code></pre>
<p>Quick smoke test:</p>
<pre><code class="language-bash">redis-cli -p 6380 ping
</code></pre>
<h3 id="inspect-stats"><a class="header" href="#inspect-stats">Inspect stats</a></h3>
<pre><code class="language-bash">go run ./cmd/nokv stats --workdir ./artifacts/cluster/store-1
</code></pre>
<h2 id="option-b-docker-compose"><a class="header" href="#option-b-docker-compose">Option B: Docker Compose</a></h2>
<p>This runs the cluster and gateway in containers.</p>
<pre><code class="language-bash">docker compose up --build
</code></pre>
<p>Tear down:</p>
<pre><code class="language-bash">docker compose down -v
</code></pre>
<h2 id="embedded-usage-single-process"><a class="header" href="#embedded-usage-single-process">Embedded Usage (single-process)</a></h2>
<p>Use NoKV as a library when you do not need raftstore.</p>
<pre><code class="language-go">package main

import (
	"fmt"
	"log"

	NoKV "github.com/feichai0017/NoKV"
)

func main() {
	opt := NoKV.NewDefaultOptions()
	opt.WorkDir = "./workdir-demo"

	db := NoKV.Open(opt)
	defer db.Close()

	key := []byte("hello")
	if err := db.Set(key, []byte("world")); err != nil {
		log.Fatalf("set failed: %v", err)
	}

	entry, err := db.Get(key)
	if err != nil {
		log.Fatalf("get failed: %v", err)
	}
	fmt.Printf("value=%s\n", entry.Value)
}
</code></pre>
<blockquote>
<p>Note: Public read APIs (<code>DB.Get</code>, <code>DB.GetCF</code>, <code>DB.GetVersionedEntry</code>, <code>Txn.Get</code>) return detached entries and do not require <code>DecrRef</code>.</p>
</blockquote>
<h2 id="benchmarks"><a class="header" href="#benchmarks">Benchmarks</a></h2>
<p>Micro benchmarks:</p>
<pre><code class="language-bash">go test -bench=. -run=^$ ./...
</code></pre>
<p>YCSB (NoKV engine only by default):</p>
<pre><code class="language-bash">make bench
</code></pre>
<p>Override defaults with env vars:</p>
<pre><code class="language-bash">YCSB_RECORDS=1000000 YCSB_OPS=1000000 YCSB_CONC=8 make bench
</code></pre>
<h2 id="cleanup"><a class="header" href="#cleanup">Cleanup</a></h2>
<p>If a local run crashes or you want a clean slate:</p>
<pre><code class="language-bash">make clean
</code></pre>
<h2 id="troubleshooting"><a class="header" href="#troubleshooting">Troubleshooting</a></h2>
<ul>
<li><strong>WAL replay errors after crash</strong>: wipe the workdir and restart the cluster.</li>
<li><strong>Port conflicts</strong>: adjust addresses in <code>raft_config.example.json</code>.</li>
<li><strong>Slow startup</strong>: reduce <code>YCSB_RECORDS</code> or <code>YCSB_OPS</code> when benchmarking locally.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="nokv-architecture-overview"><a class="header" href="#nokv-architecture-overview">NoKV Architecture Overview</a></h1>
<p>NoKV delivers a hybrid storage engine that can operate as a standalone embedded KV store or as a TinyKv-compatible distributed service. This document captures the key building blocks, how they interact, and the execution flow from client to disk.</p>
<hr>
<h2 id="1-high-level-layout"><a class="header" href="#1-high-level-layout">1. High-Level Layout</a></h2>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   TinyKv gRPC   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ raftstore Service       â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚ raftstore/client        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚  (Get / Scan / Mutate)  â”‚
            â”‚                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ ReadCommand / ProposeCommand
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ store.Store / peer.Peer â”‚  â† multi-Raft region lifecycle
â”‚  â”œ Manifest snapshot    â”‚
â”‚  â”œ Router / RegionHooks â”‚
â”‚  â”” transport (gRPC)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ Apply via kv.Apply
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ kv.Apply + percolator   â”‚
â”‚  â”œ Get / Scan           â”‚
â”‚  â”œ Prewrite / Commit    â”‚
â”‚  â”” Latch manager        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Embedded NoKV core      â”‚
â”‚  â”œ WAL Manager          â”‚
â”‚  â”œ MemTable / Flush     â”‚
â”‚  â”œ ValueLog + GC        â”‚
â”‚  â”” Manifest / Stats     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<ul>
<li><strong>Embedded mode</strong> uses <code>NoKV.Open</code> directly: WALâ†’MemTableâ†’SST durability, ValueLog separation, MVCC semantics, rich stats.</li>
<li><strong>Distributed mode</strong> layers <code>raftstore</code> on top: multi-Raft regions reuse the same WAL/Manifest, expose metrics, and serve TinyKv RPCs.</li>
<li><strong>Clients</strong> obtain leader-aware routing, automatic NotLeader/EpochNotMatch retries, and two-phase commit helpers.</li>
</ul>
<hr>
<h2 id="2-embedded-engine"><a class="header" href="#2-embedded-engine">2. Embedded Engine</a></h2>
<h3 id="21-wal--memtable"><a class="header" href="#21-wal--memtable">2.1 WAL &amp; MemTable</a></h3>
<ul>
<li><code>wal.Manager</code> appends <code>[len|type|payload|crc]</code> records (typed WAL), rotates segments, and replays logs on crash.</li>
<li><code>MemTable</code> accumulates writes until full, then enters the flush queue; <code>flush.Manager</code> runs <code>Prepare â†’ Build â†’ Install â†’ Release</code>, logs edits, and releases WAL segments.</li>
<li>Writes are handled by a single commit worker that performs value-log append first, then WAL/memtable apply, keeping durability ordering simple and consistent.</li>
</ul>
<h3 id="22-valuelog"><a class="header" href="#22-valuelog">2.2 ValueLog</a></h3>
<ul>
<li>Large values are written to the ValueLog before the WAL append; the resulting <code>ValuePtr</code> is stored in WAL/LSM so replay can recover.</li>
<li><code>vlog.Manager</code> tracks the active head and uses flush discard stats to trigger GC; manifest records new heads and removed segments.</li>
</ul>
<h3 id="23-manifest"><a class="header" href="#23-manifest">2.3 Manifest</a></h3>
<ul>
<li><code>manifest.Manager</code> stores SST metadata, WAL checkpoints, ValueLog metadata, and (importantly) Region descriptors used by raftstore.</li>
<li><code>CURRENT</code> provides crash-safe pointer updates; Region state is replicated through manifest edits.</li>
</ul>
<h3 id="24-lsm-compaction--ingest-buffer"><a class="header" href="#24-lsm-compaction--ingest-buffer">2.4 LSM Compaction &amp; Ingest Buffer</a></h3>
<ul>
<li><code>compact.Manager</code> drives compaction cycles; <code>lsm.levelManager</code> supplies table metadata and executes the plan.</li>
<li>Planning is split: <code>compact.PlanFor*</code> selects table IDs + key ranges, then LSM resolves IDs back to tables and runs the merge.</li>
<li><code>compact.State</code> guards overlapping key ranges and tracks in-flight table IDs.</li>
<li>Ingest shard selection is policy-driven in <code>compact</code> (<code>PickShardOrder</code> / <code>PickShardByBacklog</code>) while the ingest buffer remains in <code>lsm</code>.</li>
</ul>
<pre class="mermaid">flowchart TD
  Manager["compact.Manager"] --&gt; LSM["lsm.levelManager"]
  LSM --&gt;|TableMeta snapshot| Planner["compact.PlanFor*"]
  Planner --&gt; Plan["compact.Plan (fid+range)"]
  Plan --&gt;|resolvePlanLocked| Exec["LSM executor"]
  Exec --&gt; State["compact.State guard"]
  Exec --&gt; Build["subcompact/build SST"]
  Build --&gt; Manifest["manifest edits"]
  L0["L0 tables"] --&gt;|moveToIngest| Ingest["ingest buffer shards"]
  Ingest --&gt;|IngestDrain: ingest-only| Main["Main tables"]
  Ingest --&gt;|IngestKeep: ingest-merge| Ingest
</pre>

<h3 id="25-mvcc"><a class="header" href="#25-mvcc">2.5 MVCC</a></h3>
<ul>
<li><code>txn.go</code> exposes MVCC transactions with timestamps from <code>oracle</code>.</li>
<li><code>percolator</code> package implements Prewrite/Commit/ResolveLock/CheckTxnStatus; <code>kv.Apply</code> simply dispatches Raft commands to these helpers.</li>
<li>Watermarks (<code>utils.WaterMark</code>) gate read snapshots and commit visibility. They have no background goroutine; waiters block on per-index channels while advancement uses a mutex + atomics.</li>
</ul>
<h3 id="26-write-pipeline--backpressure"><a class="header" href="#26-write-pipeline--backpressure">2.6 Write Pipeline &amp; Backpressure</a></h3>
<ul>
<li>Writes enqueue into a commit queue (<code>db_write.go</code>) where requests are coalesced into batches before a commit worker drains them.</li>
<li>The commit worker always writes the value log first (when needed), then applies WAL/LSM updates; <code>SyncWrites</code> adds a WAL fsync step.</li>
<li>Batch sizing adapts to backlog (<code>WriteBatchMaxCount/Size</code>, <code>WriteBatchWait</code>) and hot-key pressure can expand batch limits temporarily to drain spikes.</li>
<li>Backpressure is enforced in two places: LSM throttling toggles <code>db.blockWrites</code> when L0 backlog grows, and HotRing can reject hot keys via <code>WriteHotKeyLimit</code>.</li>
</ul>
<hr>
<h2 id="3-replication-layer-raftstore"><a class="header" href="#3-replication-layer-raftstore">3. Replication Layer (raftstore)</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Package</th><th>Responsibility</th></tr>
</thead>
<tbody>
<tr><td><a href="../raftstore/store"><code>store</code></a></td><td>Region catalog, router, RegionMetrics, Region hooks, manifest integration, helpers such as <code>StartPeer</code> / <code>SplitRegion</code>.</td></tr>
<tr><td><a href="../raftstore/peer"><code>peer</code></a></td><td>Wraps etcd/raft <code>RawNode</code>, handles Ready pipeline, snapshot resend queue, backlog instrumentation.</td></tr>
<tr><td><a href="../raftstore/engine"><code>engine</code></a></td><td>WALStorage/DiskStorage/MemoryStorage, reusing the DBâ€™s WAL while keeping manifest metadata in sync.</td></tr>
<tr><td><a href="../raftstore/transport"><code>transport</code></a></td><td>gRPC transport for Raft Step messages, connection management, retries/blocks/TLS. Also acts as the host for TinyKv RPC.</td></tr>
<tr><td><a href="../raftstore/kv"><code>kv</code></a></td><td>TinyKv RPC handler plus <code>kv.Apply</code> bridging Raft commands to MVCC logic.</td></tr>
<tr><td><a href="../raftstore/server"><code>server</code></a></td><td><code>ServerConfig</code> + <code>New</code> combine DB, Store, transport, and TinyKv service into a reusable node instance.</td></tr>
</tbody>
</table>
</div>
<h3 id="31-bootstrap-sequence"><a class="header" href="#31-bootstrap-sequence">3.1 Bootstrap Sequence</a></h3>
<ol>
<li><code>raftstore.NewServer</code> wires DB, store configuration (StoreID, hooks, scheduler), Raft config, and transport address. It registers TinyKv RPC on the shared gRPC server and sets <code>transport.SetHandler(store.Step)</code>.</li>
<li>CLI (<code>nokv serve</code>) or application enumerates <code>Manifest.RegionSnapshot()</code> and calls <code>Store.StartPeer</code> for every Region containing the local store:
<ul>
<li><code>peer.Config</code> includes Raft params, transport, <code>kv.NewEntryApplier</code>, WAL/Manifest handles, Region metadata.</li>
<li>Router registration, regionManager bookkeeping, optional <code>Peer.Bootstrap</code> with initial peer list, leader campaign.</li>
</ul>
</li>
<li>Peers from other stores can be configured through <code>transport.SetPeer(storeID, addr)</code>, allowing dynamic updates from a scheduler.</li>
</ol>
<h3 id="32-command-paths"><a class="header" href="#32-command-paths">3.2 Command Paths</a></h3>
<ul>
<li><strong>ReadCommand</strong> (<code>KvGet</code>/<code>KvScan</code>): validate Region &amp; leader, flush pending Ready, then run <code>commandApplier</code> (i.e. <code>kv.Apply</code> in read mode) to fetch data directly from the DB. This yields leader-strong reads without a Raft round trip.</li>
<li><strong>ProposeCommand</strong> (write): encode the request, push through Router to the leader peer, replicate via Raft, and apply in <code>kv.Apply</code> which maps to MVCC operations.</li>
</ul>
<h3 id="33-transport"><a class="header" href="#33-transport">3.3 Transport</a></h3>
<ul>
<li>gRPC server handles Step RPCs and TinyKv RPCs on the same endpoint; peers are registered via <code>SetPeer</code>.</li>
<li>Retry policies (<code>WithRetry</code>) and TLS credentials are configurable. Tests cover partitions, blocked peers, and slow followers.</li>
</ul>
<hr>
<h2 id="4-tinykv-service"><a class="header" href="#4-tinykv-service">4. TinyKv Service</a></h2>
<p><code>raftstore/kv/service.go</code> exposes pb.TinyKv RPCs:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>RPC</th><th>Execution</th><th>Result</th></tr>
</thead>
<tbody>
<tr><td><code>KvGet</code></td><td><code>store.ReadCommand</code> â†’ <code>kv.Apply</code> GET</td><td><code>pb.GetResponse</code> / <code>RegionError</code></td></tr>
<tr><td><code>KvScan</code></td><td><code>store.ReadCommand</code> â†’ <code>kv.Apply</code> SCAN</td><td><code>pb.ScanResponse</code> / <code>RegionError</code></td></tr>
<tr><td><code>KvPrewrite</code></td><td><code>store.ProposeCommand</code> â†’ <code>percolator.Prewrite</code></td><td><code>pb.PrewriteResponse</code></td></tr>
<tr><td><code>KvCommit</code></td><td><code>store.ProposeCommand</code> â†’ <code>percolator.Commit</code></td><td><code>pb.CommitResponse</code></td></tr>
<tr><td><code>KvResolveLock</code></td><td><code>percolator.ResolveLock</code></td><td><code>pb.ResolveLockResponse</code></td></tr>
<tr><td><code>KvCheckTxnStatus</code></td><td><code>percolator.CheckTxnStatus</code></td><td><code>pb.CheckTxnStatusResponse</code></td></tr>
</tbody>
</table>
</div>
<p><code>nokv serve</code> is the CLI entry pointâ€”open the DB, construct <code>raftstore.Server</code>, register peers, start local Raft peers, and display a manifest summary (Regions, key ranges, peers). <code>scripts/run_local_cluster.sh</code> builds the CLI, writes a minimal region manifest, launches multiple <code>nokv serve</code> processes on localhost, and handles cleanup on Ctrl+C.</p>
<hr>
<h2 id="5-client-workflow"><a class="header" href="#5-client-workflow">5. Client Workflow</a></h2>
<p><code>raftstore/client</code> offers a leader-aware client with retry logic and convenient helpers:</p>
<ul>
<li><strong>Initialization</strong>: provide <code>[]StoreEndpoint</code> + <code>[]RegionConfig</code> describing region boundaries and known leaders.</li>
<li><strong>Reads</strong>: <code>Get</code> and <code>Scan</code> pick the leader store for a key range, issue TinyKv RPCs, and retry on NotLeader/EpochNotMatch.</li>
<li><strong>Writes</strong>: <code>Mutate</code> bundles operations per region and drives Prewrite/Commit (primary first, secondaries after); <code>Put</code> and <code>Delete</code> are convenience wrappers using the same 2PC path.</li>
<li><strong>Timestamps</strong>: clients must supply <code>startVersion</code>/<code>commitVersion</code>. For distributed demos, reuse the TSO sample under <code>scripts/tso</code> to obtain globally increasing values before calling <code>TwoPhaseCommit</code>.</li>
<li><strong>Bootstrap helpers</strong>: <code>scripts/run_local_cluster.sh --config raft_config.example.json</code> builds the binaries, seeds manifests via <code>nokv-config manifest</code>, launches the stores declared in the config, and starts the HTTP TSO allocator when the <code>tso</code> block is present.</li>
</ul>
<p><strong>Example (two regions)</strong></p>
<ol>
<li>Regions <code>[a,m)</code> and <code>[m,+âˆ)</code>, each led by a different store.</li>
<li><code>Mutate(ctx, primary="alfa", mutations, startTs, commitTs, ttl)</code> prewrites and commits across the relevant regions.</li>
<li><code>Get/Scan</code> retries automatically if the leader changes.</li>
<li>See <code>raftstore/server/server_client_integration_test.go</code> for a full end-to-end example using real <code>raftstore.Server</code> instances.</li>
</ol>
<hr>
<h2 id="6-failure-handling"><a class="header" href="#6-failure-handling">6. Failure Handling</a></h2>
<ul>
<li>Manifest edits capture Region metadata, WAL checkpoints, and ValueLog pointers. Restart simply reads <code>CURRENT</code> and replays edits.</li>
<li>WAL replay reconstructs memtables and Raft groups; ValueLog recovery trims partial records.</li>
<li><code>Stats.StartStats</code> resumes metrics sampling immediately after restart, making it easy to verify recovery correctness via <code>nokv stats</code>.</li>
</ul>
<hr>
<h2 id="7-observability--tooling"><a class="header" href="#7-observability--tooling">7. Observability &amp; Tooling</a></h2>
<ul>
<li><code>StatsSnapshot</code> publishes flush/compaction/WAL/VLog/txn/region metrics. <code>nokv stats</code> and the expvar endpoint expose the same data.</li>
<li><code>nokv regions</code> inspects Manifest-backed Region metadata.</li>
<li><code>nokv serve</code> advertises Region samples on startup (ID, key range, peers) for quick verification.</li>
<li>Scripts:
<ul>
<li><code>scripts/run_local_cluster.sh</code> â€“ launch a multi-node TinyKv cluster locally.</li>
<li><code>scripts/recovery_scenarios.sh</code> â€“ crash-recovery test harness.</li>
<li><code>scripts/transport_chaos.sh</code> â€“ inject network faults and observe transport metrics.</li>
</ul>
</li>
</ul>
<hr>
<h2 id="8-when-to-use-nokv"><a class="header" href="#8-when-to-use-nokv">8. When to Use NoKV</a></h2>
<ul>
<li><strong>Embedded</strong>: call <code>NoKV.Open</code>, use the MVCC store locally.</li>
<li><strong>Distributed</strong>: deploy <code>nokv serve</code> nodes, use <code>raftstore/client</code> (or any TinyKv gRPC client) to perform reads, scans, and 2PC writes.</li>
<li><strong>Observability-first</strong>: inspection via CLI or expvar is built-in; Region, WAL, Flush, and Raft metrics are accessible without extra instrumentation.</li>
</ul>
<p>See also <a href="#raftstore-deep-dive"><code>docs/raftstore.md</code></a> for deeper internals and <a href="#testing--validation-matrix"><code>docs/testing.md</code></a> for coverage details.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="configuration--options"><a class="header" href="#configuration--options">Configuration &amp; Options</a></h1>
<p>NoKV exposes two configuration surfaces:</p>
<ol>
<li><strong>Runtime options</strong> for the embedded engine (<code>Options</code> in <code>options.go</code>).</li>
<li><strong>Cluster topology</strong> for distributed mode (<code>raft_config.example.json</code> via
<code>config.LoadFile/Validate</code>).</li>
</ol>
<hr>
<h2 id="1-runtime-options-embedded-engine"><a class="header" href="#1-runtime-options-embedded-engine">1. Runtime Options (Embedded Engine)</a></h2>
<p><code>NoKV.NewDefaultOptions()</code> returns a tuned baseline. Override fields before
calling <code>NoKV.Open(opt)</code>.</p>
<p>Key option groups (see <code>options.go</code> for the full list):</p>
<ul>
<li><strong>Paths &amp; durability</strong>
<ul>
<li><code>WorkDir</code>, <code>SyncWrites</code>, <code>ManifestSync</code>, <code>ManifestRewriteThreshold</code></li>
</ul>
</li>
<li><strong>Write pipeline</strong>
<ul>
<li><code>WriteBatchMaxCount</code>, <code>WriteBatchMaxSize</code>, <code>WriteBatchWait</code></li>
</ul>
</li>
<li><strong>Value log</strong>
<ul>
<li><code>ValueThreshold</code>, <code>ValueLogFileSize</code>, <code>ValueLogMaxEntries</code></li>
<li><code>ValueLogGCInterval</code>, <code>ValueLogGCDiscardRatio</code></li>
<li><code>ValueLogGCParallelism</code>, <code>ValueLogGCReduceScore</code>, <code>ValueLogGCSkipScore</code></li>
<li><code>ValueLogGCReduceBacklog</code>, <code>ValueLogGCSkipBacklog</code></li>
<li><code>ValueLogGCSampleSizeRatio</code>, <code>ValueLogGCSampleCountRatio</code>,
<code>ValueLogGCSampleFromHead</code></li>
<li><code>ValueLogBucketCount</code>, <code>ValueLogHotBucketCount</code>, <code>ValueLogHotKeyThreshold</code></li>
</ul>
</li>
<li><strong>LSM &amp; compaction</strong>
<ul>
<li><code>MemTableSize</code>, <code>MemTableEngine</code>, <code>SSTableMaxSz</code>, <code>NumCompactors</code></li>
<li><code>NumLevelZeroTables</code>, <code>IngestCompactBatchSize</code>, <code>IngestBacklogMergeScore</code></li>
<li><code>CompactionValueWeight</code>, <code>CompactionValueAlertThreshold</code></li>
</ul>
</li>
<li><strong>Caches</strong>
<ul>
<li><code>BlockCacheSize</code>, <code>BloomCacheSize</code></li>
</ul>
</li>
<li><strong>Hot key throttling</strong>
<ul>
<li><code>WriteHotKeyLimit</code>, <code>HotWriteBurstThreshold</code>, <code>HotWriteBatchMultiplier</code></li>
<li><code>HotRingEnabled</code>, <code>HotRingTopK</code>, decay/window settings</li>
<li><code>HotRingNodeCap</code>, <code>HotRingNodeSampleBits</code>, <code>HotRingRotationInterval</code></li>
<li><code>ValueLogHotRingOverride</code> + <code>ValueLogHotRing*</code> overrides</li>
</ul>
</li>
<li><strong>WAL watchdog</strong>
<ul>
<li><code>EnableWALWatchdog</code>, <code>WALAutoGCInterval</code></li>
<li><code>WALAutoGCMinRemovable</code>, <code>WALAutoGCMaxBatch</code></li>
<li><code>WALTypedRecordWarnRatio</code>, <code>WALTypedRecordWarnSegments</code></li>
</ul>
</li>
<li><strong>Raft lag warnings (stats only)</strong>
<ul>
<li><code>RaftLagWarnSegments</code></li>
</ul>
</li>
</ul>
<p>Example:</p>
<pre><code class="language-go">opt := NoKV.NewDefaultOptions()
opt.WorkDir = "./data"
opt.SyncWrites = true
opt.ValueThreshold = 1024
opt.WriteBatchMaxCount = 128
db := NoKV.Open(opt)
defer db.Close()
</code></pre>
<h3 id="load-options-from-toml"><a class="header" href="#load-options-from-toml">Load Options From TOML</a></h3>
<p>For convenience, you can load engine options from a TOML file. Unspecified
fields keep their defaults from <code>NewDefaultOptions</code>.</p>
<pre><code class="language-go">opt, err := NoKV.LoadOptionsFile("nokv.options.toml")
if err != nil {
    log.Fatal(err)
}
db := NoKV.Open(opt)
defer db.Close()
</code></pre>
<p>Example (TOML):</p>
<pre><code class="language-toml">work_dir = "./data"
mem_table_engine = "art"
value_threshold = 1024
write_hot_key_limit = 128
value_log_gc_interval = "30s"
</code></pre>
<p>Notes:</p>
<ul>
<li>Field names are case-insensitive; <code>_</code> / <code>-</code> / <code>.</code> are ignored.</li>
<li>Durations accept Go-style strings (e.g. <code>"30s"</code>, <code>"200ms"</code>). Numeric durations
are interpreted as nanoseconds.</li>
<li>File extensions <code>.toml</code> and <code>.tml</code> are accepted.</li>
<li>JSON option files are rejected by design.</li>
<li>Unknown fields return an error so typos do not silently pass.</li>
</ul>
<hr>
<h2 id="2-raft-topology-file"><a class="header" href="#2-raft-topology-file">2. Raft Topology File</a></h2>
<p><code>raft_config.example.json</code> is the single source of truth for distributed
topology. It is consumed by scripts, <code>cmd/nokv-redis</code>, and the <code>config</code> package.</p>
<p>Minimal shape:</p>
<pre><code class="language-jsonc">{
  "max_retries": 8,
  "tso": { "listen_addr": "127.0.0.1:9494", "advertise_url": "http://127.0.0.1:9494" },
  "stores": [
    { "store_id": 1, "listen_addr": "127.0.0.1:20170", "addr": "127.0.0.1:20170" }
  ],
  "regions": [
    {
      "id": 1,
      "start_key": "-",
      "end_key": "-",
      "epoch": { "version": 1, "conf_version": 1 },
      "peers": [{ "store_id": 1, "peer_id": 101 }],
      "leader_store_id": 1
    }
  ]
}
</code></pre>
<p>Notes:</p>
<ul>
<li><code>start_key</code> / <code>end_key</code> accept plain strings, <code>hex:&lt;bytes&gt;</code>, or base64. Use
<code>"-"</code> or empty for unbounded ranges.</li>
<li><code>stores</code> define both host and docker addresses for local runs vs containers.</li>
<li><code>leader_store_id</code> is optional; clients use it for initial routing hints.</li>
</ul>
<p>Programmatic loading:</p>
<pre><code class="language-go">cfg, _ := config.LoadFile("raft_config.example.json")
if err := cfg.Validate(); err != nil { /* handle */ }
</code></pre>
<p>Related tools:</p>
<ul>
<li><code>scripts/run_local_cluster.sh --config raft_config.example.json</code></li>
<li><code>go run ./cmd/nokv-redis --raft-config raft_config.example.json</code></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="cli-cmdnokv-reference"><a class="header" href="#cli-cmdnokv-reference">CLI (<code>cmd/nokv</code>) Reference</a></h1>
<p><code>nokv</code> provides operational visibility similar to RocksDB <code>ldb</code> / Badger CLI, with script-friendly JSON output.</p>
<hr>
<h2 id="installation"><a class="header" href="#installation">Installation</a></h2>
<pre><code class="language-bash">go install ./cmd/nokv
</code></pre>
<hr>
<h2 id="shared-flags"><a class="header" href="#shared-flags">Shared Flags</a></h2>
<ul>
<li><code>--workdir &lt;path&gt;</code>: NoKV database directory (must contain <code>CURRENT</code> for manifest commands)</li>
<li><code>--json</code>: JSON output (default is plain text)</li>
<li><code>--expvar &lt;url&gt;</code>: for <code>stats</code>, fetch from <code>/debug/vars</code></li>
<li><code>--no-region-metrics</code>: for offline <code>stats</code>, skip attaching runtime region metrics</li>
</ul>
<hr>
<h2 id="subcommands"><a class="header" href="#subcommands">Subcommands</a></h2>
<h3 id="nokv-stats"><a class="header" href="#nokv-stats"><code>nokv stats</code></a></h3>
<ul>
<li>Reads <code>StatsSnapshot</code> either offline (<code>--workdir</code>) or online (<code>--expvar</code>)</li>
<li>JSON output is nested by domain (not flat)</li>
</ul>
<p>Common fields:</p>
<ul>
<li><code>entries</code></li>
<li><code>flush.pending</code>, <code>flush.queue_length</code>, <code>flush.last_wait_ms</code></li>
<li><code>compaction.backlog</code>, <code>compaction.max_score</code></li>
<li><code>value_log.segments</code>, <code>value_log.pending_deletes</code>, <code>value_log.gc.*</code></li>
<li><code>wal.active_segment</code>, <code>wal.segment_count</code>, <code>wal.typed_record_ratio</code></li>
<li><code>write.queue_depth</code>, <code>write.queue_entries</code>, <code>write.hot_key_limited</code></li>
<li><code>txn.active</code>, <code>txn.committed</code>, <code>txn.conflicts</code></li>
<li><code>region.total</code>, <code>region.running</code>, <code>region.removing</code></li>
<li><code>hot.read_keys</code>, <code>hot.write_keys</code></li>
<li><code>lsm.levels</code>, <code>lsm.value_bytes_total</code></li>
<li><code>transport.*</code>, <code>redis.*</code></li>
</ul>
<p>Example:</p>
<pre><code class="language-bash">nokv stats --workdir ./testdata/db --json | jq '.flush.queue_length'
</code></pre>
<h3 id="nokv-manifest"><a class="header" href="#nokv-manifest"><code>nokv manifest</code></a></h3>
<ul>
<li>Reads manifest version state</li>
<li>Shows log pointer, per-level file info, and value-log metadata</li>
</ul>
<h3 id="nokv-vlog"><a class="header" href="#nokv-vlog"><code>nokv vlog</code></a></h3>
<ul>
<li>Lists value-log segments and current head per bucket</li>
<li>Useful after GC/recovery checks</li>
</ul>
<h3 id="nokv-regions"><a class="header" href="#nokv-regions"><code>nokv regions</code></a></h3>
<ul>
<li>Dumps manifest-backed region catalog (state/range/epoch/peers)</li>
<li>Supports <code>--json</code></li>
</ul>
<h3 id="nokv-scheduler"><a class="header" href="#nokv-scheduler"><code>nokv scheduler</code></a></h3>
<ul>
<li>Displays scheduler heartbeat snapshot (in-process usage)</li>
</ul>
<hr>
<h2 id="integration-tips"><a class="header" href="#integration-tips">Integration Tips</a></h2>
<ul>
<li>Combine with <code>RECOVERY_TRACE_METRICS=1</code> for recovery validation.</li>
<li>In CI, compare JSON snapshots to detect observability regressions.</li>
<li>Use <code>nokv stats --expvar</code> for online diagnostics and <code>--workdir</code> for offline forensics.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="memtable-design--lifecycle"><a class="header" href="#memtable-design--lifecycle">Memtable Design &amp; Lifecycle</a></h1>
<p>NoKVâ€™s write path mirrors RocksDB: every write lands in the <strong>WAL</strong> and an in-memory <strong>memtable</strong> backed by a selectable in-memory index (skiplist or ART). The implementation lives in <a href="../lsm/memtable.go"><code>lsm/memtable.go</code></a> and ties directly into the flush manager (<code>lsm/flush</code>).</p>
<hr>
<h2 id="1-structure"><a class="header" href="#1-structure">1. Structure</a></h2>
<pre><code class="language-go">type memTable struct {
    lsm        *LSM
    segmentID  uint32       // WAL segment backing this memtable
    index      memIndex
    maxVersion uint64
    walSize    int64
}
</code></pre>
<p>The memtable index is an interface that can be backed by either a skiplist or ART:</p>
<pre><code class="language-go">type memIndex interface {
    Add(*kv.Entry)
    Search([]byte) kv.ValueStruct
    NewIterator(*utils.Options) utils.Iterator
    MemSize() int64
    IncrRef()
    DecrRef()
}
</code></pre>
<ul>
<li><strong>Memtable engine</strong> â€“ <code>Options.MemTableEngine</code> selects <code>skiplist</code> (default) or <code>art</code> via <code>newMemIndex</code>. Skiplist favors simpler writes; ART favors tighter memory and ordered scans.</li>
<li><strong>Arena sizing</strong> â€“ both <code>utils.NewSkiplist</code> and <code>utils.NewART</code> use <code>arenaSizeFor</code> to derive arena capacity from <code>Options.MemTableSize</code>.</li>
<li><strong>WAL coupling</strong> â€“ every <code>Set</code> uses <code>kv.EncodeEntry</code> to materialise the payload to the active WAL segment before inserting into the chosen index. <code>walSize</code> tracks how much of the segment is consumed so flush can release it later.</li>
<li><strong>Segment ID</strong> â€“ <code>LSM.NewMemtable</code> atomically increments <code>levels.maxFID</code>, switches the WAL to a new segment (<code>wal.Manager.SwitchSegment</code>), and tags the memtable with that FID. This matches RocksDBâ€™s <code>logfile_number</code> field.</li>
<li><strong>ART specifics</strong> â€“ ART stores prefix-compressed inner nodes (Node4/16/48/256), uses copy-on-write payload/node clones with CAS installs for writes, and keeps reads lock-free on immutable snapshots.</li>
</ul>
<hr>
<h2 id="2-lifecycle"><a class="header" href="#2-lifecycle">2. Lifecycle</a></h2>
<pre class="mermaid">sequenceDiagram
    participant WAL
    participant MT as MemTable
    participant Flush
    participant Manifest
    WAL-&gt;&gt;MT: Append+Set(entry)
    MT-&gt;&gt;Flush: freeze (walSize + incomingEstimate &gt; limit)
    Flush-&gt;&gt;Manifest: LogPointer + AddFile
    Manifest--&gt;&gt;Flush: ack
    Flush-&gt;&gt;WAL: Release segments â‰¤ segmentID
</pre>

<ol>
<li><strong>Active â†’ Immutable</strong> â€“ when <code>mt.walSize + estimate</code> exceeds <code>Options.MemTableSize</code>, the memtable is rotated and pushed onto the flush queue. The new active memtable triggers another WAL segment switch.</li>
<li><strong>Flush</strong> â€“ the flush manager drains immutable memtables, builds SSTables, logs manifest edits, and releases the WAL segment ID recorded in <code>memTable.segmentID</code> once the SST is durably installed.</li>
<li><strong>Recovery</strong> â€“ <code>LSM.recovery</code> scans WAL files, reopens memtables per segment (most recent becomes active), and deletes segments â‰¤ the manifestâ€™s log pointer. Entries are replayed via <code>wal.Manager.ReplaySegment</code> into fresh indexes, rebuilding <code>maxVersion</code> for the oracle.</li>
</ol>
<p>Badger follows the same pattern, while RocksDB often uses skiplist-backed arenas with reference countingâ€”NoKV reuses Badgerâ€™s arena allocator for simplicity.</p>
<hr>
<h2 id="3-read-semantics"><a class="header" href="#3-read-semantics">3. Read Semantics</a></h2>
<ul>
<li><code>memTable.Get</code> looks up the chosen index and returns a borrowed, ref-counted <code>*kv.Entry</code> from the internal pool. Internal callers must release it with <code>DecrRef</code> when done. MVCC versions stay encoded in the key suffix (<code>KeyWithTs</code>), so iterators naturally merge across memtables and SSTables.</li>
<li><code>MemTable.IncrRef/DecrRef</code> delegate to the index, allowing iterators to hold references while the flush manager processes immutable tablesâ€”mirroring RocksDBâ€™s <code>MemTable::Ref/Unref</code> lifecycle.</li>
<li>WAL-backed values that exceed the value threshold are stored as pointers; the memtable stores the encoded pointer, and the transaction/iterator logic reads from the vlog on demand.</li>
<li>Public read APIs (<code>DB.Get</code>, <code>DB.GetCF</code>, <code>DB.GetVersionedEntry</code>, <code>Txn.Get</code>) return detached entries, so application callers do not need to call <code>DecrRef</code>.</li>
</ul>
<hr>
<h2 id="4-integration-with-other-subsystems"><a class="header" href="#4-integration-with-other-subsystems">4. Integration with Other Subsystems</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Subsystem</th><th>Interaction</th></tr>
</thead>
<tbody>
<tr><td>Transactions</td><td><code>Txn.commitAndSend</code> writes entries into the active memtable after WAL append; pending writes bypass the memtable until commit so per-txn isolation is preserved.</td></tr>
<tr><td>Manifest</td><td>Flush completion logs <code>EditLogPointer(segmentID)</code> so restart can discard WAL files already persisted into SSTs.</td></tr>
<tr><td>Stats</td><td><code>Stats.Snapshot</code> pulls <code>FlushPending/Active/Queue</code> counters via <a href="../lsm/lsm.go#L120-L128"><code>lsm.FlushMetrics</code></a>, exposing how many immutables are waiting.</td></tr>
<tr><td>Value Log</td><td><code>lsm.flush</code> emits discard stats keyed by <code>segmentID</code>, letting the value log GC know when entries become obsolete.</td></tr>
</tbody>
</table>
</div>
<hr>
<h2 id="5-comparison"><a class="header" href="#5-comparison">5. Comparison</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Aspect</th><th>RocksDB</th><th>BadgerDB</th><th>NoKV</th></tr>
</thead>
<tbody>
<tr><td>Data structure</td><td>Skiplist + arena</td><td>Skiplist + arena</td><td>Skiplist or ART + arena</td></tr>
<tr><td>WAL linkage</td><td><code>logfile_number</code> per memtable</td><td>Segment ID stored in vlog entries</td><td><code>segmentID</code> on <code>memTable</code>, logged via manifest</td></tr>
<tr><td>Recovery</td><td>Memtable replays from WAL, referencing <code>MANIFEST</code></td><td>Replays WAL segments</td><td>Replays WAL segments, prunes â‰¤ manifest log pointer</td></tr>
<tr><td>Flush trigger</td><td>Size/entries/time</td><td>Size-based</td><td>WAL-size budget (<code>walSize</code>) with explicit queue metrics</td></tr>
</tbody>
</table>
</div>
<hr>
<h2 id="6-operational-notes"><a class="header" href="#6-operational-notes">6. Operational Notes</a></h2>
<ul>
<li>Tuning <code>Options.MemTableSize</code> affects WAL segment count and flush latency. Larger memtables reduce flush churn but increase crash recovery time.</li>
<li>Monitor <code>NoKV.Stats.flush.*</code> fields to catch stalled immutablesâ€”an ever-growing queue often indicates slow SST builds or manifest contention.</li>
<li>Because memtables carry WAL segment IDs, deleting WAL files manually can lead to recovery failures; always rely on the engineâ€™s manifest-driven cleanup.</li>
</ul>
<p>See <a href="#memtable-flush-pipeline"><code>docs/flush.md</code></a> for the end-to-end flush scheduler and <code>[docs/architecture.md](architecture.md#3-end-to-end-write-flow)</code> for where memtables sit in the write pipeline.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="memtable-flush-pipeline"><a class="header" href="#memtable-flush-pipeline">MemTable Flush Pipeline</a></h1>
<p>NoKVâ€™s flush subsystem translates immutable memtables into persisted SSTables while coordinating WAL checkpoints and ValueLog discard statistics. The code lives in <a href="../lsm/flush"><code>lsm/flush</code></a> and is tightly integrated with <code>DB.doWrites</code> and <code>manifest.Manager</code>.</p>
<hr>
<h2 id="1-responsibilities"><a class="header" href="#1-responsibilities">1. Responsibilities</a></h2>
<ol>
<li><strong>Reliability</strong> â€“ ensure immutables become SSTables atomically, and failures are recoverable.</li>
<li><strong>Coordination</strong> â€“ release WAL segments only after manifest commits, and feed discard stats to ValueLog GC.</li>
<li><strong>Observability</strong> â€“ expose queue depth, stage durations, and task counts through <code>Stats.collect</code> and the CLI.</li>
</ol>
<p>Compared with RocksDB: the stage transitions mirror RocksDBâ€™s flush job lifecycle (<code>PickMemTable</code>, <code>WriteLevel0Table</code>, <code>InstallMemTable</code>), while the discard stats channel is inspired by Badgerâ€™s integration with vlog GC.</p>
<hr>
<h2 id="2-stage-machine"><a class="header" href="#2-stage-machine">2. Stage Machine</a></h2>
<pre class="mermaid">flowchart LR
    Active[Active MemTable]
    Immutable[Immutable MemTable]
    FlushQ[flush.Manager queue]
    Build[StageBuild]
    Install[StageInstall]
    Release[StageRelease]

    Active --&gt;|threshold reached| Immutable --&gt; FlushQ
    FlushQ --&gt; Build --&gt; Install --&gt; Release --&gt; Active
</pre>

<ul>
<li><strong>StagePrepare</strong> â€“ <code>Manager.Submit</code> assigns a task ID, records enqueue time, and bumps queue metrics.</li>
<li><strong>StageBuild</strong> â€“ <code>Manager.Next</code> hands tasks to background workers. <code>buildTable</code> serialises data into a temporary <code>.sst.tmp</code> using <code>lsm/builder.go</code>.</li>
<li><strong>StageInstall</strong> â€“ manifest edits (<code>EditAddFile</code>, <code>EditLogPointer</code>) are logged. Only on success is the temp file renamed and the WAL checkpoint advanced.</li>
<li><strong>StageRelease</strong> â€“ metrics record release duration, discard stats are flushed to <code>valueLog.lfDiscardStats</code>, and <code>wal.Manager.Remove</code> drops obsolete segments.</li>
</ul>
<p><code>Manager.Update</code> transitions between stages and collects timing data (<code>WaitNs</code>, <code>BuildNs</code>, <code>ReleaseNs</code>). These surface via <code>StatsSnapshot.Flush</code> fields (for example <code>QueueLength</code>, <code>BuildMs</code>) in <code>nokv stats</code> output.</p>
<hr>
<h2 id="3-key-types"><a class="header" href="#3-key-types">3. Key Types</a></h2>
<pre><code class="language-go">type Task struct {
    ID        uint64
    SegmentID uint32
    Stage     Stage
    Data      any      // memtable pointer, temp file info, etc.
    Err       error
}

type Manager struct {
    queue []*Task
    active map[uint64]*Task
    cond  *sync.Cond
    // atomic metrics fields (pending, queueLen, waitNs...)
}
</code></pre>
<ul>
<li><code>Stage</code> enumerates <code>StagePrepare</code>, <code>StageBuild</code>, <code>StageInstall</code>, <code>StageRelease</code>.</li>
<li><code>Metrics</code> aggregates pending/active counts and nanosecond accumulators; the CLI converts them to human-friendly durations.</li>
<li>The queue uses condition variables to coordinate between background workers and producers; the design avoids busy waiting, unlike some RocksDB flush queues.</li>
</ul>
<hr>
<h2 id="4-execution-path-in-code"><a class="header" href="#4-execution-path-in-code">4. Execution Path in Code</a></h2>
<ol>
<li><code>DB.applyBatches</code> detects when the active memtable is full and hands it to <code>lsm.LSM.scheduleFlush</code>, which calls <code>flush.Manager.Submit</code>.</li>
<li>Background goroutines call <code>Next</code> to retrieve tasks; <code>lsm.(*LSM).runFlushMemTable</code> performs the build and install phases.</li>
<li><code>lsm.(*LSM).installLevel0Table</code> writes the manifest edit and renames the SST (atomic <code>os.Rename</code>, same as RocksDBâ€™s flush job).</li>
<li>After install, <code>valueLog.updateDiscardStats</code> is called so GC can reclaim vlog entries belonging to dropped keys.</li>
<li>Once release completes, <code>wal.Manager.Remove</code> evicts segments whose entries are fully represented in SSTs, matching RocksDBâ€™s <code>LogFileManager::PurgeObsoleteLogs</code>.</li>
</ol>
<hr>
<h2 id="5-recovery-considerations"><a class="header" href="#5-recovery-considerations">5. Recovery Considerations</a></h2>
<ul>
<li><strong>Before Install</strong> â€“ temp files remain in <code>tmp/</code>. On restart, no manifest entry exists, so <code>lsm.LSM.replayManifest</code> ignores them and the memtable is rebuilt from WAL.</li>
<li><strong>After Install but before Release</strong> â€“ manifest records the SST while WAL segments may still exist. Recovery sees the edit, ensures the file exists, and release metrics resume from StageRelease.</li>
<li><strong>Metrics</strong> â€“ because timing data is stored atomically in the manager, recovery resets counters but does not prevent the CLI from reporting backlog immediately after restart.</li>
</ul>
<p>RocksDB uses flush job logs; NoKV reuses metrics and CLI output for similar visibility.</p>
<hr>
<h2 id="6-observability--cli"><a class="header" href="#6-observability--cli">6. Observability &amp; CLI</a></h2>
<ul>
<li><code>StatsSnapshot.Flush.QueueLength</code> â€“ number of pending tasks.</li>
<li><code>StatsSnapshot.Flush.WaitMs</code> â€“ average wait time before build.</li>
<li><code>StatsSnapshot.Flush.BuildMs</code> â€“ average build duration.</li>
<li><code>StatsSnapshot.Flush.Completed</code> â€“ cumulative tasks finished.</li>
</ul>
<p>The CLI command <code>nokv stats --workdir &lt;dir&gt;</code> prints these metrics alongside compaction and transaction statistics, enabling operators to detect stalled flush workers or WAL backlog quickly.</p>
<hr>
<h2 id="7-interplay-with-valuelog-gc"><a class="header" href="#7-interplay-with-valuelog-gc">7. Interplay with ValueLog GC</a></h2>
<p>Flush completion sends discard stats via <code>db.lsm.SetDiscardStatsCh(&amp;(db.vlog.lfDiscardStats.flushChan))</code>. ValueLog GC uses this feed to determine how much of each vlog segment is obsolete, similar to Badgerâ€™s discard ratio heuristic. Without flush-driven stats, vlog GC would have to rescan SSTables, so this channel is crucial for keeping GC cheap.</p>
<hr>
<h2 id="8-testing-matrix"><a class="header" href="#8-testing-matrix">8. Testing Matrix</a></h2>
<ul>
<li><code>lsm/flush/manager_test.go</code> (implicit via <code>lsm/lsm_test.go</code>) validates stage transitions and metrics.</li>
<li><code>db_recovery_test.go</code> covers crash scenarios before/after install, ensuring WAL replay plus manifest reconciliation recovers gracefully.</li>
<li>Future additions: inject write failures during <code>StageBuild</code> to test retry logic, analogous to RocksDBâ€™s simulated IO errors.</li>
</ul>
<p>See the <a href="#crash-recovery-playbook">recovery plan</a> and <a href="#testing--validation-matrix">testing matrix</a> for more context.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="compaction--cache-strategy"><a class="header" href="#compaction--cache-strategy">Compaction &amp; Cache Strategy</a></h1>
<blockquote>
<p>NoKVâ€™s compaction pipeline borrows the leveledâ€‘LSM layout from RocksDB, but layers it with an ingest buffer, lightweight cache telemetry, and simple concurrency guards so the implementation stays approachable while still handling bursty workloads.</p>
</blockquote>
<hr>
<h2 id="1-overview"><a class="header" href="#1-overview">1. Overview</a></h2>
<p>Compactions are orchestrated by <code>compact.Manager</code> with <code>lsm.levelManager</code> implementing the executor hooks. Each level owns two lists of tables:</p>
<ul>
<li><code>tables</code> â€“ the canonical sorted run for the level.</li>
<li><code>ingest</code> â€“ a staging buffer that temporarily holds SSTables moved from the level above when there is not yet enough work (or bandwidth) to do a full merge.</li>
</ul>
<p>The compaction manager periodically calls into the executor to build a list of <code>compact.Priority</code> entries.  The priorities consider three signals:</p>
<ol>
<li><strong>L0 table count</strong> â€“ loosely capped by <code>Options.NumLevelZeroTables</code>.</li>
<li><strong>Level size vs target</strong> â€“ computed by <code>levelTargets()</code>, which dynamically adjusts the â€œbaseâ€ level depending on total data volume.</li>
<li><strong>Ingest buffer backlog</strong> â€“ if a levelâ€™s <code>ingest</code> shards have data, they receive elevated scores so staged tables are merged promptly.</li>
</ol>
<p>The highest adjusted score is processed first.  L0 compactions can either move tables into the ingest buffer of the base level (cheap reâ€‘parenting) or compact directly into a lower level when the overlap warrants it.</p>
<p>Planning now happens via <code>compact.Plan</code>: LSM snapshots table metadata into <code>compact.TableMeta</code>, <code>compact.PlanFor*</code> selects table IDs + key ranges, and LSM resolves the plan back to <code>*table</code> before executing.</p>
<hr>
<h2 id="2-ingest-buffer"><a class="header" href="#2-ingest-buffer">2. Ingest Buffer</a></h2>
<p><code>moveToIngest</code> (see <code>lsm/executor.go</code>) performs a metadata-only migration:</p>
<ol>
<li>Records a <code>manifest.EditDeleteFile</code> for the source level.</li>
<li>Logs a new <code>manifest.EditAddFile</code> targeting the destination level.</li>
<li>Removes the table from <code>thisLevel.tables</code> and appends it to <code>nextLevel.ingest</code>.</li>
</ol>
<p>This keeps write amplification low when many small L0 tables arrive at once.  Reads still see the newest data because <code>levelHandler.searchIngestSST</code> checks <code>ingest</code> before consulting <code>tables</code>.</p>
<p>Compaction tests (<code>lsm/compaction_cache_test.go</code>) now assert that after calling <code>moveToIngest</code> the table disappears from the source level and shows up in the ingest buffer.</p>
<hr>
<h2 id="3-concurrency-guards"><a class="header" href="#3-concurrency-guards">3. Concurrency Guards</a></h2>
<p>To prevent overlapping compactions:</p>
<ul>
<li><code>compact.State.CompareAndAdd</code> tracks the key range of each in-flight compaction per level.</li>
<li>Attempts to register a compaction whose ranges intersect an existing one are rejected.</li>
<li>When a compaction finishes, <code>compact.State.Delete</code> removes the ranges and table IDs from the guard.</li>
</ul>
<p>This mechanism is intentionally simpleâ€”just a mutexâ€protected sliceâ€”yet effective in tests (<code>TestCompactStatusGuards</code>) that simulate backâ€‘toâ€‘back registrations on the same key range.</p>
<hr>
<h2 id="4-cache-telemetry"><a class="header" href="#4-cache-telemetry">4. Cache Telemetry</a></h2>
<p>NoKVâ€™s cache is split into three parts (<code>lsm/cache.go</code>):</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Component</th><th>Purpose</th><th>Metrics hook</th></tr>
</thead>
<tbody>
<tr><td>Block cache</td><td>Ristretto cache for L0/L1 blocks.</td><td><code>cacheMetrics.recordBlock(level, hit)</code></td></tr>
<tr><td>OS page cache path</td><td>Deeper levels bypass user-space cache and rely on mmap + kernel page cache.</td><td>Same as above</td></tr>
<tr><td>Bloom cache</td><td>Stores decoded bloom filters to reduce disk touches.</td><td><code>recordBloom(hit)</code></td></tr>
</tbody>
</table>
</div>
<p><code>CacheMetrics()</code> on <code>DB</code> surfaces hits/misses per layer, which is especially helpful when tuning ingest behaviourâ€”if L0/L1 cache misses spike, the ingest buffer likely needs to be drained faster. <code>TestCacheHotColdMetrics</code> verifies cache hit accounting.</p>
<hr>
<h2 id="5-interaction-with-value-log"><a class="header" href="#5-interaction-with-value-log">5. Interaction with Value Log</a></h2>
<p>Compaction informs valueâ€‘log GC via discard statistics:</p>
<ol>
<li>During <code>subcompact</code>, every entry merged out is inspected.  If it stores a <code>ValuePtr</code>, the amount is added to the discard map.</li>
<li>At the end of subcompaction, the accumulated discard map is pushed through <code>setDiscardStatsCh</code>.</li>
<li><code>valueLog</code> receives the stats and can safely rewrite or delete vlog segments with predominantly obsolete data.</li>
</ol>
<p>This tight coupling keeps the value log from growing indefinitely after heavy overwrite workloads.</p>
<hr>
<h2 id="6-testing-checklist"><a class="header" href="#6-testing-checklist">6. Testing Checklist</a></h2>
<p>Relevant tests to keep compaction healthy:</p>
<ul>
<li><code>lsm/compaction_cache_test.go</code>
<ul>
<li><code>TestCompactionMoveToIngest</code> â€“ ensures metadata migration works and the ingest buffer grows.</li>
<li><code>TestCacheHotColdMetrics</code> â€“ validates cache hit accounting.</li>
<li><code>TestCompactStatusGuards</code> â€“ checks overlap detection.</li>
</ul>
</li>
<li><code>lsm/lsm_test.go</code>
<ul>
<li><code>TestCompact</code> / <code>TestHitStorage</code> â€“ endâ€‘toâ€‘end verification that data remains queryable across memtable flushes and compactions.</li>
</ul>
</li>
</ul>
<p>When adding new compaction heuristics or cache behaviour, extend these tests (or introduce new ones) so the behaviour stays observable.</p>
<hr>
<h2 id="7-practical-tips"><a class="header" href="#7-practical-tips">7. Practical Tips</a></h2>
<ul>
<li>Tune <code>Options.IngestCompactBatchSize</code> when ingest queues build up; increasing it lets a single move cover more tables.</li>
<li>Observe <code>DB.CacheMetrics()</code> and <code>DB.CompactionStats()</code> via the CLI (<code>nokv stats</code>) to decide whether you need more compaction workers or bigger caches.</li>
<li>For workloads dominated by range scans, consider increasing <code>Options.BlockCacheSize</code> if you want to keep more L0/L1 blocks in the user-space cache; cold data relies on the OS page cache.</li>
<li>Keep an eye on <code>NoKV.Stats.value_log.gc</code> (for example <code>gc_runs</code> and <code>head_updates</code>); if compactions are generating discard stats but the value log head doesnâ€™t move, GC thresholds may be too conservative.</li>
</ul>
<p>With these mechanisms, NoKV stays resilient under bursty writes while keeping the code path small and discoverableâ€”ideal for learning or embedding.  Dive into the source files referenced above for deeper implementation details.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="ingest-buffer-architecture"><a class="header" href="#ingest-buffer-architecture">Ingest Buffer Architecture</a></h1>
<p>The ingest buffer is a per-level staging area for SSTablesâ€”typically promoted from L0â€”designed to <strong>absorb bursts, reduce overlap, and unlock parallel compaction</strong> without touching the main level tables immediately. It combines fixed sharding, adaptive scheduling, and optional <code>IngestKeep</code> (ingest-merge) passes to keep write amplification and contention low.</p>
<pre class="mermaid">flowchart LR
  L0["L0 SSTables"] --&gt;|moveToIngest| Ingest["Ingest Buffer (sharded)"]
  subgraph levelN["Level N"]
    Ingest --&gt;|IngestDrain: ingest-only| MainTables["Main Tables"]
    Ingest --&gt;|IngestKeep: ingest-merge| Ingest
  end
  Ingest -.read path merge.-&gt; ClientReads["Reads/Iterators"]
</pre>

<h2 id="design-highlights"><a class="header" href="#design-highlights">Design Highlights</a></h2>
<ul>
<li><strong>Sharded by key prefix</strong>: ingest tables are routed into fixed shards (top bits of the first byte). Sharding cuts cross-range overlap and enables safe parallel drain.</li>
<li><strong>Snapshot-friendly reads</strong>: ingest tables are read under the level <code>RLock</code>, and iterators hold table refs so mmap-backed data stays valid without additional snapshots.</li>
<li><strong>Two ingest paths</strong>:
<ul>
<li><em>Ingest-only compaction</em>: drain ingest â†’ main level (or next level) with optional multi-shard parallelism guarded by <code>compact.State</code>.</li>
<li><em>Ingest-merge</em>: compact ingest tables back into ingest (stay in-place) to drop superseded versions before promoting, reducing downstream write amplification.</li>
</ul>
</li>
<li><strong>IngestMode enum</strong>: plans carry an <code>IngestMode</code> with <code>IngestNone</code>, <code>IngestDrain</code>, and <code>IngestKeep</code>. <code>IngestDrain</code> corresponds to ingest-only (drain into main tables), while <code>IngestKeep</code> corresponds to ingest-merge (compact within ingest).</li>
<li><strong>Adaptive scheduling</strong>:
<ul>
<li>Shard selection is driven by <code>compact.PickShardOrder</code> / <code>compact.PickShardByBacklog</code> using per-shard size, age, and density.</li>
<li>Shard parallelism scales with backlog score (based on shard size/target file size) bounded by <code>IngestShardParallelism</code>.</li>
<li>Batch size scales with shard backlog to drain faster under pressure.</li>
<li>Ingest-merge triggers when backlog score exceeds <code>IngestBacklogMergeScore</code> (default 2.0), with dynamic lowering under extreme backlog/age.</li>
</ul>
</li>
<li><strong>Observability</strong>: expvar/stats expose <code>IngestDrain</code> vs <code>IngestKeep</code> counts, duration, and tables processed, plus ingest size/value density per level/shard.</li>
</ul>
<h2 id="configuration"><a class="header" href="#configuration">Configuration</a></h2>
<ul>
<li><code>IngestShardParallelism</code>: max shards to compact in parallel (default <code>max(NumCompactors/2, 2)</code>, auto-scaled by backlog).</li>
<li><code>IngestCompactBatchSize</code>: base batch size per ingest compaction (auto-boosted by shard backlog).</li>
<li><code>IngestBacklogMergeScore</code>: backlog score threshold to trigger <code>IngestKeep</code>/ingest-merge (default 2.0).</li>
</ul>
<h2 id="benefits"><a class="header" href="#benefits">Benefits</a></h2>
<ul>
<li><strong>Lower write amplification</strong>: bursty L0 SSTables land in ingest first; <code>IngestKeep</code>/ingest-merge prunes duplicates before full compaction.</li>
<li><strong>Reduced contention</strong>: sharding + <code>compact.State</code> allow parallel ingest drain with minimal overlap.</li>
<li><strong>Predictable reads</strong>: ingest is part of the read snapshot, so moving tables in/out does not change read semantics.</li>
<li><strong>Tunable and observable</strong>: knobs for parallelism and merge aggressiveness, with per-path metrics to guide tuning.</li>
</ul>
<h2 id="future-work"><a class="header" href="#future-work">Future Work</a></h2>
<ul>
<li>Deeper adaptive policies (IO/latency-aware), richer shard-level metrics, and more exhaustive parallel/restart testing under fault injection.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="wal-subsystem"><a class="header" href="#wal-subsystem">WAL Subsystem</a></h1>
<p>NoKVâ€™s write-ahead log mirrors RocksDBâ€™s durability model and is implemented as a compact Go module similar to Badgerâ€™s journal. WAL appends happen alongside memtable writes (via <code>lsm.Set</code>), while values that are routed to the value log are written <em>before</em> the WAL so that replay always sees durable value pointers.</p>
<hr>
<h2 id="1-file-layout--naming"><a class="header" href="#1-file-layout--naming">1. File Layout &amp; Naming</a></h2>
<ul>
<li>Location: <code>${Options.WorkDir}/wal/</code>.</li>
<li>Naming pattern: <code>%05d.wal</code> (e.g. <code>00001.wal</code>).</li>
<li>Rotation threshold: configurable via <code>wal.Config.SegmentSize</code> (defaults to 64 MiB, minimum 64 KiB).</li>
<li>Verification: <code>wal.VerifyDir</code> ensures the directory exists prior to <code>DB.Open</code>.</li>
</ul>
<p>On open, <code>wal.Manager</code> scans the directory, sorts segment IDs, and resumes the highest IDâ€”exactly how RocksDB re-opens its MANIFEST and WAL sequence files.</p>
<hr>
<h2 id="2-record-format"><a class="header" href="#2-record-format">2. Record Format</a></h2>
<pre><code class="language-text">uint32 length (big-endian, includes type + payload)
uint8  type
[]byte payload
uint32 checksum (CRC32 Castagnoli over type + payload)
</code></pre>
<ul>
<li>Checksums use <code>kv.CastagnoliCrcTable</code>, the same polynomial used by RocksDB (Castagnoli). Record encoding/decoding lives in <code>wal/record.go</code>.</li>
<li>The type byte allows mixing LSM mutations with raft log/state/snapshot records in the same WAL segment.</li>
<li>Appends are buffered by <code>bufio.Writer</code> so batches become single system calls.</li>
<li>Replay stops cleanly at truncated tails; tests simulate torn writes by truncating the final bytes and verifying replay remains idempotent (<code>wal/manager_test.go::TestReplayTruncatedTail</code>).</li>
</ul>
<hr>
<h2 id="3-public-api-go"><a class="header" href="#3-public-api-go">3. Public API (Go)</a></h2>
<pre><code class="language-go">mgr, _ := wal.Open(wal.Config{Dir: path})
infos, _ := mgr.Append(batchPayload)
_ = mgr.Sync()
_ = mgr.Rotate()
_ = mgr.Replay(func(info wal.EntryInfo, payload []byte) error {
    // reapply to memtable
    return nil
})
</code></pre>
<p>Key behaviours:</p>
<ul>
<li><code>Append</code> automatically calls <code>ensureCapacity</code> to decide when to rotate; it returns <code>EntryInfo{SegmentID, Offset, Length}</code> for each payload so higher layers can build value pointers or manifest checkpoints.</li>
<li><code>Sync</code> flushes the active file (used for <code>Options.SyncWrites</code>).</li>
<li><code>Rotate</code> forces a new segment (used after flush/compaction checkpoints similar to RocksDBâ€™s <code>LogFileManager::SwitchLog</code>).</li>
<li><code>Replay</code> iterates segments in numeric order, forwarding each payload to the callback. Errors abort replay so recovery can surface corruption early.</li>
<li>Metrics (<code>wal.Manager.Metrics</code>) reveal the active segment ID, total segments, and number of removed segmentsâ€”these feed directly into <code>StatsSnapshot</code> and <code>nokv stats</code> output.</li>
</ul>
<p>Compared with Badger: Badger keeps a single vlog for both data and durability. NoKV splits WAL (durability) from vlog (value separation), matching RocksDBâ€™s separation of WAL and blob files.</p>
<hr>
<h2 id="4-integration-points"><a class="header" href="#4-integration-points">4. Integration Points</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Call Site</th><th>Purpose</th></tr>
</thead>
<tbody>
<tr><td><code>lsm.memTable.set</code></td><td>Encodes each entry (<code>kv.EncodeEntry</code>) and appends to WAL before inserting into the skiplist.</td></tr>
<tr><td><code>DB.commitWorker</code></td><td>Commit worker applies batched writes via <code>writeToLSM</code>, which flows into <code>lsm.Set</code> and thus WAL.</td></tr>
<tr><td><code>DB.Set</code></td><td>Direct write path: calls <code>lsm.Set</code>, which appends to WAL and updates the memtable.</td></tr>
<tr><td><code>manifest.Manager.LogEdit</code></td><td>Uses <code>EntryInfo.SegmentID</code> to persist the WAL checkpoint (<code>EditLogPointer</code>). This acts as the <code>log number</code> seen in RocksDB manifest entries.</td></tr>
<tr><td><code>lsm/flush.Manager.Update</code></td><td>Once an SST is installed, WAL segments older than the checkpoint are released (<code>wal.Manager.Remove</code>).</td></tr>
<tr><td><code>db.runRecoveryChecks</code></td><td>Ensures WAL directory invariants before manifest replay, similar to Badgerâ€™s directory bootstrap.</td></tr>
</tbody>
</table>
</div>
<hr>
<h2 id="5-metrics--observability"><a class="header" href="#5-metrics--observability">5. Metrics &amp; Observability</a></h2>
<p><code>Stats.collect</code> reads the manager metrics and exposes them as:</p>
<ul>
<li><code>NoKV.Stats.wal.active_segment</code></li>
<li><code>NoKV.Stats.wal.segment_count</code></li>
<li><code>NoKV.Stats.wal.segments_removed</code></li>
</ul>
<p>The CLI command <code>nokv stats --workdir &lt;dir&gt;</code> prints these alongside backlog, making WAL health visible without manual inspection. In high-throughput scenarios the active segment ID mirrors RocksDBâ€™s <code>LOG</code> number growth.</p>
<hr>
<h2 id="6-wal-watchdog-auto-gc"><a class="header" href="#6-wal-watchdog-auto-gc">6. WAL Watchdog (Auto GC)</a></h2>
<p>The WAL watchdog runs inside the DB process to keep WAL backlog in check and
surface warnings when raft-typed records dominate the log. It:</p>
<ul>
<li>Samples WAL metrics + per-segment metrics and combines them with
<code>manifest.RaftPointerSnapshot()</code> to compute removable segments.</li>
<li>Removes up to <code>WALAutoGCMaxBatch</code> segments when at least
<code>WALAutoGCMinRemovable</code> are eligible.</li>
<li>Exposes counters (<code>wal.auto_gc_runs/removed/last_unix</code>) and warning state
(<code>wal.typed_record_ratio/warning/reason</code>) through <code>StatsSnapshot.WAL</code>.</li>
</ul>
<p>Relevant options (see <code>options.go</code> for defaults):</p>
<ul>
<li><code>EnableWALWatchdog</code></li>
<li><code>WALAutoGCInterval</code></li>
<li><code>WALAutoGCMinRemovable</code></li>
<li><code>WALAutoGCMaxBatch</code></li>
<li><code>WALTypedRecordWarnRatio</code></li>
<li><code>WALTypedRecordWarnSegments</code></li>
</ul>
<hr>
<h2 id="7-recovery-walkthrough"><a class="header" href="#7-recovery-walkthrough">7. Recovery Walkthrough</a></h2>
<ol>
<li><code>wal.Open</code> reopens the highest segment, leaving the file pointer at the end (<code>switchSegmentLocked</code>).</li>
<li><code>manifest.Manager</code> supplies the WAL checkpoint (segment + offset) while building the version. Replay skips entries up to this checkpoint, ensuring we only reapply writes not yet materialised in SSTables.</li>
<li><code>wal.Manager.Replay</code> (invoked by the LSM recovery path) rebuilds memtables from entries newer than the manifest checkpoint. Value-log recovery only validates/truncates segments and does not reapply data.</li>
<li>If the final record is partially written, the CRC mismatch stops replay and the segment is truncated during recovery tests, mimicking RocksDBâ€™s tolerant behaviour.</li>
</ol>
<hr>
<h2 id="8-operational-tips"><a class="header" href="#8-operational-tips">8. Operational Tips</a></h2>
<ul>
<li>Configure <code>SyncOnWrite</code> for synchronous durability (default async like RocksDBâ€™s default). For latency-sensitive deployments, consider enabling to emulate Badgerâ€™s <code>SyncWrites</code>.</li>
<li>After large flushes, forcing <code>Rotate</code> keeps WAL files short, reducing replay time.</li>
<li>Archived WAL segments can be copied alongside manifest files for hot-backup strategiesâ€”since the manifest contains the WAL log number, snapshots behave like RocksDBâ€™s <code>Checkpoints</code>.</li>
</ul>
<hr>
<h2 id="9-truncation-metadata"><a class="header" href="#9-truncation-metadata">9. Truncation Metadata</a></h2>
<ul>
<li><code>raftstore/engine/wal_storage</code> keeps a per-group index of <code>[firstIndex,lastIndex]</code> spans for each WAL record so it can map raft log indices back to the segment that stored them.</li>
<li>When a log is truncated (either via snapshot or future compaction hooks), the manifest is updated via <code>LogRaftTruncate</code> with the index/term, segment ID (<code>RaftLogPointer.SegmentIndex</code>), and byte offset (<code>RaftLogPointer.TruncatedOffset</code>) that delimit the remaining WAL data.</li>
<li><code>lsm/levelManager.canRemoveWalSegment</code> now blocks garbage collection whenever any raft group still references a segment through its truncation metadata, preventing slow followers from losing required WAL history while letting aggressively compacted groups release older segments earlier.</li>
</ul>
<p>For broader context, read the <a href="#nokv-architecture-overview">architecture overview</a> and <a href="#memtable-flush-pipeline">flush pipeline</a> documents.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="value-log-vlog-design"><a class="header" href="#value-log-vlog-design">Value Log (vlog) Design</a></h1>
<p>NoKV keeps the LSM tree lean by separating large values into sequential <strong>value log</strong> (vlog) files. The module is split between</p>
<ul>
<li><a href="../vlog/manager.go"><code>vlog/manager.go</code></a> â€“ owns the open file set, rotation, and segment lifecycle helpers.</li>
<li><a href="../vlog/io.go"><code>vlog/io.go</code></a> â€“ append/read/iterate/verify/sample IO paths.</li>
<li><a href="../vlog.go"><code>vlog.go</code></a> â€“ integrates the manager with the DB write path, discard statistics, and garbage collection (GC).</li>
</ul>
<p>The design echoes BadgerDBâ€™s value log while remaining manifest-driven like RocksDBâ€™s <code>blob_db</code>: vlog metadata (head pointer, pending deletions) is persisted inside the manifest so recovery can reconstruct the exact state without scanning the filesystem.</p>
<hr>
<h2 id="1-layering-engine-view"><a class="header" href="#1-layering-engine-view">1. Layering (Engine View)</a></h2>
<p>The value log is split into three layers so IO can stay reusable while DB
policy lives in the core package:</p>
<ul>
<li><strong>DB policy layer (<code>vlog.go</code>, <code>vlog_gc.go</code>)</strong> â€“ integrates the manager with
the DB write path, persists vlog metadata in the manifest, and drives GC
scheduling based on discard stats.</li>
<li><strong>Value-log manager (<code>vlog/</code>)</strong> â€“ owns segment lifecycle (open/rotate/remove),
encodes/decodes entries, and exposes append/read/sample APIs without touching
MVCC or LSM policy.</li>
<li><strong>File IO (<code>file/</code>)</strong> â€“ mmap-backed <code>LogFile</code> primitives (open/close/truncate,
read/write, read-only remap) shared by WAL/vlog/SST. Vlog currently uses
<code>LogFile</code> directly instead of an intermediate store abstraction.</li>
</ul>
<hr>
<h2 id="2-directory-layout--naming"><a class="header" href="#2-directory-layout--naming">2. Directory Layout &amp; Naming</a></h2>
<pre><code class="language-text">&lt;workdir&gt;/
  vlog/
    bucket-000/
      00000.vlog
      00001.vlog
    bucket-001/
      00000.vlog
      00001.vlog
    ...
</code></pre>
<ul>
<li>Files are named <code>%05d.vlog</code> and live under <code>workdir/vlog/bucket-XXX/</code> when <code>Options.ValueLogBucketCount &gt; 1</code>. <a href="../vlog/manager.go"><code>Manager.populate</code></a> discovers existing segments at open.</li>
<li><code>Manager</code> tracks the active file ID (<code>activeID</code>) and byte offset; <a href="../vlog/manager.go"><code>Manager.Head</code></a> exposes these so the manifest can checkpoint them (<code>manifest.EditValueLogHead</code>).</li>
<li>Files created after a crash but never linked in the manifest are removed during <a href="../vlog.go"><code>valueLog.reconcileManifest</code></a>.</li>
<li>When HotRing routing is enabled (<code>ValueLogHotBucketCount</code> + <code>ValueLogHotKeyThreshold</code>), buckets are split into hot vs cold ranges to isolate update-heavy keys from GC pressure.</li>
</ul>
<hr>
<h2 id="3-record-format"><a class="header" href="#3-record-format">3. Record Format</a></h2>
<p>The vlog uses the shared encoding helper (<code>kv.EncodeEntryTo</code>), so entries written to the value log and the WAL are byte-identical.</p>
<pre><code>+--------+----------+------+-------------+-----------+-------+
| KeyLen | ValueLen | Meta | ExpiresAt   | Key bytes | Value |
+--------+----------+------+-------------+-----------+-------+
                                             + CRC32 (4 B)
</code></pre>
<ul>
<li>Header fields are varint-encoded (<code>kv.EntryHeader</code>).</li>
<li>The first 20 bytes of every segment are reserved (<code>kv.ValueLogHeaderSize</code>) for future metadata; iteration always skips this fixed header.</li>
<li><code>kv.EncodeEntry</code> and the entry iterator (<code>kv.EntryIterator</code>) perform the layout work, and each append finishes with a CRC32 to detect torn writes.</li>
<li><code>vlog.VerifyDir</code> scans all segments with <a href="../vlog/io.go"><code>sanitizeValueLog</code></a> to trim corrupted tails after crashes, mirroring RocksDBâ€™s <code>blob_file::Sanitize</code>. Badger performs a similar truncation pass at startup.</li>
</ul>
<hr>
<h2 id="4-manager-api-surface"><a class="header" href="#4-manager-api-surface">4. Manager API Surface</a></h2>
<pre><code class="language-go">mgr, _ := vlog.Open(vlog.Config{Dir: "...", MaxSize: 1&lt;&lt;29})
ptr, _ := mgr.AppendEntry(entry)
ptrs, _ := mgr.AppendEntries(entries, writeMask)
val, unlock, _ := mgr.Read(ptr)
unlock()             // release per-file lock
_ = mgr.Rewind(*ptr) // rollback partially written batch
_ = mgr.Remove(fid)  // close + delete file
</code></pre>
<p>Key behaviours:</p>
<ol>
<li><strong>Append + Rotate</strong> â€“ <a href="../vlog/io.go"><code>Manager.AppendEntry</code></a> encodes and appends into the active file. The reservation path handles rotation when the active segment would exceed <code>MaxSize</code>; manual rotation is rare.</li>
<li><strong>Crash recovery</strong> â€“ <a href="../vlog/manager.go"><code>Manager.Rewind</code></a> truncates the active file and removes newer files when a write batch fails mid-flight. <code>valueLog.write</code> uses this to guarantee idempotent WAL/value log ordering.</li>
<li><strong>Safe reads</strong> â€“ <a href="../vlog/io.go"><code>Manager.Read</code></a> returns an mmap-backed slice plus an unlock callback. Active segments take a per-file <code>RWMutex</code>, while sealed segments use a pin/unpin path to avoid long-held locks; callers that need ownership should copy the bytes before releasing the lock.</li>
<li><strong>Verification</strong> â€“ <a href="../vlog/io.go"><code>VerifyDir</code></a> validates entire directories (used by CLI and recovery) by parsing headers and CRCs.</li>
</ol>
<p>Compared with RocksDBâ€™s blob manager the surface is intentionally smallâ€”NoKV treats the manager as an append-only log with rewind semantics, while RocksDB maintains index structures inside the blob file metadata.</p>
<hr>
<h2 id="5-integration-with-db-writes"><a class="header" href="#5-integration-with-db-writes">5. Integration with DB Writes</a></h2>
<pre class="mermaid">sequenceDiagram
    participant Commit as commitWorker
    participant Mgr as vlog.Manager
    participant WAL as wal.Manager
    participant Mem as MemTable
    Commit-&gt;&gt;Mgr: AppendEntries(entries, writeMask)
    Mgr--&gt;&gt;Commit: ValuePtr list
    Commit-&gt;&gt;WAL: Append(entries+ptrs)
    Commit-&gt;&gt;Mem: apply to active memtable index
</pre>

<ol>
<li><a href="../vlog.go"><code>valueLog.write</code></a> builds a write mask for each batch, then delegates to <a href="../vlog/io.go"><code>Manager.AppendEntries</code></a>. Entries staying in LSM (<code>shouldWriteValueToLSM</code>) receive zero-value pointers.</li>
<li>Rotation is handled inside the manager when the reserved bytes would exceed <code>MaxSize</code>. The WAL append happens <strong>after</strong> the value log append so crash replay observes consistent pointers.</li>
<li>Any error triggers <code>Manager.Rewind</code> back to the saved head pointer, removing new files and truncating partial bytes. <a href="../vlog_test.go"><code>vlog_test.go</code></a> exercises both append- and rotate-failure paths.</li>
<li><code>Txn.Commit</code> and batched writes share the same pipeline: the commit worker always writes the value log first, then applies to WAL/memtable, keeping MVCC and durability ordering consistent.</li>
</ol>
<p>Badger follows the same ordering (value log first, then write batch). RocksDBâ€™s blob DB instead embeds blob references into the WAL entry before the blob file write, relying on two-phase commit between WAL and blob; NoKV avoids the extra coordination by reusing a single batching loop.</p>
<hr>
<h2 id="6-discard-statistics--gc"><a class="header" href="#6-discard-statistics--gc">6. Discard Statistics &amp; GC</a></h2>
<pre class="mermaid">flowchart LR
  Compaction -- "obsolete ptrs" --&gt; DiscardStats
  DiscardStats --&gt;|"batch json"| writeCh
  valuePtr["valueLog.newValuePtr(lfDiscardStatsKey)"]
  writeCh --&gt; valuePtr
  valueLog -- "GC trigger" --&gt; Manager

</pre>

<ul>
<li><code>lfDiscardStats</code> aggregates per-file discard counts from LSM compaction workers (<code>lsm/executor.go</code>, <code>subcompact</code> -&gt; <code>updateDiscardStats</code>). Once the in-memory counter crosses <a href="../vlog.go#L27"><code>discardStatsFlushThreshold</code></a>, it marshals the map into JSON and writes it back through the DB pipeline under the special key <code>!NoKV!discard</code>.</li>
<li><code>valueLog.flushDiscardStats</code> consumes those stats, ensuring they are persisted even across crashes. During recovery <code>valueLog.populateDiscardStats</code> replays the JSON payload to repopulate the in-memory map.</li>
<li>GC uses <code>discardRatio = discardedBytes/totalBytes</code> derived from <a href="../vlog/io.go"><code>Manager.Sample</code></a>, which applies windowed iteration based on configurable ratios. If a file exceeds the configured threshold, <a href="../vlog_gc.go"><code>valueLog.doRunGC</code></a> rewrites live entries into the current head via <code>db.batchSet</code> (the normal commit pipeline) and then <a href="../vlog_gc.go"><code>valueLog.rewrite</code></a> triggers manifest delete edits through <code>removeValueLogFile</code>.
<ul>
<li>Sampling behaviour is controlled by <code>Options.ValueLogGCSampleSizeRatio</code> (default 0.10 of the file) and <code>Options.ValueLogGCSampleCountRatio</code> (default 1% of the configured entry limit). Setting either to <code>&lt;=0</code> keeps the default heuristics. <code>Options.ValueLogGCSampleFromHead</code> starts sampling from the beginning instead of a random window.</li>
</ul>
</li>
<li>Completed deletions are logged via <code>lsm.LogValueLogDelete</code> so the manifest can skip them during replay. When GC rotates to a new head, <code>valueLog.updateHead</code> records the pointer and increments <code>NoKV.Stats.value_log.gc.head_updates</code>.</li>
</ul>
<p>RocksDBâ€™s blob GC leans on compaction iterators to discover obsolete blobs. NoKV, like Badger, leverages flush/compaction discard stats so GC does not need to rescan SSTs.</p>
<hr>
<h2 id="7-gc-scheduling--parallelism"><a class="header" href="#7-gc-scheduling--parallelism">7. GC Scheduling &amp; Parallelism</a></h2>
<p>NoKV runs value-log GC with <strong>bucket-aware parallelism</strong> while protecting the LSM from overload:</p>
<ul>
<li><code>ValueLogGCParallelism</code> controls the maximum number of concurrent GC tasks. When set to <code>&lt;= 0</code>, it auto-tunes to <code>max(NumCompactors/2, 1)</code> and is capped by the bucket count.</li>
<li>Each bucket has a lock-free guard, so <strong>no two GC jobs run in the same bucket</strong> at once.</li>
<li>A lightweight semaphore limits total concurrency without blocking the GC scheduler thread.</li>
</ul>
<h3 id="pressure-aware-throttling"><a class="header" href="#pressure-aware-throttling">Pressure-aware throttling</a></h3>
<p>Compaction backlog and score feed into the GC scheduler:</p>
<ul>
<li><strong>Reduce</strong>: when compaction backlog or max score crosses <code>ValueLogGCReduceBacklog</code> / <code>ValueLogGCReduceScore</code>, GC parallelism is halved.</li>
<li><strong>Skip</strong>: when compaction backlog or max score crosses <code>ValueLogGCSkipBacklog</code> / <code>ValueLogGCSkipScore</code>, GC is skipped for that tick.</li>
</ul>
<p>This keeps GC throughput high under light load but avoids compaction starvation under pressure.</p>
<hr>
<h2 id="8-recovery-semantics"><a class="header" href="#8-recovery-semantics">8. Recovery Semantics</a></h2>
<ol>
<li><code>DB.Open</code> restores the manifest and fetches the last persisted head pointer.</li>
<li><a href="../vlog.go"><code>valueLog.open</code></a> launches <code>flushDiscardStats</code> and iterates every vlog file via <a href="../vlog.go"><code>valueLog.replayLog</code></a>. Files marked invalid in the manifest are removed; valid ones are registered in the managerâ€™s file map.</li>
<li><code>valueLog.replayLog</code> streams entries to validate checksums and trims torn tails; it does <strong>not</strong> reapply data into the LSM. WAL replay remains the sole source of committed state.</li>
<li><code>Manager.VerifyDir</code> trims torn records so replay never sees corrupt payloads.</li>
<li>After validation, <code>valueLog.populateDiscardStats</code> rehydrates discard counters from the persisted JSON entry if present.</li>
</ol>
<p>The flow mirrors Badgerâ€™s vlog scanning but keeps state reconstruction anchored on WAL + manifest checkpoints, similar to RocksDBâ€™s reliance on <code>MANIFEST</code> to mark blob files live or obsolete.</p>
<hr>
<h2 id="9-observability--cli"><a class="header" href="#9-observability--cli">9. Observability &amp; CLI</a></h2>
<ul>
<li>Metrics in <a href="../stats.go"><code>stats.go</code></a> report segment counts, pending deletions, discard queue depth, and GC head pointer via <code>expvar</code>.</li>
<li>GC scheduling exposes <code>NoKV.Stats.value_log.gc</code> (including <code>gc_parallelism</code>, <code>gc_active</code>, <code>gc_scheduled</code>, <code>gc_throttled</code>, <code>gc_skipped</code>, <code>gc_rejected</code>) for diagnostics.</li>
<li><code>nokv vlog --workdir &lt;dir&gt;</code> loads a manager in read-only mode and prints current head plus file status (valid, gc candidate). It invokes <a href="../vlog/io.go"><code>vlog.VerifyDir</code></a> before describing segments.</li>
<li>Recovery traces controlled by <code>RECOVERY_TRACE_METRICS</code> log every head movement and file removal, aiding pressure testing of GC edge cases. For ad-hoc diagnostics, enable <code>Options.ValueLogVerbose</code> to emit replay/GC messages to stdout.</li>
</ul>
<hr>
<h2 id="10-quick-comparison"><a class="header" href="#10-quick-comparison">10. Quick Comparison</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Capability</th><th>RocksDB BlobDB</th><th>BadgerDB</th><th>NoKV</th></tr>
</thead>
<tbody>
<tr><td>Head tracking</td><td>In MANIFEST (blob log number + offset)</td><td>Internal to vlog directory</td><td>Manifest entry via <code>EditValueLogHead</code></td></tr>
<tr><td>GC trigger</td><td>Compaction sampling, blob garbage score</td><td>Discard stats from LSM tables</td><td>Discard stats flushed through <code>lfDiscardStats</code></td></tr>
<tr><td>Failure recovery</td><td>Blob DB and WAL coordinate two-phase commits</td><td>Replays value log then LSM</td><td>Rewind-on-error + manifest-backed deletes</td></tr>
<tr><td>Read path</td><td>Separate blob cache</td><td>Direct read + checksum</td><td><code>Manager.Read</code> with copy + per-file lock</td></tr>
</tbody>
</table>
</div>
<p>By anchoring the vlog state in the manifest and exposing rewind/verify primitives, NoKV maintains the determinism of RocksDB while keeping Badgerâ€™s simple sequential layout.</p>
<hr>
<h2 id="11-further-reading"><a class="header" href="#11-further-reading">11. Further Reading</a></h2>
<ul>
<li><a href="#value-log-recovery"><code>docs/recovery.md</code></a> â€“ failure matrix covering append crashes, GC interruptions, and manifest rewrites.</li>
<li><a href="#value-pointer-reads"><code>docs/cache.md</code></a> â€“ how vlog-backed entries interact with the block cache.</li>
<li><a href="#value-log-metrics"><code>docs/stats.md</code></a> â€“ metric names surfaced for monitoring.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="manifest--version-management"><a class="header" href="#manifest--version-management">Manifest &amp; Version Management</a></h1>
<p>The manifest keeps the source of truth for SST files, WAL checkpoints, and ValueLog heads. NoKVâ€™s implementation (<code>manifest/manager.go</code>, <code>manifest/codec.go</code>, <code>manifest/types.go</code>) borrows RocksDBâ€™s <code>VersionEdit + CURRENT</code> pattern while adding metadata required for value separation.</p>
<hr>
<h2 id="1-file-layout"><a class="header" href="#1-file-layout">1. File Layout</a></h2>
<pre><code class="language-text">WorkDir/
  CURRENT             # stores the active MANIFEST file name
  MANIFEST-000001     # log of manifest edits
  MANIFEST-000002     # newer file after rewrite
</code></pre>
<ul>
<li><code>CURRENT</code> is atomically swapped via <code>CURRENT.tmp</code> â†’ <code>CURRENT</code> rename.</li>
<li>Each <code>MANIFEST-*</code> contains a series of binary edits prefixed by the magic string <code>"NoKV"</code> (encoding lives in <code>manifest/codec.go</code>).</li>
<li>During <code>manifest.Open</code>, <code>loadCurrent</code> opens the file referenced by CURRENT; if missing, <code>createNew</code> bootstraps an empty manifest.</li>
</ul>
<hr>
<h2 id="2-edit-types"><a class="header" href="#2-edit-types">2. Edit Types</a></h2>
<pre><code class="language-go">type EditType uint8
const (
    EditAddFile EditType = iota
    EditDeleteFile
    EditLogPointer
    EditValueLogHead
    EditDeleteValueLog
    EditUpdateValueLog
    EditRaftPointer
    EditRegion
)
</code></pre>
<p>Each edit serialises one logical action:</p>
<ul>
<li><code>EditAddFile</code> / <code>EditDeleteFile</code> â€“ manage SST metadata (<code>FileMeta</code>: level, fileID, size, key bounds, timestamps).</li>
<li><code>EditLogPointer</code> â€“ persists the latest WAL segment + offset checkpoint, analogous to RocksDBâ€™s <code>log_number</code> and <code>prev_log_number</code> fields.</li>
<li><code>EditValueLogHead</code> â€“ records the head pointer for vlog append, ensuring recovery resumes from the correct file/offset.</li>
<li><code>EditDeleteValueLog</code> â€“ marks a vlog segment logically deleted (GC has reclaimed it).</li>
<li><code>EditUpdateValueLog</code> â€“ updates metadata for an existing vlog file (used when GC rewrites a segment).</li>
<li><code>EditRaftPointer</code> â€“ persists raft-group WAL progress (segment, offset, applied/truncated index &amp; term, etc.).</li>
<li><code>EditRegion</code> â€“ persists Region metadata (key range, epoch, peers, lifecycle state).</li>
</ul>
<p><code>manifest.Manager.apply</code> interprets each edit and updates the in-memory <code>Version</code> structure, which is consumed by LSM initialisation and value log recovery.</p>
<hr>
<h2 id="3-version-structure"><a class="header" href="#3-version-structure">3. Version Structure</a></h2>
<pre><code class="language-go">type Version struct {
    Levels       map[int][]FileMeta
    LogSegment   uint32
    LogOffset    uint64
    ValueLogs    map[uint32]ValueLogMeta
    ValueLogHead ValueLogMeta
    RaftPointers map[uint64]RaftLogPointer
    Regions      map[uint64]RegionMeta
}
</code></pre>
<ul>
<li><code>Levels</code> mirrors the LSM tree levels; during recovery <code>lsm.LSM</code> loads files per level.</li>
<li><code>LogSegment</code>/<code>LogOffset</code> ensure WAL replay starts exactly where persistent state ended.</li>
<li><code>ValueLogs</code> holds metadata for every known vlog file; <code>ValueLogHead</code> caches the active head for quick access.</li>
</ul>
<p>Compared with RocksDB: RocksDBâ€™s manifest stores blob file metadata when <code>BlobDB</code> is enabled. NoKV integrates vlog metadata natively to avoid a separate blob manifest.</p>
<hr>
<h2 id="4-lifecycle"><a class="header" href="#4-lifecycle">4. Lifecycle</a></h2>
<pre class="mermaid">sequenceDiagram
    participant DB
    participant Manifest
    participant CURRENT
    DB-&gt;&gt;Manifest: Open(dir)
    Manifest-&gt;&gt;CURRENT: read file name
    Manifest-&gt;&gt;Manifest: replay edits â†’ Version
    DB-&gt;&gt;Manifest: LogEdit(EditAddFile+LogPointer)
    Manifest-&gt;&gt;Manifest: append edit
    Manifest--&gt;&gt;DB: updated Version
    Note over Manifest,CURRENT: On rewrite -&gt; write tmp -&gt; rename CURRENT
</pre>

<ul>
<li><strong>Open/Rebuild</strong> â€“ <code>replay</code> reads all edits, applying them sequentially (<code>bufio.Reader</code> ensures streaming). If any edit fails to decode, recovery aborts so operators can inspect the manifest, similar to RocksDBâ€™s strictness.</li>
<li><strong>LogEdit</strong> â€“ obtains the mutex, appends the encoded edit, flushes, and updates the in-memory <code>Version</code> before returning.</li>
<li><strong>Rewrite</strong> â€“ when the manifest grows beyond <code>Options.ManifestRewriteThreshold</code>, the manager writes a new <code>MANIFEST-xxxxxx</code> containing a full snapshot of the current <code>Version</code>, fsyncs it, updates <code>CURRENT</code>, and removes the old file. This mirrors RocksDBâ€™s <code>max_manifest_file_size</code> behavior while keeping recovery simple.</li>
<li><strong>Close</strong> â€“ flushes and closes the underlying file handle; the version stays available for introspection via <code>Manager.Version()</code> (used by CLI).</li>
</ul>
<hr>
<h2 id="5-interaction-with-other-modules"><a class="header" href="#5-interaction-with-other-modules">5. Interaction with Other Modules</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Module</th><th>Manifest usage</th></tr>
</thead>
<tbody>
<tr><td><code>lsm</code></td><td><code>installLevel0Table</code> logs <code>EditAddFile</code> + <code>EditLogPointer</code> to checkpoint WAL progress. Compaction deletes old files via <code>EditDeleteFile</code>.</td></tr>
<tr><td><code>wal</code></td><td>Manifestâ€™s log pointer tells WAL replay where to resume.</td></tr>
<tr><td><code>vlog</code></td><td><code>valueLog.rewrite</code> writes <code>EditUpdateValueLog</code> / <code>EditDeleteValueLog</code> after GC, ensuring stale segments are not reopened.</td></tr>
<tr><td><code>CLI</code></td><td><code>nokv manifest</code> reads <code>manifest.Manager.Version()</code> and prints levels, vlog head, and deletion status.</td></tr>
</tbody>
</table>
</div>
<p>Badger keeps a separate <code>value.log</code> directory without manifest-level bookkeeping; NoKVâ€™s integrated manifest avoids scanning the filesystem during recovery.</p>
<hr>
<h2 id="6-recovery-scenarios"><a class="header" href="#6-recovery-scenarios">6. Recovery Scenarios</a></h2>
<ol>
<li><strong>Missing SST file</strong> â€“ if <code>MANIFEST</code> references <code>000123.sst</code> but the file is absent, <code>db_recovery_test.go::TestRecoveryCleansMissingSSTFromManifest</code> verifies that recovery removes the edit, mimicking RocksDBâ€™s lost table handling.</li>
<li><strong>ValueLog deletion</strong> â€“ <code>TestRecoveryRemovesStaleValueLogSegment</code> ensures <code>EditDeleteValueLog</code> entries trigger file removal during recovery.</li>
<li><strong>Manifest rewrite crash</strong> â€“ <code>TestRecoveryManifestRewriteCrash</code> simulates a crash after writing the new manifest but before updating <code>CURRENT</code>; recovery still points to the old manifest and resumes safely, exactly like RocksDBâ€™s two-phase rewrite.</li>
<li><strong>Stale WAL pointer</strong> â€“ WAL replay respects <code>LogSegment/Offset</code>; tests cover truncated WALs to confirm idempotency.</li>
</ol>
<hr>
<h2 id="7-cli-output"><a class="header" href="#7-cli-output">7. CLI Output</a></h2>
<p><code>nokv manifest --workdir &lt;dir&gt; --json</code> prints:</p>
<ul>
<li>Level file counts and key ranges.</li>
<li><code>wal_log_segment</code> / <code>wal_log_offset</code> checkpoint.</li>
<li><code>value_log_head</code> metadata.</li>
<li>List of vlog files with <code>valid</code> status (mirroring RocksDBâ€™s blob file dump).</li>
</ul>
<p>This structured output enables automated validation in CI and ad-hoc audits.</p>
<hr>
<h2 id="8-extensibility"><a class="header" href="#8-extensibility">8. Extensibility</a></h2>
<ul>
<li><strong>Column families</strong> â€“ add a column family identifier to <code>FileMeta</code> and extend edits accordingly, as RocksDB does.</li>
<li><strong>Snapshots</strong> â€“ persistent snapshots can be derived from manifest versions (keep a copy of the current Version and WAL pointer).</li>
<li><strong>Remote manifests</strong> â€“ similar to RocksDBâ€™s remote compaction, storing manifests in object storage is straightforward because edits are append-only.</li>
</ul>
<p>For end-to-end recovery context, see <a href="#crash-recovery-playbook">recovery.md</a> and the <a href="#nokv-architecture-overview">architecture overview</a>.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="file-abstractions"><a class="header" href="#file-abstractions">File Abstractions</a></h1>
<p>The <code>file</code> package encapsulates direct file-system interaction for WAL, SST, and value-log files. It provides portable mmap helpers, allocation primitives, and log file wrappers.</p>
<hr>
<h2 id="1-core-types"><a class="header" href="#1-core-types">1. Core Types</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Type</th><th>Purpose</th><th>Key Methods</th></tr>
</thead>
<tbody>
<tr><td><a href="../file/file.go#L5-L16"><code>Options</code></a></td><td>Parameter bag for opening files (FID, path, size).</td><td>Used by WAL/vlog managers.</td></tr>
<tr><td><a href="../file/file.go#L18-L27"><code>CoreFile</code></a></td><td>Interface abstracting platform-specific operations.</td><td><code>NewReader</code>, <code>Bytes</code>, <code>Sync</code>, <code>Delete</code>.</td></tr>
<tr><td><a href="../file/mmap_linux.go#L12-L98"><code>MmapFile</code></a></td><td>Cross-platform mmap wrapper.</td><td><code>OpenMmapFile</code>, <code>AppendBuffer</code>, <code>Truncature</code>, <code>Sync</code>.</td></tr>
<tr><td><a href="../file/vlog.go#L16-L130"><code>LogFile</code></a></td><td>Value-log specific helper built on <code>MmapFile</code>.</td><td><code>Open</code>, <code>Write</code>, <code>Read</code>, <code>DoneWriting</code>, <code>EncodeEntry</code>.</td></tr>
</tbody>
</table>
</div>
<p>Darwin-specific builds live alongside (<code>mmap_darwin.go</code>, <code>sstable_darwin.go</code>) ensuring the package compiles on macOS without manual tuning.</p>
<hr>
<h2 id="2-mmap-management"><a class="header" href="#2-mmap-management">2. Mmap Management</a></h2>
<ul>
<li><code>OpenMmapFile</code> opens or creates a file, optionally extending it to <code>maxSz</code>, then mmaps it. The returned <code>MmapFile</code> exposes <code>Data []byte</code> and the underlying <code>*os.File</code> handle.</li>
<li>Writes grow the map on demand: <code>AppendBuffer</code> checks if the write would exceed the current mapping and calls <code>Truncature</code> to expand (doubling up to 1 GiB increments).</li>
<li><code>Sync</code> flushes dirty pages (<code>mmap.Msync</code>), while <code>Delete</code> unmaps, truncates, closes, and removes the fileâ€”used when dropping SSTs or value-log segments.</li>
</ul>
<p>RocksDB relies on custom Env implementations for portability; NoKV keeps the logic in Go, relying on build tags for OS differences.</p>
<hr>
<h2 id="3-logfile-semantics"><a class="header" href="#3-logfile-semantics">3. LogFile Semantics</a></h2>
<p><code>LogFile</code> wraps <code>MmapFile</code> to simplify value-log operations:</p>
<pre><code class="language-go">lf := &amp;file.LogFile{}
_ = lf.Open(&amp;file.Options{FID: 1, FileName: "00001.vlog", MaxSz: 1&lt;&lt;29})
ptr, _ := lf.EncodeEntry(entry, buf, offset)
_ = lf.Write(offset, buf.Bytes())
_ = lf.DoneWriting(nextOffset)
</code></pre>
<ul>
<li><code>Open</code> mmaps the file and records current size (guarded to <code>&lt; 4 GiB</code>).</li>
<li><code>Read</code> validates offsets against both the mmap length and tracked size, preventing partial reads when GC or drop operations shrink the file.</li>
<li><code>EncodeEntry</code> uses the shared <code>kv.EntryHeader</code> and CRC32 helpers to produce the exact on-disk layout consumed by <code>vlog.Manager</code> and <code>wal.Manager</code>.</li>
<li><code>DoneWriting</code> syncs, truncates to the provided offset, reinitialises the mmap, and keeps the file open in read-write modeâ€”supporting subsequent appends.</li>
<li><code>Rewind</code> (via <code>vlog.Manager.Rewind</code>) leverages <code>LogFile.Truncate</code> and <code>Init</code> to roll back partial batches after errors.</li>
</ul>
<hr>
<h2 id="4-sst-helpers"><a class="header" href="#4-sst-helpers">4. SST Helpers</a></h2>
<p>While SSTable builders/readers live under <code>lsm/table.go</code>, they rely on <code>file</code> helpers to map index/data blocks efficiently. The build tags (<code>sstable_linux.go</code>, <code>sstable_darwin.go</code>) provide OS-specific tuning for direct I/O hints or mmap flags.</p>
<hr>
<h2 id="5-comparison-1"><a class="header" href="#5-comparison-1">5. Comparison</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Engine</th><th>Approach</th></tr>
</thead>
<tbody>
<tr><td>RocksDB</td><td>C++ Env &amp; random-access file wrappers.</td></tr>
<tr><td>Badger</td><td><code>y.File</code> abstraction with mmap.</td></tr>
<tr><td>NoKV</td><td>Go-native mmap wrappers with explicit log helpers.</td></tr>
</tbody>
</table>
</div>
<p>By keeping all filesystem primitives in one package, NoKV ensures WAL, vlog, and SST layers share consistent behaviour (sync semantics, truncation rules) and simplifies testing (<code>mmap_linux_test.go</code>).</p>
<hr>
<h2 id="6-operational-notes-1"><a class="header" href="#6-operational-notes-1">6. Operational Notes</a></h2>
<ul>
<li>Value-log and WAL segments rely on <code>DoneWriting</code>/<code>Truncate</code> to seal files; avoid manipulating files externally or mmap metadata may desynchronise.</li>
<li><code>LogFile.AddSize</code> updates the cached size used by readsâ€”critical when rewinding or rewriting segments.</li>
<li><code>SyncDir</code> (see <code>mmap_linux.go</code>) is invoked when new files are created to persist directory entries, similar to RocksDBâ€™s <code>Env::FsyncDir</code>.</li>
</ul>
<p>For more on how these primitives plug into higher layers, see <a href="#wal-subsystem"><code>docs/wal.md</code></a> and <a href="#value-log-vlog-design"><code>docs/vlog.md</code></a>.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="cache--bloom-filters"><a class="header" href="#cache--bloom-filters">Cache &amp; Bloom Filters</a></h1>
<p>NoKVâ€™s LSM tier layers a multi-level block cache with bloom filter caching to accelerate lookups. The implementation is in <a href="../lsm/cache.go"><code>lsm/cache.go</code></a>.</p>
<hr>
<h2 id="1-components"><a class="header" href="#1-components">1. Components</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Component</th><th>Purpose</th><th>Source</th></tr>
</thead>
<tbody>
<tr><td><code>cache.indexs</code></td><td>Table index cache (<code>fid</code> â†’ <code>*pb.TableIndex</code>) reused across reopen.</td><td><a href="../utils/cache"><code>utils/cache</code></a></td></tr>
<tr><td><code>blockCache</code></td><td>Ristretto-based block cache (L0/L1 only) with per-table direct slots.</td><td><a href="../lsm/cache.go"><code>lsm/cache.go</code></a></td></tr>
<tr><td><code>bloomCache</code></td><td>LRU cache of bloom filter bitsets per SST.</td><td><a href="../lsm/cache.go"><code>lsm/cache.go</code></a></td></tr>
<tr><td><code>cacheMetrics</code></td><td>Atomic hit/miss counters for L0/L1 blocks and blooms.</td><td><a href="../lsm/cache.go#L30-L110"><code>lsm/cache.go#L30-L110</code></a></td></tr>
</tbody>
</table>
</div>
<p>Badger uses a similar block cache split (<code>Pinner</code>/<code>Cache</code>) while RocksDB exposes block cache(s) via the <code>BlockBasedTableOptions</code>. NoKV keeps it Go-native and GC-friendly.</p>
<hr>
<h3 id="11-index-cache--handles"><a class="header" href="#11-index-cache--handles">1.1 Index Cache &amp; Handles</a></h3>
<ul>
<li>SSTable metadata stays with the <code>table</code> struct, while decoded protobuf indexes are stored in <code>cache.indexs</code>. Lookups first hit the cache before falling back to disk.</li>
<li>SST handles are reopened on demand for lower levels. L0/L1 tables keep their file descriptors pinned, while deeper levels close them once no iterator is using the table.</li>
</ul>
<hr>
<h2 id="2-block-cache-strategy"><a class="header" href="#2-block-cache-strategy">2. Block Cache Strategy</a></h2>
<pre><code class="language-text">User-space block cache (L0/L1, parsed blocks, Ristretto LFU-ish)
Deeper levels rely on OS page cache + mmap readahead
</code></pre>
<ul>
<li><code>Options.BlockCacheSize</code> sets capacity in <strong>blocks</strong> (cost=1 per block). Entries keep parsed blocks (data slice + offsets/baseKey/checksum), so hits avoid re-parsing.</li>
<li>Per-table direct slots (<code>table.cacheSlots[idx]</code>) give a lock-free fast path. Misses fall back to the shared Ristretto cache (approx LFU with admission).</li>
<li>Evictions clear the table slot via <code>OnEvict</code>; user-space cache only tracks L0/L1 blocks. Deeper levels depend on the OS page cache.</li>
<li>Access patterns: <code>getBlock</code> also updates hit/miss metrics for L0/L1; deeper levels bypass the cache and do not affect metrics.</li>
</ul>
<pre class="mermaid">flowchart LR
  Read --&gt; CheckCache
  CheckCache --&gt;|hit| Return
  CheckCache --&gt;|miss| LoadFromTable["LoadFromTable (mmap + OS page cache)"]
  LoadFromTable --&gt; InsertCache
  InsertCache --&gt; Return
</pre>

<p>By default only L0 and L1 blocks are cached (<code>level &gt; 1</code> short-circuits), reflecting the higher re-use for top levels.</p>
<hr>
<h2 id="3-bloom-cache"><a class="header" href="#3-bloom-cache">3. Bloom Cache</a></h2>
<ul>
<li><code>bloomCache</code> stores the raw filter bitset (<code>utils.Filter</code>) per table ID. Entries are deep-copied (<code>SafeCopy</code>) to avoid sharing memory with mmaps.</li>
<li>Cache policy is LRU.</li>
<li>Capacity is controlled by <code>Options.BloomCacheSize</code>.</li>
<li>Bloom hits/misses are recorded via <code>cacheMetrics.recordBloom</code>, feeding into <code>StatsSnapshot.Cache.BloomHitRate</code>.</li>
</ul>
<hr>
<h2 id="4-metrics--observability"><a class="header" href="#4-metrics--observability">4. Metrics &amp; Observability</a></h2>
<p><code>cache.metricsSnapshot()</code> produces:</p>
<pre><code class="language-go">type CacheMetrics struct {
    L0Hits, L0Misses uint64
    L1Hits, L1Misses uint64
    BloomHits, BloomMisses uint64
    IndexHits, IndexMisses uint64
}
</code></pre>
<p><code>Stats.Snapshot</code> converts these into hit rates. Monitor them alongside the block cache sizes to decide when to scale memory.</p>
<hr>
<h2 id="5-hotring-integration"><a class="header" href="#5-hotring-integration">5. HotRing Integration</a></h2>
<ul>
<li>Hot detection: HotRing counts on read/write paths and triggers targeted prefetch for hot keys.</li>
<li>Cache warmup: prefetch loads target blocks into the normal L0/L1 block cache path.</li>
<li>Compaction coupling: HotRing top-k feeds compaction scoring; levels/ingest shards covering hot ranges get higher scores to trim overlap sooner.</li>
<li>Tuning: Hot thresholds come from HotRing options (window/decay configurable).</li>
</ul>
<hr>
<h2 id="6-interaction-with-value-log"><a class="header" href="#6-interaction-with-value-log">6. Interaction with Value Log</a></h2>
<ul>
<li>Keys stored as value pointers (large values) still populate block cache entries for the key/index block. The value payload is read directly from the vlog (<code>valueLog.read</code>), so block cache hit rates remain meaningful.</li>
<li>Discard stats from flushes can demote cached blocks via <code>cache.dropBlock</code>, ensuring obsolete SST data leaves the cache quickly.</li>
</ul>
<hr>
<h2 id="7-comparison"><a class="header" href="#7-comparison">7. Comparison</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Feature</th><th>RocksDB</th><th>BadgerDB</th><th>NoKV</th></tr>
</thead>
<tbody>
<tr><td>Block cache policy</td><td>Configurable multiple caches</td><td>Single cache</td><td>Ristretto for L0/L1 + OS page cache for deeper levels</td></tr>
<tr><td>Bloom cache</td><td>Enabled per table, no explicit cache</td><td>Optional</td><td>Dedicated LRU storing filters</td></tr>
<tr><td>Metrics</td><td>Block cache stats via <code>GetAggregatedIntProperty</code></td><td>Limited</td><td><code>NoKV.Stats.cache.*</code> hit rates</td></tr>
</tbody>
</table>
</div>
<hr>
<h2 id="8-operational-tips-1"><a class="header" href="#8-operational-tips-1">8. Operational Tips</a></h2>
<ul>
<li>If bloom hit rate falls below ~60%, consider increasing bits-per-key or Bloom cache size.</li>
<li>Track <code>nokv stats --json</code> cache metrics over time; drops often indicate iterator misuse or working-set shifts.</li>
</ul>
<p>More on SST layout lives in <a href="#manifest--version-management"><code>docs/manifest.md</code></a> and <a href="#4-read-path--iterators"><code>docs/architecture.md</code></a>.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="hotring--hot-key-tracking"><a class="header" href="#hotring--hot-key-tracking">HotRing â€“ Hot Key Tracking</a></h1>
<p><code>hotring</code> is NoKVâ€™s hot-key tracker. It samples read/write access frequency per key and exposes the hottest entries to the stats subsystem and CLI. The implementation lives in the standalone module <a href="https://github.com/feichai0017/hotring"><code>github.com/feichai0017/hotring</code></a>.</p>
<hr>
<h2 id="1-motivation"><a class="header" href="#1-motivation">1. Motivation</a></h2>
<ul>
<li><strong>Cache hints</strong> â€“ <code>DB.prefetchLoop</code> (see <a href="../db.go"><code>db.go</code></a>) consumes hot keys to schedule asynchronous reads into the block cache.</li>
<li><strong>Operational insight</strong> â€“ <code>StatsSnapshot.Hot.ReadKeys</code> and <code>nokv stats --json</code> surface the hottest keys, aiding debugging of traffic hotspots.</li>
<li><strong>Throttling</strong> â€“ <code>HotRing.TouchAndClamp</code> enables simple rate caps: once a key crosses a threshold, callers can back off or log alerts.</li>
</ul>
<p>Compared with RocksDB (which exposes block access stats via <code>perf_context</code>) and Badger (which lacks built-in hot-key reporting), NoKV offers a lightweight but concurrent-friendly tracker out of the box.</p>
<hr>
<h2 id="2-data-structure"><a class="header" href="#2-data-structure">2. Data Structure</a></h2>
<pre><code class="language-text">HotRing
  buckets[] -&gt; per-bucket lock-free linked list (Node)
  hashFn   -&gt; hash(key) -&gt; uint32
  hashMask -&gt; selects bucket (power of two size)
</code></pre>
<ul>
<li>Each bucket stores a sorted linked list of <a href="https://github.com/feichai0017/hotring/blob/main/node.go"><code>Node</code></a> ordered by <code>(tag, key)</code>, where <code>tag</code> is derived from the upper bits of the hash. Head pointers are <code>atomic.Pointer[Node]</code>, so readers walk the list without taking locks; writers use CAS to splice nodes while preserving order.</li>
<li><code>defaultTableBits = 12</code> â†’ 4096 buckets by default (<code>NewHotRing</code>). The mask ensures cheap modulo operations.</li>
<li>Nodes keep a <code>count</code> (int32) updated atomically and a <code>next</code> pointer stored via <code>unsafe.Pointer</code>. Sliding-window state is guarded by a tiny per-node spin lock instead of a process-wide mutex.</li>
</ul>
<pre class="mermaid">flowchart LR
  Key(key) --&gt;|hash| Bucket["buckets[index] (atomic head)"]
  Bucket --&gt; Node1
  Node1 --&gt; Node2
  Node2 --&gt; Node3
  Node3 --&gt; Nil[(nil)]
</pre>

<hr>
<h2 id="3-core-operations"><a class="header" href="#3-core-operations">3. Core Operations</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Method</th><th>Behaviour</th><th>Notes</th></tr>
</thead>
<tbody>
<tr><td><a href="https://github.com/feichai0017/hotring/blob/main/hotring.go"><code>Touch</code></a></td><td>Insert or increment keyâ€™s counter.</td><td>CAS-splices a new node if missing, then increments (window-aware when enabled).</td></tr>
<tr><td><a href="https://github.com/feichai0017/hotring/blob/main/hotring.go"><code>Frequency</code></a></td><td>Read-only counter lookup.</td><td>Lock-free lookup; uses sliding-window totals when configured.</td></tr>
<tr><td><a href="https://github.com/feichai0017/hotring/blob/main/hotring.go"><code>TouchAndClamp</code></a></td><td>Increment unless <code>count &gt;= limit</code>, returning <code>(count, limited)</code>.</td><td>Throttling follows sliding-window totals so hot bursts clamp quickly.</td></tr>
<tr><td><a href="https://github.com/feichai0017/hotring/blob/main/hotring.go"><code>TopN</code></a></td><td>Snapshot hottest keys sorted by count desc.</td><td>Walks buckets without locks, then sorts a copy.</td></tr>
<tr><td><a href="https://github.com/feichai0017/hotring/blob/main/hotring.go"><code>KeysAbove</code></a></td><td>Return all keys with counters â‰¥ threshold.</td><td>Handy for targeted throttling or debugging hot shards.</td></tr>
</tbody>
</table>
</div>
<p>Bucket ordering is preserved by <code>findOrInsert</code>, which CASes either the bucket head or the predecessorâ€™s <code>next</code> pointer to splice new nodes. Reads never take locks; only per-node sliding-window updates spin briefly to avoid data races.</p>
<hr>
<h2 id="4-integration-points-1"><a class="header" href="#4-integration-points-1">4. Integration Points</a></h2>
<ul>
<li><strong>DB reads</strong> â€“ <code>Txn.Get</code> and iterators call <code>db.recordRead</code>, which invokes <code>HotRing.Touch</code> on a <strong>read-only ring</strong> for every successful lookup.</li>
<li><strong>Write throttling &amp; hot batching</strong> â€“ writes are tracked by a <strong>write-only ring</strong>. When <code>Options.WriteHotKeyLimit &gt; 0</code>, writes use <code>TouchAndClamp</code> to enforce throttling; when throttling is disabled but <code>HotWriteBurstThreshold &gt; 0</code>, writes still <code>Touch</code> so hot batching can trigger.</li>
<li><strong>Stats</strong> â€“ <code>StatsSnapshot.Hot.ReadKeys</code> and <code>StatsSnapshot.Hot.WriteKeys</code> publish read/write hot keys. <code>expvar</code> exposes these under <code>NoKV.Stats.hot.read_keys</code> and <code>NoKV.Stats.hot.write_keys</code>.</li>
<li><strong>Caching</strong> â€“ hot reads trigger asynchronous prefetch into the normal L0/L1 block cache path.</li>
<li><strong>Value log routing</strong> â€“ a dedicated HotRing instance powers <strong>vlog hot/cold bucket routing</strong>. It tracks <em>write</em> hotness only (no read signal) to avoid polluting bucket selection. Hot keys are routed to hot buckets (<code>ValueLogHotBucketCount</code>) once <code>ValueLogHotKeyThreshold</code> is reached; cold keys go to the cold range.</li>
</ul>
<hr>
<h2 id="5-comparisons"><a class="header" href="#5-comparisons">5. Comparisons</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Engine</th><th>Approach</th></tr>
</thead>
<tbody>
<tr><td>RocksDB</td><td>External â€“ <code>TRACE</code> / <code>perf_context</code> requires manual sampling.</td></tr>
<tr><td>Badger</td><td>None built-in.</td></tr>
<tr><td>NoKV</td><td>In-process ring with expvar/CLI export and throttling helpers.</td></tr>
</tbody>
</table>
</div>
<p>The HotRing emphasises simplicity: lock-free bucket lists with atomic counters (plus optional per-node window tracking), avoiding sketches while staying light enough for hundreds of thousands of hot keys.</p>
<hr>
<h2 id="6-operational-tips"><a class="header" href="#6-operational-tips">6. Operational Tips</a></h2>
<ul>
<li><code>Options.HotRingTopK</code> controls how many keys show up in stats; default 16. Increase it when investigating workloads with broad hot sets.</li>
<li>Combine <code>TouchAndClamp</code> with request middleware to detect abusive tenants: when <code>limited</code> is true, log the key and latency impact.</li>
<li>Resetting the ring is as simple as instantiating a new <code>HotRing</code>â€”useful for benchmarks that require clean counters between phases.</li>
</ul>
<p>For end-to-end examples see <a href="#hot-key-export"><code>docs/stats.md</code></a> and the CLI walkthrough in <a href="#hot-key-output"><code>docs/cli.md</code></a>.</p>
<hr>
<h2 id="61-default-configuration"><a class="header" href="#61-default-configuration">6.1 Default Configuration</a></h2>
<p>Global HotRing defaults (<code>NewDefaultOptions</code>):</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Option</th><th>Default value</th><th>Notes</th></tr>
</thead>
<tbody>
<tr><td><code>HotRingEnabled</code></td><td><code>true</code></td><td>Master switch for DB hot tracking.</td></tr>
<tr><td><code>HotRingBits</code></td><td><code>12</code></td><td>4096 buckets.</td></tr>
<tr><td><code>HotRingTopK</code></td><td><code>16</code></td><td>Top-K hot keys for stats/CLI.</td></tr>
<tr><td><code>HotRingDecayInterval</code></td><td><code>0</code></td><td>Decay disabled by default.</td></tr>
<tr><td><code>HotRingDecayShift</code></td><td><code>0</code></td><td>Decay disabled by default.</td></tr>
<tr><td><code>HotRingWindowSlots</code></td><td><code>8</code></td><td>Sliding window enabled.</td></tr>
<tr><td><code>HotRingWindowSlotDuration</code></td><td><code>250ms</code></td><td>~2s window.</td></tr>
<tr><td><code>HotRingRotationInterval</code></td><td><code>30m</code></td><td>Dual-ring rotation enabled.</td></tr>
<tr><td><code>HotRingNodeCap</code></td><td><code>250,000</code></td><td>Strict cap per ring.</td></tr>
<tr><td><code>HotRingNodeSampleBits</code></td><td><code>0</code></td><td>Strict cap (no sampling).</td></tr>
</tbody>
</table>
</div>
<p>Value-log override defaults (<code>ValueLogHotRing*</code>):</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Option</th><th>Default value</th><th>Notes</th></tr>
</thead>
<tbody>
<tr><td><code>ValueLogHotRingOverride</code></td><td><code>true</code></td><td>Use dedicated VLog settings.</td></tr>
<tr><td><code>ValueLogHotRingBits</code></td><td><code>12</code></td><td>4096 buckets.</td></tr>
<tr><td><code>ValueLogHotRingRotationInterval</code></td><td><code>10m</code></td><td>Faster rotation for write-hotness.</td></tr>
<tr><td><code>ValueLogHotRingNodeCap</code></td><td><code>200,000</code></td><td>Strict cap per ring.</td></tr>
<tr><td><code>ValueLogHotRingNodeSampleBits</code></td><td><code>0</code></td><td>Strict cap (no sampling).</td></tr>
<tr><td><code>ValueLogHotRingDecayInterval</code></td><td><code>0</code></td><td>Decay disabled (window handles recency).</td></tr>
<tr><td><code>ValueLogHotRingDecayShift</code></td><td><code>0</code></td><td>Decay disabled.</td></tr>
<tr><td><code>ValueLogHotRingWindowSlots</code></td><td><code>6</code></td><td>~600ms window.</td></tr>
<tr><td><code>ValueLogHotRingWindowSlotDuration</code></td><td><code>100ms</code></td><td>Shorter write-hotness window.</td></tr>
</tbody>
</table>
</div>
<p>When <code>ValueLogHotRingOverride=false</code>, the value-log ring inherits the global HotRing
settings. When override is enabled, <strong>zeros disable features</strong> (except <code>bits=0</code>,
which falls back to the ring default).</p>
<hr>
<h2 id="7-write-path-throttling"><a class="header" href="#7-write-path-throttling">7. Write-Path Throttling</a></h2>
<p><code>Options.WriteHotKeyLimit</code> wires the write-only HotRing into the write path. When set to a positive integer, every call to <code>DB.Set*</code> or transactional <code>Txn.Set*</code> invokes <code>HotRing.TouchAndClamp</code> with the limit. Once a key (optionally scoped by column family via <code>cfHotKey</code>) reaches the limit, the write is rejected with <code>utils.ErrHotKeyWriteThrottle</code>. If throttling is disabled but <code>HotWriteBurstThreshold &gt; 0</code>, the write ring still tracks frequency to enable hot write batching. This keeps pathological tenants or hot shards from overwhelming a single Raft group without adding heavyweight rate-limiters to the client stack.</p>
<p>Operational hints:</p>
<ul>
<li><code>StatsSnapshot.Write.HotKeyLimited</code> and the CLI line <code>Write.HotKeyThrottled</code> expose how many writes were rejected since the process started.</li>
<li>Applications should surface <code>utils.ErrHotKeyWriteThrottle</code> to callers (e.g. HTTP 429) so clients can back off.</li>
<li>Prefetching continues to run independentlyâ€”only writes are rejected; reads still register hotness so the cache layer knows what to prefetch.</li>
<li>Set the limit conservatively (e.g. a few dozen) and pair it with richer <code>HotRing</code> analytics (top-K stats, expvar export) to identify outliers before tuning.</li>
</ul>
<hr>
<h2 id="8-time-based-decay--sliding-window"><a class="header" href="#8-time-based-decay--sliding-window">8. Time-Based Decay &amp; Sliding Window</a></h2>
<p>HotRing now exposes two complementary controls so â€œoldâ€ hotspots fade away automatically:</p>
<ol>
<li><strong>Periodic decay (<code>Options.HotRingDecayInterval</code> + <code>HotRingDecayShift</code>)</strong><br>Every <code>interval</code> the global counters are right-shifted (<code>count &gt;&gt;= shift</code>). This keeps <code>TopN</code> and stats output focused on recent traffic even if writes stop abruptly.</li>
<li><strong>Sliding window (<code>Options.HotRingWindowSlots</code> + <code>HotRingWindowSlotDuration</code>)</strong><br>Per-key windows split time into <code>slots</code>, each lasting <code>slotDuration</code>. <code>Touch</code> only accumulates inside the current slot; once the window slides past, the stale contribution is dropped. <code>TouchAndClamp</code> and <code>Frequency</code> use the sliding-window total, so write throttling reflects short-term pressure instead of lifetime counts.</li>
</ol>
<p>Disable either mechanism by setting the interval/durations to zero. Typical starting points:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Option</th><th>Default value</th><th>Effect</th></tr>
</thead>
<tbody>
<tr><td><code>HotRingDecayInterval</code></td><td><code>0</code></td><td>Decay disabled by default.</td></tr>
<tr><td><code>HotRingDecayShift</code></td><td><code>0</code></td><td>Decay disabled by default.</td></tr>
<tr><td><code>HotRingWindowSlots</code></td><td><code>8</code></td><td>Keep ~8 buckets of recency data.</td></tr>
<tr><td><code>HotRingWindowSlotDuration</code></td><td><code>250ms</code></td><td>Roughly 2s window for throttling.</td></tr>
</tbody>
</table>
</div>
<p>With both enabled, the decay loop keeps background stats tidy while the sliding window powers precise, short-term throttling logic.</p>
<p>Note: in NoKV, configuration normalization treats the sliding window as higher
priority. If a window is enabled, decay is automatically disabled to avoid
redundant background work.</p>
<hr>
<h2 id="9-bounding-growth-node-cap--rotation"><a class="header" href="#9-bounding-growth-node-cap--rotation">9. Bounding Growth (Node Cap &amp; Rotation)</a></h2>
<p>HotRing does not automatically evict keys. To keep memory predictable in high-cardinality
workloads, use a <strong>node cap</strong> (with optional sampling) and/or <strong>ring rotation</strong>.</p>
<h3 id="node-cap--sampling"><a class="header" href="#node-cap--sampling">Node cap + sampling</a></h3>
<ul>
<li><code>Options.HotRingNodeCap</code> sets a per-ring upper bound on tracked keys.</li>
<li><code>Options.HotRingNodeSampleBits</code> controls stable sampling once the cap is hit:
<ul>
<li><code>0</code> = strict cap (no new keys after the cap).</li>
<li><code>N</code> = allow roughly <code>1/2^N</code> of new keys (soft cap).</li>
<li>When <code>HotRingNodeCap = 0</code>, sampling is disabled.</li>
</ul>
</li>
</ul>
<h3 id="dual-ring-rotation"><a class="header" href="#dual-ring-rotation">Dual-ring rotation</a></h3>
<ul>
<li><code>Options.HotRingRotationInterval</code> enables dual-ring rotation:
<ul>
<li><strong>active</strong> ring receives new touches</li>
<li><strong>warm</strong> ring keeps the previous generation to avoid sudden drops</li>
</ul>
</li>
<li>Merge semantics:
<ul>
<li><code>Frequency</code> / <code>TouchAndClamp</code> â†’ <code>max(active, warm)</code></li>
<li><code>TopN</code> / <code>KeysAbove</code> â†’ <code>sum(active, warm)</code></li>
</ul>
</li>
</ul>
<p><strong>Memory note:</strong> rotation keeps two rings, so the upper bound is roughly
<code>2 Ã— HotRingNodeCap</code>. If you have a fixed budget, halve the per-ring cap.</p>
<p>Suggested starting points:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Option</th><th>Effect</th></tr>
</thead>
<tbody>
<tr><td><code>HotRingNodeCap</code></td><td>Hard cap per ring (0 disables).</td></tr>
<tr><td><code>HotRingNodeSampleBits</code></td><td>Soft cap sampling rate.</td></tr>
<tr><td><code>HotRingRotationInterval</code></td><td>Rotation period (0 disables).</td></tr>
</tbody>
</table>
</div>
<hr>
<h2 id="10-value-log-overrides"><a class="header" href="#10-value-log-overrides">10. Value Log Overrides</a></h2>
<p>NoKV maintains a <strong>value-log HotRing</strong> dedicated to hot/cold routing. By
default this override is enabled so the write-only ring can use faster rotation
and a shorter window. You can disable it to inherit the global HotRing config:</p>
<ul>
<li><code>Options.ValueLogHotRingOverride = false</code> (inherit global settings)</li>
<li>Or keep it enabled and tune <code>ValueLogHotRing*</code> fields explicitly.</li>
</ul>
<p>When override is enabled, <strong>the value-log ring uses the override values verbatim</strong>;
zeros disable a feature (for example, rotation). If override is disabled, it
inherits the global <code>HotRing*</code> configuration.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="transaction--mvcc-design"><a class="header" href="#transaction--mvcc-design">Transaction &amp; MVCC Design</a></h1>
<p>NoKV provides snapshot-isolated transactions backed by a lightweight <strong>oracle</strong> that hands out timestamps, tracks conflicts, and coordinates with the write pipeline. The implementation lives entirely in <a href="../txn.go"><code>txn.go</code></a> with metrics surfaced via <a href="../stats.go"><code>stats.go</code></a>.</p>
<hr>
<h2 id="1-components-at-a-glance"><a class="header" href="#1-components-at-a-glance">1. Components at a Glance</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Component</th><th>Purpose</th><th>Key Functions</th></tr>
</thead>
<tbody>
<tr><td><code>oracle</code></td><td>Issues read/commit timestamps, performs conflict checks, persists watermark progress.</td><td><a href="../txn.go#L80-L100"><code>readTs</code></a>, <a href="../txn.go#L142-L190"><code>newCommitTs</code></a>, <a href="../txn.go#L206-L208"><code>doneCommit</code></a></td></tr>
<tr><td><code>Txn</code></td><td>User-facing transaction state: pending writes, read-set fingerprints, MVCC metadata.</td><td><a href="../txn.go#L412-L425"><code>SetEntry</code></a>, <a href="../txn.go#L428-L502"><code>Get</code></a>, <a href="../txn.go#L618-L671"><code>Commit</code></a></td></tr>
<tr><td><code>pendingWritesIterator</code></td><td>Allows iterator merge to see unflushed txn writes.</td><td><a href="../txn.go#L324-L347"><code>newPendingWritesIterator</code></a></td></tr>
<tr><td>Metrics</td><td>Tracks counts of started/committed/conflicted txns.</td><td><a href="../txn.go#L58-L66"><code>trackTxnStart</code></a>, <a href="../txn.go#L72-L78"><code>txnMetricsSnapshot</code></a></td></tr>
</tbody>
</table>
</div>
<p>The oracle is initialised during <code>DB.Open</code>, sharing lineage with BadgerDBâ€™s MVCC model. Unlike RocksDBâ€”which relies on WriteBatch/TwoPhaseCommit extensionsâ€”transactions are first-class citizens, and the core engine enforces ordering.</p>
<hr>
<h2 id="2-timestamp--conflict-flow"><a class="header" href="#2-timestamp--conflict-flow">2. Timestamp &amp; Conflict Flow</a></h2>
<pre class="mermaid">sequenceDiagram
    participant Client
    participant DB
    participant Oracle
    participant Commit as commitWorker
    participant Mgr as vlog.Manager
    participant WAL
    participant Mem as MemTable
    Client-&gt;&gt;DB: NewTransaction(update)
    DB-&gt;&gt;Oracle: readTs()
    Oracle--&gt;&gt;DB: snapshot ts (nextTxnTs-1)
    Client-&gt;&gt;DB: Set/Delete/Get
    DB-&gt;&gt;Txn: stage pendingWrites, record read hashes
    Client-&gt;&gt;DB: Commit
    DB-&gt;&gt;Oracle: newCommitTs(txn)
    alt conflict
        Oracle--&gt;&gt;DB: ErrConflict
    else success
        Oracle--&gt;&gt;DB: commitTs
        DB-&gt;&gt;Commit: batch requests
        Commit-&gt;&gt;Mgr: AppendEntries(entries, writeMask)
        Commit-&gt;&gt;WAL: Append(entries with commitTs)
        Commit-&gt;&gt;Mem: apply to active memtable index
        DB-&gt;&gt;Oracle: doneCommit(commitTs)
    end
</pre>

<ol>
<li><strong>Start</strong> â€“ <code>DB.newTransaction</code> calls <a href="../txn.go#L80-L100"><code>oracle.readTs</code></a>, which waits for all prior commits to finish (<code>txnMark.WaitForMark</code>) so new readers see a consistent snapshot. In distributed deployments, clients must obtain the <code>startVersion</code> themselves (see <a href="#timestamp-sources">Timestamp sources</a>).</li>
<li><strong>Reads</strong> â€“ <code>Txn.Get</code> first checks <code>pendingWrites</code>; otherwise it merges LSM iterators and value-log pointers under the read timestamp. For update transactions the read key fingerprint is recorded in <code>Txn.reads</code> via <a href="../txn.go#L511-L526"><code>addReadKey</code></a>.</li>
<li><strong>Conflict detection</strong> â€“ When <code>Options.DetectConflicts</code> is enabled, <code>oracle.newCommitTs</code> iterates <code>oracle.committedTxns</code> and compares read fingerprints against keys written by newer commits. This mirrors Badgerâ€™s optimistic strategy.</li>
<li><strong>Commit timestamp</strong> â€“ <code>newCommitTs</code> increments <code>nextTxnTs</code>, registers the commit in <code>txnMark</code>, and stores the conflict key set for future comparisons.</li>
<li><strong>Apply</strong> â€“ <code>Txn.commitAndSend</code> assigns the commit timestamp to each pending entry (<code>kv.KeyWithTs</code>), enqueues them through <code>sendToWriteCh</code>, and returns a callback that waits for the batch completion. Only after the callback runs does the oracleâ€™s <code>doneCommit</code> release the commit watermark.</li>
<li><strong>Value log ordering</strong> â€“ As with non-transactional writes, the commit worker runs <code>valueLog.write</code> (which calls <code>Manager.AppendEntries</code>) before the WAL append. On failure <code>vlog.manager.Rewind</code> ensures partial writes do not leak.</li>
</ol>
<p>RocksDBâ€™s default WriteBatch lacks conflict detection, relying on application-level locking; NoKV ships with snapshot isolation and optional detection, similar to Badgerâ€™s <code>Txn</code> but with integrated metrics and iterator pooling.</p>
<hr>
<h2 id="3-data-structures"><a class="header" href="#3-data-structures">3. Data Structures</a></h2>
<h3 id="oracle-watermarks"><a class="header" href="#oracle-watermarks">Oracle Watermarks</a></h3>
<pre><code class="language-text">oracle{
  nextTxnTs       // next commit timestamp to assign
  txnMark         // watermark waiting for WAL/vlog durability
  readMark        // tracks oldest active read timestamp
  committedTxns[] // sliding window of conflict key sets
}
</code></pre>
<ul>
<li><code>txnMark</code> / <code>readMark</code> are <code>utils.WaterMark</code> instances. They guarantee all writes with timestamp â‰¤ <code>readTs</code> are durable before a new read snapshot begins, mirroring Badgerâ€™s approach to avoid reading half-committed data.</li>
<li><code>cleanupCommittedTransactions</code> prunes conflict history based on the oldest outstanding read, preventing unbounded memory use.</li>
</ul>
<h3 id="txn-state"><a class="header" href="#txn-state">Txn State</a></h3>
<pre><code class="language-go">type Txn struct {
    readTs   uint64
    commitTs uint64
    pendingWrites map[string]*kv.Entry
    conflictKeys  map[uint64]struct{}
    reads         []uint64
    numIterators  int32
    discarded     bool
    update        bool
}
</code></pre>
<ul>
<li>Pending writes retain the callerâ€™s entry pointers until commit; NoKV copies values only when moving them into the write batch.</li>
<li>Read fingerprints use <code>kv.MemHash</code>, so conflict detection is order-independent and compact.</li>
<li>MVCC versions are encoded in the key suffix (<code>KeyWithTs</code>), matching the LSMâ€™s descending version order.</li>
</ul>
<h3 id="iterator-integration"><a class="header" href="#iterator-integration">Iterator Integration</a></h3>
<ul>
<li><code>Txn.newPendingWritesIterator</code> materialises staged entries as a sorted slice, allowing transaction iterators to merge them with memtables/SST tables. This ensures <code>Txn.NewIterator</code> sees writes immediately without affecting other snapshots.</li>
<li><code>Txn.numIterators</code> enforces that all iterators close before commit/discardâ€”helpful for catching resource leaks in tests (<code>txn_iterator_test.go</code>).</li>
</ul>
<hr>
<h2 id="4-commit--error-handling"><a class="header" href="#4-commit--error-handling">4. Commit &amp; Error Handling</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Stage</th><th>Failure Handling</th></tr>
</thead>
<tbody>
<tr><td>Conflict</td><td><code>oracle.newCommitTs</code> returns <code>(0, true)</code>; <code>Txn.Commit</code> surfaces <code>utils.ErrConflict</code> and leaves state untouched.</td></tr>
<tr><td>Value log append</td><td><code>valueLog.write</code> rewinds via <code>Manager.Rewind</code>; <code>req.Wait</code> returns the error so callers can retry safely.</td></tr>
<tr><td>WAL append</td><td><code>sendToWriteCh</code> propagates WAL errors; commit watermark is cleared immediately in that case.</td></tr>
<tr><td>Callback mode</td><td><code>Txn.CommitWith</code> schedules <code>runTxnCallback</code> on a goroutine; user callbacks always execute (success or error).</td></tr>
</tbody>
</table>
</div>
<p>The final call to <code>Txn.Discard</code> runs regardless of success, marking the read watermark done and decrementing the oracleâ€™s active counter.</p>
<hr>
<h2 id="5-comparisons-1"><a class="header" href="#5-comparisons-1">5. Comparisons</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Feature</th><th>RocksDB</th><th>BadgerDB</th><th>NoKV</th></tr>
</thead>
<tbody>
<tr><td>Isolation</td><td>Optional (WritePrepared/2PC)</td><td>Snapshot isolation</td><td>Snapshot isolation with <code>WaterMark</code> barriers</td></tr>
<tr><td>Conflict detection</td><td>External</td><td>Optional optimistic</td><td>Optional optimistic keyed by <code>utils.MemHash</code></td></tr>
<tr><td>Iterator view</td><td>Snapshot handles, manual merging</td><td>Built-in</td><td>Built-in with pending write iterator</td></tr>
<tr><td>Metrics</td><td><code>rocksdb.transactions.*</code> when enabled</td><td>Basic stats</td><td><code>NoKV.Stats.txn.*</code> + CLI</td></tr>
</tbody>
</table>
</div>
<p>NoKV inherits Badgerâ€™s optimistic concurrency but strengthens durability ordering by coupling commits with the same write pipeline that non-transactional writes use. Compared with RocksDBâ€™s transactional library, the Go implementation remains lightweight and requires no external locks.</p>
<hr>
<h2 id="6-operational-notes-2"><a class="header" href="#6-operational-notes-2">6. Operational Notes</a></h2>
<ul>
<li><strong>Long-running reads</strong>: watch <code>NoKV.Stats.txn.active</code> and <code>oracle.readMark.DoneUntil()</code>â€”slow consumers keep old versions alive, delaying vlog GC and compaction reclamation.</li>
<li><strong>Non-transactional APIs</strong>: <code>DB.Set/Get/Del</code> and <code>SetCF/GetCF/DelCF</code> use a MaxUint64 sentinel version for â€œlatestâ€. Do not mix these writes with MVCC/Txn writes in the same database.</li>
<li><strong>Managed mode</strong>: exposing <code>Txn.SetEntry</code> with pre-set versions allows replication/replay flows. Because commit timestamps may diverge, transaction markers are only set when all entries share a single commitTs.</li>
<li><strong>Throttling</strong>: combine <code>HotRing.TouchAndClamp</code> with per-transaction analytics to detect hot-key write storms that lead to frequent conflicts.</li>
</ul>
<p>See <a href="#transactions"><code>docs/testing.md</code></a> for the regression matrix covering conflict detection, iterator semantics, and managed timestamps.</p>
<hr>
<h2 id="7-timestamp-sources"><a class="header" href="#7-timestamp-sources">7. Timestamp Sources</a></h2>
<p>Replica nodes do <strong>not</strong> generate timestamps during TinyKV RPC handling; the values sent in <code>KvPrewrite</code>/<code>KvCommit</code> are applied verbatim. For teaching and prototyping you can pick from two approaches:</p>
<ul>
<li>
<p><strong>Single-client experiments</strong> â€“ choose monotonically increasing integers in your client code (as shown in <code>raftstore/client/client_test.go</code>).</p>
</li>
<li>
<p><strong>Shared allocator</strong> â€“ run the sample TSO service under <code>scripts/tso</code> to hand out globally increasing timestamps:</p>
<pre><code class="language-bash">go run ./scripts/tso --addr 127.0.0.1:9494 --start 100

# request one timestamp
curl -s http://127.0.0.1:9494/tso
# request a batch of 16
curl -s "http://127.0.0.1:9494/tso?batch=16"
</code></pre>
<p>Each call returns JSON (<code>{"timestamp":123,"count":1}</code>), where <code>timestamp</code> is the first value in the allocated range. Clients can use the first value for <code>startVersion</code>, or the entire range to provision multiple transactions. This keeps the learning focus on the Percolator flow while demonstrating how production systems would obtain globally ordered timestamps.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="raftstore-deep-dive"><a class="header" href="#raftstore-deep-dive">RaftStore Deep Dive</a></h1>
<p><code>raftstore</code> powers NoKVâ€™s distributed mode by layering multi-Raft replication on top of the embedded storage engine. This note explains the major packages, the boot and command paths, how transport and storage interact, and the supporting tooling for observability and testing.</p>
<hr>
<h2 id="1-package-structure"><a class="header" href="#1-package-structure">1. Package Structure</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Package</th><th>Responsibility</th></tr>
</thead>
<tbody>
<tr><td><a href="../raftstore/store"><code>store</code></a></td><td>Orchestrates peer set, command pipeline, region manager, scheduler/heartbeat loops; exposes helpers such as <code>StartPeer</code>, <code>ProposeCommand</code>, <code>SplitRegion</code>.</td></tr>
<tr><td><a href="../raftstore/peer"><code>peer</code></a></td><td>Wraps etcd/raft <code>RawNode</code>, drives Ready processing (persist to WAL, send messages, apply entries), tracks snapshot resend/backlog.</td></tr>
<tr><td><a href="../raftstore/engine"><code>engine</code></a></td><td>WALStorage/DiskStorage/MemoryStorage across all Raft groups, leveraging the NoKV WAL while keeping manifest metadata in sync.</td></tr>
<tr><td><a href="../raftstore/transport"><code>transport</code></a></td><td>gRPC transport with retry/TLS/backpressure; exposes the raft Step RPC and can host additional services (TinyKv).</td></tr>
<tr><td><a href="../raftstore/kv"><code>kv</code></a></td><td>TinyKv RPC implementation, bridging Raft commands to MVCC operations via <code>kv.Apply</code>.</td></tr>
<tr><td><a href="../raftstore/server"><code>server</code></a></td><td><code>ServerConfig</code> + <code>New</code> that bind DB, Store, transport, and TinyKv server into a reusable node primitive.</td></tr>
</tbody>
</table>
</div>
<hr>
<h2 id="2-boot-sequence"><a class="header" href="#2-boot-sequence">2. Boot Sequence</a></h2>
<ol>
<li>
<p><strong>Construct Server</strong></p>
<pre><code class="language-go">srv, _ := raftstore.NewServer(raftstore.ServerConfig{
    DB: db,
    Store: raftstore.StoreConfig{StoreID: 1},
    Raft: myraft.Config{ElectionTick: 10, HeartbeatTick: 2, PreVote: true},
    TransportAddr: "127.0.0.1:20160",
})
</code></pre>
<ul>
<li>A gRPC transport is created, the TinyKv service is registered, and <code>transport.SetHandler(store.Step)</code> wires raft Step handling.</li>
<li><code>store.Store</code> loads <code>manifest.RegionSnapshot()</code> to rebuild the Region catalog (router + metrics).</li>
</ul>
</li>
<li>
<p><strong>Start local peers</strong></p>
<ul>
<li>CLI (<code>nokv serve</code>) iterates the manifest snapshot and calls <code>Store.StartPeer</code> for every region that includes the local store.</li>
<li>Each <code>peer.Config</code> carries raft parameters, the transport reference, <code>kv.NewEntryApplier</code>, WAL/manifest handles, and Region metadata.</li>
<li><code>StartPeer</code> registers the peer through the peer-set/routing layer and may bootstrap or campaign for leadership.</li>
</ul>
</li>
<li>
<p><strong>Peer connectivity</strong></p>
<ul>
<li><code>transport.SetPeer(storeID, addr)</code> defines outbound raft connections; the CLI exposes it via <code>--peer storeID=addr</code>.</li>
<li>Additional services can reuse the same gRPC server through <code>transport.WithServerRegistrar</code>.</li>
</ul>
</li>
</ol>
<hr>
<h2 id="3-command-execution"><a class="header" href="#3-command-execution">3. Command Execution</a></h2>
<h3 id="read-strong-leader-read"><a class="header" href="#read-strong-leader-read">Read (strong leader read)</a></h3>
<ol>
<li><code>kv.Service.KvGet</code> builds <code>pb.RaftCmdRequest</code> and invokes <code>Store.ReadCommand</code>.</li>
<li><code>validateCommand</code> ensures the region exists, epoch matches, and the local peer is leader; a RegionError is returned otherwise.</li>
<li><code>peer.Flush()</code> drains pending Ready, guaranteeing the latest committed log is applied.</li>
<li><code>commandApplier</code> (i.e. <code>kv.Apply</code>) runs GET/SCAN directly against the DB, using MVCC readers to honour locks and version visibility.</li>
</ol>
<h3 id="write-via-propose"><a class="header" href="#write-via-propose">Write (via Propose)</a></h3>
<ol>
<li>Write RPCs (Prewrite/Commit/â€¦) call <code>Store.ProposeCommand</code>, encoding the command and routing to the leader peer.</li>
<li>The leader appends the encoded request to raft, replicates, and once committed the command pipeline hands data to <code>kv.Apply</code>, which maps Prewrite/Commit/ResolveLock to the <code>percolator</code> package.</li>
<li><code>engine.WALStorage</code> persists raft entries/state snapshots and updates manifest raft pointers. This keeps WAL GC and raft truncation aligned.</li>
<li>Raft apply only accepts command-encoded payloads (<code>RaftCmdRequest</code>). Legacy raw KV payloads are rejected as unsupported.</li>
</ol>
<hr>
<h2 id="4-transport"><a class="header" href="#4-transport">4. Transport</a></h2>
<ul>
<li>gRPC transport listens on <code>TransportAddr</code>, serving both raft Step RPC and TinyKv RPC.</li>
<li><code>SetPeer</code> updates the mapping of remote store IDs to addresses; <code>BlockPeer</code> can be used by tests or chaos tooling.</li>
<li>Configurable retry/backoff/timeout options mirror production requirements. Tests cover message loss, blocked peers, and partitions.</li>
</ul>
<hr>
<h2 id="5-storage-backend-engine"><a class="header" href="#5-storage-backend-engine">5. Storage Backend (engine)</a></h2>
<ul>
<li><code>WALStorage</code> piggybacks on the embedded WAL: each Raft group writes typed entries, HardState, and snapshots into the shared log.</li>
<li><code>LogRaftPointer</code> and <code>LogRaftTruncate</code> edit manifest metadata so WAL GC knows how far it can compact per group.</li>
<li>Alternative storage backends (<code>DiskStorage</code>, <code>MemoryStorage</code>) are available for tests and special scenarios.</li>
</ul>
<hr>
<h2 id="6-tinykv-rpc-integration"><a class="header" href="#6-tinykv-rpc-integration">6. TinyKv RPC Integration</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>RPC</th><th>Execution Path</th><th>Notes</th></tr>
</thead>
<tbody>
<tr><td><code>KvGet</code> / <code>KvScan</code></td><td><code>ReadCommand</code> â†’ <code>kv.Apply</code> (read mode)</td><td>No raft round-trip; leader-only.</td></tr>
<tr><td><code>KvPrewrite</code> / <code>KvCommit</code> / <code>KvBatchRollback</code> / <code>KvResolveLock</code> / <code>KvCheckTxnStatus</code></td><td><code>ProposeCommand</code> â†’ command pipeline â†’ raft log â†’ <code>kv.Apply</code></td><td>Pipeline matches proposals with apply results; MVCC latch manager prevents write conflicts.</td></tr>
</tbody>
</table>
</div>
<p>The <code>cmd/nokv serve</code> command uses <code>raftstore.Server</code> internally and prints a manifest summary (key ranges, peers) so operators can verify the nodeâ€™s view at startup.</p>
<hr>
<h2 id="7-client-interaction-raftstoreclient"><a class="header" href="#7-client-interaction-raftstoreclient">7. Client Interaction (<code>raftstore/client</code>)</a></h2>
<ul>
<li>Region-aware routing with NotLeader/EpochNotMatch retry.</li>
<li><code>Mutate</code> splits mutations by region and performs two-phase commit (primary first). <code>Put</code> / <code>Delete</code> are convenience wrappers.</li>
<li><code>Scan</code> transparently walks region boundaries.</li>
<li>End-to-end coverage lives in <code>raftstore/server/server_client_integration_test.go</code>, which launches real servers, uses the client to write and delete keys, and verifies the results.</li>
</ul>
<hr>
<h2 id="8-control-plane--region-operations"><a class="header" href="#8-control-plane--region-operations">8. Control Plane &amp; Region Operations</a></h2>
<h3 id="81-topology--routing"><a class="header" href="#81-topology--routing">8.1 Topology &amp; Routing</a></h3>
<ul>
<li>Topology is sourced from <code>raft_config.example.json</code> (via <code>config.LoadFile</code>) and
reused by scripts, Docker Compose, and the Redis gateway.</li>
<li>The client builds a static region map (<code>[]RegionConfig</code>) and store endpoints
from the same file; there is no dynamic PD-style reconfiguration today.</li>
<li>The built-in scheduler currently emits leader-transfer operations only
(see <code>raftstore/scheduler</code>), acting as a minimal control plane.</li>
</ul>
<h3 id="82-split--merge"><a class="header" href="#82-split--merge">8.2 Split / Merge</a></h3>
<ul>
<li><strong>Split</strong>: leaders call <code>Store.ProposeSplit</code>, which writes a split
<code>AdminCommand</code> into the parent regionâ€™s raft log. On apply,
<code>Store.SplitRegion</code> updates the parent range/epoch and starts the child peer.</li>
<li><strong>Merge</strong>: leaders call <code>Store.ProposeMerge</code>, writing a merge <code>AdminCommand</code>.
On apply, the target region range/epoch is expanded and the source peer is
stopped/removed from the manifest.</li>
<li>These operations are explicit and are not auto-triggered by size/traffic
heuristics; a higher-level controller could call the same APIs.</li>
</ul>
<hr>
<h2 id="9-observability"><a class="header" href="#9-observability">9. Observability</a></h2>
<ul>
<li><code>store.RegionMetrics()</code> feeds into <code>StatsSnapshot</code>, making region counts and backlog visible via expvar and <code>nokv stats</code>.</li>
<li><code>nokv regions</code> shows manifest-backed regions: ID, range, peers, state.</li>
<li><code>scripts/transport_chaos.sh</code> exercises transport metrics under faults; <code>scripts/run_local_cluster.sh</code> spins up multi-node clusters for manual inspection.</li>
</ul>
<h3 id="store-internals-at-a-glance"><a class="header" href="#store-internals-at-a-glance">Store internals at a glance</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Component</th><th>File</th><th>Responsibility</th></tr>
</thead>
<tbody>
<tr><td>Store facade</td><td><a href="../raftstore/store/store.go"><code>store.go</code></a></td><td>Store construction/wiring and shared component ownership (router, region manager, command pipeline, scheduler runtime).</td></tr>
<tr><td>Peer lifecycle</td><td><a href="../raftstore/store/peer_lifecycle.go"><code>peer_lifecycle.go</code></a></td><td>Start/stop peers, router registration, lifecycle hooks, and store shutdown sequencing.</td></tr>
<tr><td>Command service</td><td><a href="../raftstore/store/command_service.go"><code>command_service.go</code></a></td><td>Region/epoch/key-range validation and read/propose request handling.</td></tr>
<tr><td>Admin service</td><td><a href="../raftstore/store/admin_service.go"><code>admin_service.go</code></a></td><td>Split/merge proposal handling and applied admin command side effects.</td></tr>
<tr><td>Membership service</td><td><a href="../raftstore/store/membership_service.go"><code>membership_service.go</code></a></td><td>Conf-change proposal helpers and manifest metadata updates after membership changes.</td></tr>
<tr><td>Region catalog</td><td><a href="../raftstore/store/region_catalog.go"><code>region_catalog.go</code></a></td><td>Public region catalog accessors and region metadata lifecycle operations.</td></tr>
<tr><td>Scheduler runtime</td><td><a href="../raftstore/store/scheduler_runtime.go"><code>scheduler_runtime.go</code></a></td><td>Scheduler snapshot generation, store stats, operation application, and apply-entry dispatch.</td></tr>
<tr><td>Peer set</td><td><a href="../raftstore/store/peer_set.go"><code>peer_set.go</code></a></td><td>Tracks active peers and exposes thread-safe lookups/iteration snapshots.</td></tr>
<tr><td>Command pipeline</td><td><a href="../raftstore/store/command_pipeline.go"><code>command_pipeline.go</code></a></td><td>Assigns request IDs, records proposals, matches apply results, returns responses/errors to callers.</td></tr>
<tr><td>Region manager</td><td><a href="../raftstore/store/region_manager.go"><code>region_manager.go</code></a></td><td>Validates state transitions, writes manifest edits, updates peer metadata, triggers region hooks.</td></tr>
<tr><td>Operation scheduler</td><td><a href="../raftstore/store/operation_scheduler.go"><code>operation_scheduler.go</code></a></td><td>Buffers planner output, enforces cooldown &amp; burst limits, dispatches leader transfers or other operations.</td></tr>
<tr><td>Heartbeat loop</td><td><a href="../raftstore/store/heartbeat_loop.go"><code>heartbeat_loop.go</code></a></td><td>Periodically publishes region/store heartbeats and re-runs the planner to produce scheduling actions.</td></tr>
</tbody>
</table>
</div>
<hr>
<h2 id="10-extending-raftstore"><a class="header" href="#10-extending-raftstore">10. Extending raftstore</a></h2>
<ul>
<li><strong>Adding peers</strong>: update the manifest with new Region metadata, then call <code>Store.StartPeer</code> on the target node.</li>
<li><strong>Follower or lease reads</strong>: extend <code>ReadCommand</code> to include ReadIndex or leader lease checks; current design only serves leader reads.</li>
<li><strong>Scheduler integration</strong>: pair <code>RegionSnapshot()</code> and <code>RegionMetrics()</code> with an external scheduler (PD-like) for dynamic balancing.</li>
</ul>
<p>This layering keeps the embedded storage engine intact while providing a production-ready replication path, robust observability, and straightforward integration in both CLI and programmatic contexts.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="crash-recovery-playbook"><a class="header" href="#crash-recovery-playbook">Crash Recovery Playbook</a></h1>
<p>This playbook documents how NoKV rebuilds state after a crash and which automated checks ensure correctness. It ties together WAL replay, manifest reconciliation, ValueLog GC, and flush pipelinesâ€”mirroring RocksDBâ€™s layered recovery while incorporating Badger-style value log hygiene.</p>
<hr>
<h2 id="1-recovery-phases"><a class="header" href="#1-recovery-phases">1. Recovery Phases</a></h2>
<pre class="mermaid">flowchart TD
    Start[DB.Open]
    Verify[runRecoveryChecks]
    Manifest[manifest.Open â†’ replay]
    WAL[wal.Manager.Replay]
    VLog[valueLog.recover]
    Flush[Recreate memtables]
    Stats[Stats.StartStats]

    Start --&gt; Verify --&gt; Manifest --&gt; WAL --&gt; VLog --&gt; Flush --&gt; Stats
</pre>

<ol>
<li><strong>Directory verification</strong> â€“ <code>DB.runRecoveryChecks</code> calls <code>manifest.Verify</code>, <code>wal.VerifyDir</code>, and initialises the vlog directory. Missing directories fail fast.</li>
<li><strong>Manifest replay</strong> â€“ <code>manifest.Open</code> reads <code>CURRENT</code>, replays <code>EditAddFile/DeleteFile</code>, <code>EditLogPointer</code>, and vlog edits into an in-memory <code>Version</code>.</li>
<li><strong>WAL replay</strong> â€“ <code>wal.Manager.Replay</code> processes segments newer than the manifest checkpoint, rebuilding memtables from committed entries.</li>
<li><strong>ValueLog reconciliation</strong> â€“ <code>valueLog.recover</code> scans existing <code>.vlog</code> files, drops segments marked invalid, and trims torn tails to the last valid entry.</li>
<li><strong>Flush backlog</strong> â€“ Immutable memtables recreated from WAL are resubmitted to <code>flush.Manager</code>; temporary <code>.sst.tmp</code> files are either reinstalled or cleaned up.</li>
<li><strong>Stats bootstrap</strong> â€“ the metrics goroutine restarts so CLI commands immediately reflect queue backlogs and GC status.</li>
</ol>
<p>This mirrors RocksDBâ€™s <code>DBImpl::Recover</code> while extending to handle value log metadata automatically.</p>
<hr>
<h2 id="2-failure-scenarios--expected-outcomes"><a class="header" href="#2-failure-scenarios--expected-outcomes">2. Failure Scenarios &amp; Expected Outcomes</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Failure Point</th><th>Example Simulation</th><th>Expected Recovery Behaviour</th><th>Tests</th></tr>
</thead>
<tbody>
<tr><td>WAL tail truncation</td><td>truncate last 2 bytes of <code>000005.wal</code></td><td>Replay stops at truncated record, previously flushed SST remains intact</td><td><code>wal/manager_test.go::TestReplayTruncatedTail</code></td></tr>
<tr><td>Flush crash before install</td><td>crash after writing <code>.sst.tmp</code></td><td>WAL replay rebuilds memtable; temp file removed; no manifest edit present</td><td><code>db_recovery_test.go::TestRecoveryWALReplayRestoresData</code></td></tr>
<tr><td>Flush crash after install</td><td>crash after logging manifest edit but before WAL release</td><td>Manifest still lists SST; recovery verifies file exists and releases WAL on reopen</td><td><code>db_recovery_test.go::TestRecoveryCleansMissingSSTFromManifest</code></td></tr>
<tr><td>ValueLog GC crash</td><td>delete edit written, file still on disk</td><td>Recovery removes stale <code>.vlog</code> file and keeps manifest consistent</td><td><code>db_recovery_test.go::TestRecoveryRemovesStaleValueLogSegment</code></td></tr>
<tr><td>Manifest rewrite crash</td><td>new MANIFEST written, CURRENT not updated</td><td>Recovery keeps using old manifest; stale temp file cleaned</td><td><code>db_recovery_test.go::TestRecoveryManifestRewriteCrash</code></td></tr>
<tr><td>Transaction in-flight</td><td>crash between WAL append and memtable update</td><td>WAL replay reapplies entry; transactions remain atomic because commit order is vlog â†’ WAL â†’ memtable</td><td><code>txn_test.go::TestTxnCommitPersists</code></td></tr>
</tbody>
</table>
</div>
<hr>
<h2 id="3-automation--tooling"><a class="header" href="#3-automation--tooling">3. Automation &amp; Tooling</a></h2>
<h3 id="31-go-test-matrix"><a class="header" href="#31-go-test-matrix">3.1 Go Test Matrix</a></h3>
<pre><code class="language-bash">GOCACHE=$PWD/.gocache GOMODCACHE=$PWD/.gomodcache go test ./... -run 'Recovery'
</code></pre>
<ul>
<li>Exercises WAL replay, manifest cleanup, vlog GC, and managed transaction recovery.</li>
<li>Set <code>RECOVERY_TRACE_METRICS=1</code> to emit structured logs (key/value pairs) for each scenario.</li>
</ul>
<h3 id="32-shell-script-harness"><a class="header" href="#32-shell-script-harness">3.2 Shell Script Harness</a></h3>
<p><code>scripts/recovery_scenarios.sh</code> orchestrates the matrix end-to-end:</p>
<ol>
<li>Spins up a temporary database, injects writes, and crashes at chosen checkpoints.</li>
<li>Reopens the database and validates via CLI (<code>nokv stats</code>, <code>nokv manifest</code>, <code>nokv vlog</code>).</li>
<li>Archives logs under <code>artifacts/recovery/&lt;scenario&gt;.log</code> for CI inspection.</li>
</ol>
<h3 id="33-cli-validation"><a class="header" href="#33-cli-validation">3.3 CLI Validation</a></h3>
<ul>
<li><code>nokv manifest --workdir &lt;dir&gt;</code>: confirm WAL checkpoint, level files, vlog head.</li>
<li><code>nokv stats --workdir &lt;dir&gt;</code>: observe flush backlog drop to zero after replay.</li>
<li><code>nokv vlog --workdir &lt;dir&gt;</code>: ensure stale segments disappear after GC recovery.</li>
</ul>
<p>These commands give the same insight as RocksDBâ€™s <code>ldb manifest_dump</code> or Badgerâ€™s CLI but with JSON output for automation.</p>
<hr>
<h2 id="4-metrics-emitted-during-recovery"><a class="header" href="#4-metrics-emitted-during-recovery">4. Metrics Emitted During Recovery</a></h2>
<p>When <code>RECOVERY_TRACE_METRICS=1</code>:</p>
<ul>
<li><code>RECOVERY_METRIC phase="manifest" ...</code> â€“ manifest replay progress.</li>
<li><code>RECOVERY_METRIC phase="wal" segment=... offset=...</code> â€“ WAL records applied.</li>
<li><code>RECOVERY_METRIC phase="vlog_gc" fid=... action="delete"</code> â€“ vlog cleanup status.</li>
</ul>
<p><code>StatsSnapshot</code> also exposes:</p>
<ul>
<li><code>flush.queue_length</code> â€“ remaining flush tasks.</li>
<li><code>value_log.heads</code> â€“ current value log heads after recovery.</li>
<li><code>txn.active</code> â€“ should reset to zero post-recovery.</li>
</ul>
<hr>
<h2 id="5-comparison-with-rocksdb--badger"><a class="header" href="#5-comparison-with-rocksdb--badger">5. Comparison with RocksDB &amp; Badger</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Aspect</th><th>RocksDB</th><th>BadgerDB</th><th>NoKV</th></tr>
</thead>
<tbody>
<tr><td>WAL replay</td><td><code>DBImpl::RecoverLogFiles</code> replays per log number</td><td>Journal (value log) is replayed into LSM</td><td>Dedicated WAL manager with manifest checkpoint, plus vlog trim</td></tr>
<tr><td>Manifest reconciliation</td><td>Removes missing files, handles CURRENT rewrite</td><td>Minimal manifest (mainly tables)</td><td>Tracks SST + vlog metadata; auto-cleans missing SST/vlog</td></tr>
<tr><td>Value log recovery</td><td>Optional (BlobDB) requires external blob manifest</td><td>Primary log, re-scanned on start</td><td>Manifest-backed head + discard stats to avoid rescan</td></tr>
<tr><td>Tooling</td><td><code>ldb</code> for manifest dump</td><td><code>badger</code> CLI</td><td><code>nokv</code> CLI with JSON output</td></tr>
</tbody>
</table>
</div>
<p>NoKV inherits RocksDBâ€™s strict manifest semantics and Badgerâ€™s value log durability, yielding deterministic restart behaviour even under mixed workloads.</p>
<hr>
<h2 id="6-extending-the-matrix"><a class="header" href="#6-extending-the-matrix">6. Extending the Matrix</a></h2>
<p>Future enhancements to cover:</p>
<ul>
<li><strong>Compaction crash</strong> â€“ simulate partial compaction output and verify manifest rollback.</li>
<li><strong>Prefetch queue state</strong> â€“ ensure hot-key prefetch map resets cleanly.</li>
<li><strong>Raft integration</strong> â€“ once replication is added, validate raft log catch-up interacts correctly with WAL replay.</li>
</ul>
<p>Contributions adding new recovery scenarios should update this document and the shell harness to keep observability aligned.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="stats--observability-pipeline"><a class="header" href="#stats--observability-pipeline">Stats &amp; Observability Pipeline</a></h1>
<p>NoKV exposes runtime health through:</p>
<ul>
<li><code>StatsSnapshot</code> (structured in-process snapshot)</li>
<li><code>expvar</code> (<code>/debug/vars</code>)</li>
<li><code>nokv stats</code> CLI (plain text or JSON)</li>
</ul>
<p>The implementation lives in <a href="../stats.go"><code>stats.go</code></a>, and collection runs continuously once DB is open.</p>
<hr>
<h2 id="1-architecture"><a class="header" href="#1-architecture">1. Architecture</a></h2>
<pre class="mermaid">flowchart TD
    subgraph Collectors
        LSM[lsm.* metrics]
        WAL[wal metrics]
        VLog[value log metrics]
        TXN[oracle txn metrics]
        HOT[hotring]
        REGION[region metrics]
        TRANSPORT[grpc transport metrics]
        REDIS[redis gateway metrics]
    end
    Collectors --&gt; SNAP[Stats.Snapshot()]
    SNAP --&gt; EXP[Stats.collect -&gt; expvar]
    SNAP --&gt; CLI[nokv stats]
</pre>

<p>Two-layer design:</p>
<ul>
<li><code>metrics</code> layer: only collects counters/gauges/snapshots.</li>
<li><code>stats</code> layer: aggregates cross-module data and exports.</li>
</ul>
<hr>
<h2 id="2-snapshot-schema"><a class="header" href="#2-snapshot-schema">2. Snapshot Schema</a></h2>
<p><code>StatsSnapshot</code> is now domain-grouped (not flat):</p>
<ul>
<li><code>entries</code></li>
<li><code>flush.*</code></li>
<li><code>compaction.*</code></li>
<li><code>value_log.*</code> (includes <code>value_log.gc.*</code>)</li>
<li><code>wal.*</code></li>
<li><code>raft.*</code></li>
<li><code>write.*</code></li>
<li><code>txn.*</code></li>
<li><code>region.*</code></li>
<li><code>hot.*</code></li>
<li><code>cache.*</code></li>
<li><code>lsm.*</code></li>
<li><code>transport.*</code></li>
<li><code>redis.*</code></li>
</ul>
<p>Representative fields:</p>
<ul>
<li><code>flush.pending</code>, <code>flush.queue_length</code>, <code>flush.last_wait_ms</code></li>
<li><code>compaction.backlog</code>, <code>compaction.max_score</code>, <code>compaction.value_weight</code></li>
<li><code>value_log.segments</code>, <code>value_log.pending_deletes</code>, <code>value_log.gc.gc_runs</code></li>
<li><code>wal.active_segment</code>, <code>wal.segment_count</code>, <code>wal.typed_record_ratio</code></li>
<li><code>raft.group_count</code>, <code>raft.lagging_groups</code>, <code>raft.max_lag_segments</code></li>
<li><code>write.queue_depth</code>, <code>write.avg_request_wait_ms</code>, <code>write.hot_key_limited</code></li>
<li><code>txn.active</code>, <code>txn.started</code>, <code>txn.conflicts</code></li>
<li><code>region.total</code>, <code>region.running</code>, <code>region.removing</code>, <code>region.tombstone</code></li>
<li><code>hot.read_keys</code>, <code>hot.write_keys</code>, <code>hot.read_ring</code>, <code>hot.write_ring</code></li>
<li><code>cache.block_l0_hit_rate</code>, <code>cache.bloom_hit_rate</code>, <code>cache.iterator_reused</code></li>
<li><code>lsm.levels</code>, <code>lsm.value_bytes_total</code>, <code>lsm.column_families</code></li>
</ul>
<hr>
<h2 id="3-expvar-export"><a class="header" href="#3-expvar-export">3. expvar Export</a></h2>
<p><code>Stats.collect</code> exports a single structured object:</p>
<ul>
<li><code>NoKV.Stats</code></li>
</ul>
<p>All domains (<code>flush</code>, <code>compaction</code>, <code>value_log</code>, <code>wal</code>, <code>txn</code>, <code>region</code>, <code>hot</code>, <code>cache</code>, <code>lsm</code>, <code>transport</code>, <code>redis</code>) are nested under this object.</p>
<p>Legacy scalar compatibility keys are removed. Consumers should read fields from <code>NoKV.Stats</code> directly.</p>
<hr>
<h2 id="4-cli--json"><a class="header" href="#4-cli--json">4. CLI &amp; JSON</a></h2>
<ul>
<li><code>nokv stats --workdir &lt;dir&gt;</code>: offline snapshot from local DB</li>
<li><code>nokv stats --expvar &lt;host:port&gt;</code>: snapshot from running process <code>/debug/vars</code></li>
<li><code>nokv stats --json</code>: machine-readable nested JSON</li>
</ul>
<p>Example:</p>
<pre><code class="language-json">{
  "entries": 1048576,
  "flush": {
    "pending": 2,
    "queue_length": 2
  },
  "value_log": {
    "segments": 6,
    "pending_deletes": 1,
    "gc": {
      "gc_runs": 12
    }
  },
  "hot": {
    "read_keys": [
      {"key": "user:123", "count": 42}
    ]
  }
}
</code></pre>
<hr>
<h2 id="5-operational-guidance"><a class="header" href="#5-operational-guidance">5. Operational Guidance</a></h2>
<ul>
<li><code>flush.queue_length</code> + <code>compaction.backlog</code> both rising:
flush/compaction under-provisioned.</li>
<li><code>value_log.discard_queue</code> high for long periods:
check <code>value_log.gc.*</code> and compaction pressure.</li>
<li><code>write.throttle_active=true</code> frequently:
L0 pressure likely high; inspect <code>cache.block_l0_hit_rate</code> and compaction.</li>
<li><code>write.hot_key_limited</code> increasing:
hot key write throttling is active.</li>
<li><code>raft.lag_warning=true</code>:
at least one group exceeds lag threshold.</li>
</ul>
<hr>
<h2 id="6-comparison"><a class="header" href="#6-comparison">6. Comparison</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Engine</th><th>Built-in observability</th></tr>
</thead>
<tbody>
<tr><td>RocksDB</td><td>Rich metrics/perf context, often needs additional tooling/parsing</td></tr>
<tr><td>Badger</td><td>Optional metrics integrations</td></tr>
<tr><td>NoKV</td><td>Native expvar + structured snapshot + CLI with offline/online modes</td></tr>
</tbody>
</table>
</div>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="testing--validation-matrix"><a class="header" href="#testing--validation-matrix">Testing &amp; Validation Matrix</a></h1>
<p>This document inventories NoKVâ€™s automated coverage and provides guidance for extending tests. It aligns module-level unit tests, integration suites, and benchmarking harnesses with the architectural features described elsewhere.</p>
<hr>
<h2 id="1-quick-commands"><a class="header" href="#1-quick-commands">1. Quick Commands</a></h2>
<pre><code class="language-bash"># All unit + integration tests (uses local module caches)
GOCACHE=$PWD/.gocache GOMODCACHE=$PWD/.gomodcache go test ./...

# Focused transaction suite
go test ./... -run '^TestTxn|TestConflict|TestTxnIterator'

# Crash recovery scenarios
RECOVERY_TRACE_METRICS=1 ./scripts/recovery_scenarios.sh

# gRPC transport chaos tests + watchdog metrics
CHAOS_TRACE_METRICS=1 ./scripts/transport_chaos.sh

# Sample timestamp allocator (TSO) for multi-client transaction tests
go run ./scripts/tso --addr 127.0.0.1:9494 --start 100

# Local three-node cluster (includes manifest bootstrap + optional TSO)
./scripts/run_local_cluster.sh --config ./raft_config.example.json
# Tear down with Ctrl+C

# Docker-compose sandbox (3 nodes + TSO)
docker compose up --build
docker compose down -v

# Build RocksDB locally (installs into ./third_party/rocksdb/dist by default)
./scripts/build_rocksdb.sh
# YCSB baseline (records=1e6, ops=1e6, warmup=1e5, conc=16)
./scripts/run_benchmarks.sh
# YCSB with RocksDB (requires CGO, `benchmark_rocksdb`, and the RocksDB build above)
LD_LIBRARY_PATH="$(pwd)/third_party/rocksdb/dist/lib:${LD_LIBRARY_PATH}" \
CGO_CFLAGS="-I$(pwd)/third_party/rocksdb/dist/include" \
CGO_LDFLAGS="-L$(pwd)/third_party/rocksdb/dist/lib -lrocksdb -lz -lbz2 -lsnappy -lzstd -llz4" \
YCSB_ENGINES="nokv,badger,rocksdb" ./scripts/run_benchmarks.sh
# One-click script (auto-detect RocksDB, supports `YCSB_*` env vars to override defaults)
./scripts/run_benchmarks.sh
# Quick smoke run (smaller dataset)
NOKV_RUN_BENCHMARKS=1 YCSB_RECORDS=10000 YCSB_OPS=50000 YCSB_WARM_OPS=0 \
./scripts/run_benchmarks.sh -ycsb_workloads=A -ycsb_engines=nokv
</code></pre>
<blockquote>
<p>Tip: Pin <code>GOCACHE</code>/<code>GOMODCACHE</code> in CI to keep build artefacts local and avoid permission issues.</p>
</blockquote>
<hr>
<h2 id="2-module-coverage-overview"><a class="header" href="#2-module-coverage-overview">2. Module Coverage Overview</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Module</th><th>Tests</th><th>Coverage Highlights</th><th>Gaps / Next Steps</th></tr>
</thead>
<tbody>
<tr><td>WAL</td><td><code>wal/manager_test.go</code></td><td>Segment rotation, sync semantics, replay tolerance for truncation, directory bootstrap.</td><td>Add IO fault injection, concurrent append stress.</td></tr>
<tr><td>LSM / Flush / Compaction</td><td><code>lsm/lsm_test.go</code>, <code>lsm/compact_test.go</code>, <code>lsm/flush/*_test.go</code></td><td>Memtable correctness, iterator merging, flush pipeline metrics, compaction scheduling.</td><td>Extend backpressure assertions, test cache hot/cold split.</td></tr>
<tr><td>Manifest</td><td><code>manifest/manager_test.go</code>, <code>manifest/levels_test.go</code></td><td>CURRENT swap safety, rewrite crash handling, vlog metadata persistence.</td><td>Simulate partial edit corruption, column family extensions.</td></tr>
<tr><td>ValueLog</td><td><code>vlog/vlog_test.go</code>, <code>vlog/gc_test.go</code></td><td>ValuePtr encoding/decoding, GC rewrite, concurrent iterator safety.</td><td>Long-running GC with transactions, discard ratio edge cases.</td></tr>
<tr><td>Transactions / Oracle</td><td><code>txn_test.go</code>, <code>txn_iterator_test.go</code>, <code>txn_metrics_test.go</code></td><td>MVCC timestamps, conflict detection, iterator snapshots, metrics accounting.</td><td>Mixed workload fuzzing, managed transactions with TTL.</td></tr>
<tr><td>DB Integration</td><td><code>db_test.go</code>, <code>db_recovery_test.go</code>, <code>db_recovery_managed_test.go</code></td><td>End-to-end writes, recovery, managed vs. unmanaged transactions, throttle behaviour.</td><td>Combine ValueLog GC + compaction stress, multi-DB interference.</td></tr>
<tr><td>CLI &amp; Stats</td><td><code>cmd/nokv/main_test.go</code>, <code>stats_test.go</code></td><td>Golden JSON output, stats snapshot correctness, hot key ranking.</td><td>CLI error handling, expvar HTTP integration tests.</td></tr>
<tr><td>Redis Gateway</td><td><code>cmd/nokv-redis/backend_embedded_test.go</code>, <code>cmd/nokv-redis/server_test.go</code>, <code>cmd/nokv-redis/backend_raft_test.go</code></td><td>Embedded backend semantics (NX/XX, TTL, counters), RESP parser, raft backend config wiring &amp; TSO discovery.</td><td>End-to-end multi-region CRUD with raft backend, TTL lock cleanup under failures.</td></tr>
<tr><td>Scripts &amp; Tooling</td><td><code>scripts/scripts_test.go</code>, <code>cmd/nokv-config/main_test.go</code></td><td><code>serve_from_config.sh</code> address scoping (host/docker) and manifest skipping, <code>nokv-config</code> JSON/simple formats, manifest logging CLI.</td><td>Golden coverage for <code>run_local_cluster.sh</code>, failure-path diagnostics.</td></tr>
<tr><td>Benchmark</td><td><code>benchmark/ycsb_test.go</code>, <code>benchmark/ycsb_runner.go</code></td><td>YCSB throughput/latency comparisons across engines with detailed percentile + operation mix reporting.</td><td>Automate multi-node deployments, add more workloads (D/E/F) and multi-GB datasets.</td></tr>
</tbody>
</table>
</div>
<hr>
<h2 id="3-system-scenarios"><a class="header" href="#3-system-scenarios">3. System Scenarios</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Scenario</th><th>Coverage</th><th>Focus</th></tr>
</thead>
<tbody>
<tr><td>Crash recovery</td><td><code>db_recovery_test.go</code>, <code>scripts/recovery_scenarios.sh</code></td><td>WAL replay, missing SST cleanup, vlog GC restart, manifest rewrite safety.</td></tr>
<tr><td>WAL pointer desync</td><td><code>raftstore/engine/wal_storage_test.go::TestWALStorageDetectsTruncatedSegment</code></td><td>Detects manifest pointer offsets beyond truncated WAL tails to avoid silent corruption.</td></tr>
<tr><td>Transaction contention</td><td><code>TestConflict</code>, <code>TestTxnReadAfterWrite</code>, <code>TestTxnDiscard</code></td><td>Oracle watermark handling, conflict errors, managed commit path.</td></tr>
<tr><td>Value separation + GC</td><td><code>vlog/gc_test.go</code>, <code>db_recovery_test.go::TestRecoveryRemovesStaleValueLogSegment</code></td><td>GC correctness, manifest integration, iterator stability.</td></tr>
<tr><td>Iterator consistency</td><td><code>txn_iterator_test.go</code>, <code>lsm/iterator_test.go</code></td><td>Snapshot visibility, merging iterators across levels and memtables.</td></tr>
<tr><td>Throttling / backpressure</td><td><code>lsm/compact_test.go</code>, <code>db_test.go::TestWriteThrottle</code></td><td>L0 backlog triggers, flush queue growth, metrics observation.</td></tr>
<tr><td>Distributed TinyKv client</td><td><code>raftstore/client/client_test.go::TestClientTwoPhaseCommitAndGet</code>, <code>raftstore/transport/grpc_transport_test.go::TestGRPCTransportManualTicksDriveElection</code></td><td>Region-aware routing, NotLeader retries, manual tick-driven elections, cross-region 2PC sequencing.</td></tr>
<tr><td>Performance regression</td><td><code>benchmark</code> package</td><td>Compare NoKV vs Badger/RocksDB, produce human-readable reports under <code>benchmark/benchmark_results</code>.</td></tr>
</tbody>
</table>
</div>
<hr>
<h2 id="4-observability-in-tests"><a class="header" href="#4-observability-in-tests">4. Observability in Tests</a></h2>
<ul>
<li><strong>RECOVERY_METRIC logs</strong> â€“ produced when <code>RECOVERY_TRACE_METRICS=1</code>; consumed by recovery script and helpful when triaging CI failures.</li>
<li><strong>TRANSPORT_METRIC logs</strong> â€“ emitted by <code>scripts/transport_chaos.sh</code> when <code>CHAOS_TRACE_METRICS=1</code>, capturing gRPC watchdog counters during network partitions and retries.</li>
<li><strong>Stats snapshots</strong> â€“ <code>stats_test.go</code> verifies JSON structure so CLI output remains backwards compatible.</li>
<li><strong>Benchmark artefacts</strong> â€“ stored under <code>benchmark/benchmark_results/*.txt</code> for historical comparison. Aligns with README instructions.</li>
</ul>
<hr>
<h2 id="5-extending-coverage"><a class="header" href="#5-extending-coverage">5. Extending Coverage</a></h2>
<ol>
<li><strong>Property-based testing</strong> â€“ integrate <code>testing/quick</code> or third-party generators to randomise transaction sequences (Badger uses similar fuzz tests for transaction ordering).</li>
<li><strong>Stress harness</strong> â€“ add a Go-based stress driver to run mixed read/write workloads for hours, capturing metrics akin to RocksDBâ€™s <code>db_stress</code> tool.</li>
<li><strong>Distributed readiness</strong> â€“ when Raft or replication is introduced, craft tests that validate WAL shipping combined with manifest updates.</li>
<li><strong>CLI smoke tests</strong> â€“ simulate corrupted directories to ensure CLI emits actionable errors.</li>
</ol>
<p>Keep this matrix updated when adding new modules or scenarios so documentation and automation remain aligned.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="scripts-overview"><a class="header" href="#scripts-overview">Scripts Overview</a></h1>
<p>NoKV ships a small collection of helper scripts to streamline local experimentation, demos, diagnostics, and automation. This page summarises what each script does, how to use it, and which shared configuration it consumes.</p>
<hr>
<h2 id="cluster-helpers"><a class="header" href="#cluster-helpers">Cluster helpers</a></h2>
<h3 id="scriptsrun_local_clustersh"><a class="header" href="#scriptsrun_local_clustersh"><code>scripts/run_local_cluster.sh</code></a></h3>
<ul>
<li><strong>Purpose</strong> â€“ builds <code>nokv</code>, <code>nokv-config</code>, and <code>nokv-tso</code>, reads <code>raft_config.json</code>, seeds manifests, and starts the TinyKv nodes (plus TSO when configured). If a store directory already contains a manifest (<code>CURRENT</code>), the seeding step is skipped so previously bootstrapped data is reused.</li>
<li><strong>Usage</strong>
<pre><code class="language-bash">./scripts/run_local_cluster.sh --config ./raft_config.example.json --workdir ./artifacts/cluster
</code></pre>
</li>
</ul>
<p><code>--config</code> defaults to the repositoryâ€™s <code>raft_config.example.json</code>; <code>--workdir</code> chooses the data root (<code>./artifacts/cluster</code> by default). For every entry under <code>stores</code> the script creates <code>store-&lt;id&gt;</code>, calls <code>nokv-config manifest</code>, and, if <code>tso.listen_addr</code> is set, launches <code>nokv-tso</code>. The script runs in the foregroundâ€”press <code>Ctrl+C</code> to stop all spawned processes.</p>
<blockquote>
<p>â—ï¸ <strong>Shutdown / restart note</strong> â€” To avoid WAL/manifest mismatches, always stop the script with <code>Ctrl+C</code> and wait for the <code>Shutting down...</code> message. If you crash the process or the host, clean the workdir (<code>rm -rf ./artifacts/cluster</code>) before starting again; otherwise the replay step may panic when it encounters truncated WAL segments.</p>
</blockquote>
<h3 id="scriptsbootstrap_from_configsh"><a class="header" href="#scriptsbootstrap_from_configsh"><code>scripts/bootstrap_from_config.sh</code></a></h3>
<ul>
<li><strong>Purpose</strong> â€“ manifest-only bootstrap, typically used in Docker Compose before the nodes start. Stores that already hold a manifest are detected and skipped.</li>
<li><strong>Usage</strong>
<pre><code class="language-bash">./scripts/bootstrap_from_config.sh --config /etc/nokv/raft_config.json --path-template /data/store-{id}
</code></pre>
The script iterates over every store in the config and writes Region metadata via <code>nokv-config manifest</code> into the provided path template.</li>
</ul>
<h3 id="scriptsserve_from_configsh"><a class="header" href="#scriptsserve_from_configsh"><code>scripts/serve_from_config.sh</code></a></h3>
<ul>
<li><strong>Purpose</strong> â€“ translate <code>raft_config.json</code> into a <code>nokv serve</code> command, avoiding manual <code>--peer</code> lists. It resolves peer IDs from the region metadata and maps every peer (other than the local store) to its advertised address so that gRPC transport works out of the box.</li>
<li><strong>Usage</strong>
<pre><code class="language-bash">./scripts/serve_from_config.sh \
    --config ./raft_config.json \
    --store-id 1 \
    --workdir ./artifacts/cluster/store-1 \
    --scope local   # use --scope docker inside containers
</code></pre>
<code>--scope</code> decides whether to use the local addresses or the container-friendly ones. The script assembles all peer mappings (excluding the local store) and execs <code>nokv serve</code>.</li>
</ul>
<hr>
<h2 id="diagnostics--benchmarking"><a class="header" href="#diagnostics--benchmarking">Diagnostics &amp; benchmarking</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Script</th><th>Purpose</th></tr>
</thead>
<tbody>
<tr><td><code>scripts/recovery_scenarios.sh</code></td><td>Runs crash-recovery scenarios across WAL/manifest/vlog. Set <code>RECOVERY_TRACE_METRICS=1</code> to collect metrics under <code>artifacts/recovery/</code>.</td></tr>
<tr><td><code>scripts/transport_chaos.sh</code></td><td>Injects disconnects/blocks/delay into the <code>raftstore</code> transport to observe behaviour under faulty networks.</td></tr>
<tr><td><code>scripts/run_benchmarks.sh</code></td><td>Executes the comparison benchmarks (NoKV vs Badger/RocksDB).</td></tr>
<tr><td><code>scripts/analyze_pprof.sh</code></td><td>Aggregates CPU/heap profiles from <code>pprof_output/</code> and renders SVG/PNG summaries.</td></tr>
<tr><td><code>scripts/debug.sh</code></td><td>Convenience wrapper around <code>dlv test</code> for targeted debugging.</td></tr>
<tr><td><code>scripts/gen.sh</code></td><td>Generates mock data or helper artefacts (see inline comments for details).</td></tr>
</tbody>
</table>
</div>
<hr>
<h2 id="other-helpers"><a class="header" href="#other-helpers">Other helpers</a></h2>
<h3 id="scriptstso"><a class="header" href="#scriptstso"><code>scripts/tso</code></a></h3>
<p>A small Go program (not shell) that exposes an HTTP timestamp oracle:</p>
<pre><code class="language-bash">go run ./scripts/tso --addr 0.0.0.0:9494 --start 100
</code></pre>
<p><code>run_local_cluster.sh</code> and Docker Compose invoke it automatically when <code>tso.listen_addr</code> is present in the shared config.</p>
<hr>
<h2 id="relationship-with-nokv-config"><a class="header" href="#relationship-with-nokv-config">Relationship with <code>nokv-config</code></a></h2>
<ul>
<li><code>nokv-config stores</code> / <code>regions</code> / <code>tso</code> provide structured views over <code>raft_config.json</code>, making it easy for scripts and CI to query the topology.</li>
<li><code>nokv-config manifest</code> writes Region metadata into manifests and replaces the historical <code>manifestctl</code> binary.</li>
<li><code>cmd/nokv-redis</code> reads the same config; when <code>--tso-url</code> is omitted it falls back to the <code>tso</code> section.</li>
<li>Go tools or custom scripts can import <code>github.com/feichai0017/NoKV/config</code> and call <code>config.LoadFile</code> / <code>Validate</code> to consume the same <code>raft_config.json</code>, avoiding divergent schemas.</li>
</ul>
<p>Maintaining a single <code>raft_config.json</code> keeps local scripts, Docker Compose, Redis gateway, and automated tests aligned.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="redis-gateway"><a class="header" href="#redis-gateway">Redis Gateway</a></h1>
<p><code>cmd/nokv-redis</code> exposes NoKV through a RESP-compatible endpoint. The gateway reuses the engineâ€™s MVCC/transaction semantics and can operate in two modes:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Mode</th><th>Description</th><th>Key flags</th></tr>
</thead>
<tbody>
<tr><td>Embedded (<code>embedded</code>)</td><td>Opens a local <code>*NoKV.DB</code> work directory. Commands (<code>SET</code>, <code>SET NX/XX</code>, <code>EX/PX/EXAT/PXAT</code>, <code>MSET</code>, <code>INCR/DECR</code>, <code>DEL</code>, <code>MGET</code>, <code>EXISTS</code>, â€¦) run inside <code>db.Update</code> / <code>db.View</code>, providing atomic single-key updates and snapshot reads across multiple keys.</td><td><code>--workdir &lt;dir&gt;</code></td></tr>
<tr><td>Raft (<code>raft</code>)</td><td>Routes requests through <code>raftstore/client</code> and a TinyKv cluster. Writes execute via TwoPhaseCommit; TTL metadata is stored under <code>!redis:ttl!&lt;key&gt;</code>. When <code>--tso-url</code> is omitted, the gateway consults the <code>tso</code> block in <code>raft_config.json</code> and falls back to a local oracle if the block is absent.</td><td><code>--raft-config &lt;file&gt;</code><br><code>--tso-url http://host:port</code> (optional)</td></tr>
</tbody>
</table>
</div>
<h2 id="usage-examples"><a class="header" href="#usage-examples">Usage examples</a></h2>
<h3 id="embedded-backend"><a class="header" href="#embedded-backend">Embedded backend</a></h3>
<pre><code class="language-bash">go run ./cmd/nokv-redis \
  --addr 127.0.0.1:6380 \
  --workdir ./work_redis \
  --metrics-addr 127.0.0.1:9100  # optional expvar endpoint
</code></pre>
<p>Validate with <code>redis-cli -p 6380 ping</code>. Metrics are exposed at <code>http://127.0.0.1:9100/debug/vars</code> under <code>NoKV.Stats.redis</code>.</p>
<h3 id="raft-backend"><a class="header" href="#raft-backend">Raft backend</a></h3>
<ol>
<li>
<p>Start TinyKv and, if configured, the TSO using the helper script or Docker Compose. Both consume <code>raft_config.example.json</code>, initialise manifests for each store, and launch <code>nokv-tso</code> automatically when <code>tso.listen_addr</code> is present:</p>
<pre><code class="language-bash">./scripts/run_local_cluster.sh
# or: docker compose up --build
</code></pre>
</li>
<li>
<p>Run the gateway:</p>
<pre><code class="language-bash">go run ./cmd/nokv-redis \
  --addr 127.0.0.1:6380 \
  --raft-config raft_config.example.json
</code></pre>
<p>Supply <code>--tso-url</code> only when you need to override the config file; otherwise the gateway uses <code>tso.advertise_url</code> (or <code>listen_addr</code>) from the same JSON. If the block is missing, it falls back to the embedded timestamp oracle.</p>
</li>
</ol>
<h2 id="supported-commands"><a class="header" href="#supported-commands">Supported commands</a></h2>
<ul>
<li>String operations: <code>GET</code>, <code>SET</code>, <code>SET NX/XX</code>, <code>EX/PX/EXAT/PXAT</code>, <code>DEL</code>, <code>MGET</code>, <code>MSET</code>, <code>EXISTS</code></li>
<li>Integer operations: <code>INCR</code>, <code>DECR</code>, <code>INCRBY</code>, <code>DECRBY</code></li>
<li>Utility: <code>PING</code>, <code>ECHO</code>, <code>QUIT</code></li>
</ul>
<p>In both modes write commands are atomic. The Raft backend batches multi-key updates (<code>MSET</code>, <code>DEL</code>, â€¦) into a single TwoPhaseCommit, matching the embedded semantics. Reads use snapshot transactions locally (<code>db.View</code>) and leader reads with TTL checks remotely.</p>
<h2 id="configuration-file"><a class="header" href="#configuration-file">Configuration file</a></h2>
<p><code>raft_config.example.json</code> is shared by <code>scripts/run_local_cluster.sh</code>, Docker Compose, and the Redis gateway. Important fields:</p>
<ul>
<li><code>stores</code> â€“ store ID, gRPC address, and optional container listen/advertise addresses</li>
<li><code>regions</code> â€“ region ID, start/end keys (use <code>hex:&lt;bytes&gt;</code> for binary data), epoch, peer list, leader store ID</li>
<li><code>max_retries</code> â€“ maximum retries for region errors in the distributed client</li>
</ul>
<p>Use <code>nokv-config</code> to inspect or validate the configuration:</p>
<pre><code class="language-bash">nokv-config stores --config raft_config.json
nokv-config regions --config raft_config.json --format json | jq '.[] | {id:.id, peers:.peers}'
</code></pre>
<p>For Go tooling, import <code>github.com/feichai0017/NoKV/config</code> and call <code>config.LoadFile</code> / <code>Validate</code> to reuse the same schema and defaults across CLIs, scripts, and applications.</p>
<h2 id="metrics"><a class="header" href="#metrics">Metrics</a></h2>
<p>With <code>--metrics-addr</code> enabled the gateway publishes Redis metrics as part of <code>NoKV.Stats</code> on <code>/debug/vars</code>, for example:</p>
<pre><code class="language-json">{
  "NoKV.Stats": {
    "redis": {
      "commands_total": 128,
      "errors_total": 0,
      "connections_active": 1,
      "connections_accepted": 4,
      "commands_per_operation": {
        "PING": 4,
        "SET": 32,
        "GET": 64,
        "MGET": 8,
        "DEL": 10,
        "INCR": 10
      }
    }
  }
}
</code></pre>
<p>These counters are part of the process-wide expvar output and can be scraped alongside the rest of NoKVâ€™s metrics.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="notes"><a class="header" href="#notes">Notes</a></h1>
<p>Use this folder to capture per-debug or per-investigation notes. Keep entries short, factual, and easy to skim.</p>
<h2 id="add-a-new-note"><a class="header" href="#add-a-new-note">Add a new note</a></h2>
<ol>
<li>Create a new file in <code>docs/notes/</code> named <code>YYYY-MM-DD-short-title.md</code>.</li>
<li>Add it to <code>docs/SUMMARY.md</code> under Notes.</li>
<li>Use the template below to keep entries consistent.</li>
</ol>
<h2 id="template"><a class="header" href="#template">Template</a></h2>
<h3 id="context"><a class="header" href="#context">Context</a></h3>
<h3 id="symptom"><a class="header" href="#symptom">Symptom</a></h3>
<h3 id="repro"><a class="header" href="#repro">Repro</a></h3>
<h3 id="investigation"><a class="header" href="#investigation">Investigation</a></h3>
<h3 id="root-cause"><a class="header" href="#root-cause">Root cause</a></h3>
<h3 id="fix"><a class="header" href="#fix">Fix</a></h3>
<h3 id="follow-ups"><a class="header" href="#follow-ups">Follow-ups</a></h3>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="2026-01-16-mmap-choice"><a class="header" href="#2026-01-16-mmap-choice">2026-01-16 mmap choice</a></h1>
<p>æœ¬æ–‡æ¡£è¯¦ç»†å¯¹æ¯”äº†ä¸»æµæ–‡ä»¶ I/O æ¨¡å‹çš„å·®å¼‚ï¼Œå¹¶è§£æ NoKV åœ¨ä¸åŒç»„ä»¶ï¼ˆSSTable, WAL, VLogï¼‰ä¸­åšå‡ºä¸åŒ I/O é€‰æ‹©çš„æ·±å±‚åŸå› ä¸æƒè¡¡ã€‚</p>
<h2 id="1-io-æ¨¡å‹çš„å››å›½æ€"><a class="header" href="#1-io-æ¨¡å‹çš„å››å›½æ€">1. I/O æ¨¡å‹çš„å››å›½æ€</a></h2>
<p>åœ¨ Linux/Unix ç¯å¢ƒä¸‹ï¼Œæˆ‘ä»¬åœ¨è®¾è®¡å­˜å‚¨å¼•æ“æ—¶é€šå¸¸é¢ä¸´å››ç§é€‰æ‹©ã€‚ç†è§£å®ƒä»¬çš„ä¼˜åŠ£æ˜¯åšå‡ºæ­£ç¡®æ¶æ„å†³ç­–çš„å‰æã€‚</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th style="text-align: left">ç‰¹æ€§</th><th style="text-align: left">æ ‡å‡† I/O (<code>read</code>/<code>write</code>)</th><th style="text-align: left">å†…å­˜æ˜ å°„ (<code>mmap</code>)</th><th style="text-align: left">ç›´æ¥ I/O (<code>O_DIRECT</code>)</th><th style="text-align: left">å¼‚æ­¥ I/O (<code>io_uring</code>)</th></tr>
</thead>
<tbody>
<tr><td style="text-align: left"><strong>æœºåˆ¶</strong></td><td style="text-align: left">ç³»ç»Ÿè°ƒç”¨ï¼Œæ•°æ®åœ¨ Kernel Buffer å’Œ User Buffer é—´æ‹·è´</td><td style="text-align: left">å»ºç«‹è™šæ‹Ÿå†…å­˜æ˜ å°„ï¼Œç¼ºé¡µä¸­æ–­åŠ è½½ï¼Œ<strong>é›¶æ‹·è´</strong></td><td style="text-align: left">ç»•è¿‡ Page Cacheï¼Œç›´æ¥ DMA åˆ°ç”¨æˆ·å†…å­˜</td><td style="text-align: left">æäº¤è¯·æ±‚é˜Ÿåˆ—ï¼Œå†…æ ¸å¼‚æ­¥å®Œæˆï¼Œé›¶ç³»ç»Ÿè°ƒç”¨å¼€é”€</td></tr>
<tr><td style="text-align: left"><strong>ä¼˜åŠ¿</strong></td><td style="text-align: left">ç®€å•ï¼Œé€šç”¨ï¼ŒPage Cache è‡ªåŠ¨é¢„è¯»</td><td style="text-align: left"><strong>è¯»å»¶è¿Ÿæä½</strong> (åƒè®¿é—®å†…å­˜ä¸€æ ·)ï¼Œä»£ç ç®€å•</td><td style="text-align: left"><strong>å®Œå…¨å¯æ§</strong> (å†…å­˜/åˆ·ç›˜)ï¼Œæ—  GC å¹²æ‰°</td><td style="text-align: left">ååé‡æé«˜ï¼ŒCPU å ç”¨ä½</td></tr>
<tr><td style="text-align: left"><strong>ç—›ç‚¹</strong></td><td style="text-align: left"><strong>æ‹·è´å¼€é”€</strong> (CPU copy)ï¼Œé«˜é¢‘è°ƒç”¨ Context Switch</td><td style="text-align: left"><strong>ä¸å¯æ§</strong> (Page Fault é˜»å¡ï¼ŒTLB shootdown)ï¼Œå¤§æ–‡ä»¶æ±¡æŸ“ Cache</td><td style="text-align: left"><strong>å¤æ‚</strong> (éœ€è‡ªå»º Buffer Poolï¼Œå¯¹é½é™åˆ¶)</td><td style="text-align: left"><strong>æå¤æ‚</strong> (ç¼–ç¨‹æ¨¡å‹å®Œå…¨ä¸åŒ)</td></tr>
<tr><td style="text-align: left"><strong>é€‚ç”¨</strong></td><td style="text-align: left">æ—¥å¿—è¿½åŠ  (WAL)</td><td style="text-align: left">åªè¯»ç´¢å¼•ï¼Œéšæœºå°è¯» (SSTable)</td><td style="text-align: left">æ•°æ®åº“è‡ªç®¡ç†ç¼“å­˜ (MySQL, ScyllaDB)</td><td style="text-align: left">è¶…é«˜å¹¶å‘ç½‘ç»œ/ç£ç›˜ IO</td></tr>
</tbody>
</table>
</div>
<hr>
<h2 id="2-nokv-çš„é€‰æ‹©å› åœ°åˆ¶å®œ"><a class="header" href="#2-nokv-çš„é€‰æ‹©å› åœ°åˆ¶å®œ">2. NoKV çš„é€‰æ‹©ï¼šå› åœ°åˆ¶å®œ</a></h2>
<p>NoKV æ²¡æœ‰â€œä¸€ç§ IO èµ°å¤©ä¸‹â€ï¼Œè€Œæ˜¯æ ¹æ®ä¸åŒç»„ä»¶çš„è®¿é—®æ¨¡å¼ï¼ˆAccess Patternï¼‰é€‰æ‹©äº†æœ€é€‚åˆçš„æ–¹æ¡ˆã€‚</p>
<h3 id="21-sstableåšå®šé€‰æ‹©-mmap"><a class="header" href="#21-sstableåšå®šé€‰æ‹©-mmap">2.1 SSTableï¼šåšå®šé€‰æ‹© <code>mmap</code></a></h3>
<p>SSTable æ˜¯ LSM Tree çš„æ•°æ®æ–‡ä»¶ï¼Œå…·æœ‰ <strong>ä¸å¯å˜ (Immutable)</strong> å’Œ <strong>éšæœºè¯» (Random Read)</strong> çš„ç‰¹æ€§ã€‚</p>
<ul>
<li><strong>ç—›ç‚¹</strong>ï¼šå¦‚æœç”¨æ ‡å‡† <code>pread</code>ï¼Œæ¯æ¬¡ <code>Get(key)</code> éƒ½è¦å‘èµ·ä¸€æ¬¡ç³»ç»Ÿè°ƒç”¨ã€‚åœ¨ 100k QPS ä¸‹ï¼Œä¸Šä¸‹æ–‡åˆ‡æ¢ï¼ˆContext Switchï¼‰çš„å¼€é”€æ˜¯å·¨å¤§çš„ã€‚</li>
<li><strong>mmap çš„è§£æ³•</strong>ï¼š
<ul>
<li><strong>é›¶æ‹·è´</strong>ï¼šæ•°æ®ç›´æ¥æ˜ å°„åˆ°ç”¨æˆ·ç©ºé—´ï¼Œ<code>slice = data[offset:len]</code>ï¼Œæ²¡æœ‰ <code>memcpy</code>ã€‚</li>
<li><strong>é›¶ç³»ç»Ÿè°ƒç”¨</strong>ï¼šçƒ­ç‚¹æ•°æ®å¦‚æœåœ¨ç‰©ç†å†…å­˜ä¸­ï¼Œè¯»å–å°±æ˜¯çº¯å†…å­˜è®¿é—®ï¼Œçº³ç§’çº§å»¶è¿Ÿã€‚</li>
<li><strong>OS å¸®æˆ‘ç®¡ç¼“å­˜</strong>ï¼šåˆ©ç”¨æ“ä½œç³»ç»Ÿçš„ Page Cache ç®¡ç†çƒ­ç‚¹ï¼Œä¸ç”¨è‡ªå·±å†™å¤æ‚çš„ LRU Cacheã€‚</li>
</ul>
</li>
</ul>
<h3 id="22-walå›å½’æ ‡å‡†-osfile--bufio"><a class="header" href="#22-walå›å½’æ ‡å‡†-osfile--bufio">2.2 WALï¼šå›å½’æ ‡å‡† <code>os.File</code> + <code>bufio</code></a></h3>
<p>WAL (Write Ahead Log) æ˜¯ <strong>é¡ºåºè¿½åŠ  (Append Only)</strong> ä¸” <strong>æŒä¹…åŒ–æ•æ„Ÿ</strong> çš„ã€‚</p>
<ul>
<li><strong>mmap çš„ç—›ç‚¹</strong>ï¼š
<ul>
<li><strong>æ–‡ä»¶æ‰©å®¹éº»çƒ¦</strong>ï¼šmmap éœ€è¦é¢„å…ˆ <code>ftruncate</code> å ä½ï¼Œå†™æ»¡äº†è¦ <code>remap</code>ï¼Œè¿™åœ¨è¿½å†™åœºæ™¯ä¸‹å¾ˆç¬¨é‡ã€‚</li>
<li><strong>è½ç›˜ä¸å¯æ§</strong>ï¼šè™½ç„¶æœ‰ <code>msync</code>ï¼Œä½† OS ä½•æ—¶æŠŠ Dirty Page åˆ·ç›˜æ˜¯ä¸ç¡®å®šçš„ã€‚å¯¹äºè¦æ±‚ <code>fsync</code> ä¸¥æ ¼è½ç›˜çš„ WALï¼Œæ ‡å‡† IO æ›´å¯æ§ã€‚</li>
</ul>
</li>
<li><strong>NoKV çš„é€‰æ‹©</strong>ï¼šä½¿ç”¨æ ‡å‡† I/O é…åˆ <code>bufio.Writer</code>ã€‚
<ul>
<li><code>bufio</code> æä¾›äº†ç”¨æˆ·æ€ç¼“å†²ï¼Œå‡å°‘äº† <code>write</code> ç³»ç»Ÿè°ƒç”¨æ¬¡æ•°ã€‚</li>
<li><code>fsync</code> è¯­ä¹‰æ¸…æ™°ï¼Œç¡®ä¿æ•°æ®ä¸ä¸¢ã€‚</li>
</ul>
</li>
</ul>
<h3 id="23-valuelogç›®å‰çš„å¦¥å-mmap--madvise"><a class="header" href="#23-valuelogç›®å‰çš„å¦¥å-mmap--madvise">2.3 ValueLogï¼šç›®å‰çš„å¦¥å (mmap + madvise)</a></h3>
<p>ValueLog ä¹Ÿæ˜¯ <strong>é¡ºåºå†™</strong>ï¼Œä½†é¢ä¸´ <strong>éšæœºè¯»</strong>ï¼ˆKV åˆ†ç¦»æŸ¥è¯¢æ—¶ï¼‰ã€‚</p>
<ul>
<li><strong>ç°çŠ¶</strong>ï¼šNoKV ç›®å‰å¯¹ VLog ä¹Ÿä½¿ç”¨äº† <code>mmap</code>ã€‚</li>
<li><strong>å†™å…¥æ§åˆ¶</strong>ï¼šè™½ç„¶ä½¿ç”¨ mmap å†™å…¥ï¼Œä½†ä»£ç ä¸­æ˜¾å¼è°ƒç”¨äº† <code>madvise(MADV_DONTNEED)</code>ã€‚
<ul>
<li>åœ¨ <code>DoneWriting</code>ï¼ˆæ–‡ä»¶å†™æ»¡è½®è½¬ï¼‰å’Œ <code>SetReadOnly</code> æ—¶ï¼Œç³»ç»Ÿä¼šé€šçŸ¥å†…æ ¸â€œæˆ‘ä¸å†éœ€è¦è¿™äº›é¡µé¢äº†â€ã€‚</li>
<li><strong>ç›®çš„</strong>ï¼šä¸»åŠ¨é‡Šæ”¾ VLog åˆšåˆšå†™å…¥çš„å¤§é‡è„é¡µå ç”¨çš„ Page Cacheï¼Œé˜²æ­¢å®ƒä»¬æŠŠ SSTable çš„çƒ­ç‚¹æ•°æ®ï¼ˆç´¢å¼•ã€Filterï¼‰æŒ¤å‡ºå†…å­˜ã€‚</li>
</ul>
</li>
<li><strong>æŒä¹…åŒ–</strong>ï¼šåªæœ‰å½“ <code>SyncWrites: true</code> æ—¶ï¼Œæ‰ä¼šè°ƒç”¨ <code>msync</code>ã€‚å¹³æ—¶ä¾èµ– OS çš„åå°åˆ·ç›˜ã€‚</li>
</ul>
<hr>
<h2 id="3-è¯»å†™äº¤äº’é€»è¾‘å›¾"><a class="header" href="#3-è¯»å†™äº¤äº’é€»è¾‘å›¾">3. è¯»å†™äº¤äº’é€»è¾‘å›¾</a></h2>
<p>ä¸‹é¢è¿™å¼ å›¾å±•ç¤ºäº†ä¸åŒ IO æ¨¡å‹åœ¨ NoKV è¯»å†™æµä¸­çš„ä½ç½®ï¼š</p>
<pre class="mermaid">flowchart TD
    subgraph "Write Path"
        Mem[MemTable]
        WAL["WAL (Standard IO)"]
        Flush["Flush/Compact"]
    end
    
    subgraph "Persistence"
        SST["SSTable (mmap)"]
        VLog["ValueLog (mmap)"]
    end
    
    Write["Set(k, v)"] --&gt; Mem
    Write --&gt; WAL
    
    Mem --&gt;|Full| Flush
    Flush --&gt;|"Small Values"| SST
    Flush --&gt;|"Large Values"| VLog
    
    subgraph "Read Path"
        Get["Get(k)"]
        LSM["LSM Search"]
        
        Get --&gt; LSM
        LSM --&gt;|"1. Index Lookups"| SST
        SST --&gt;|"2. Zero Copy Read"| Kernel["Page Cache"]
        
        LSM --&gt;|"3. ValuePtr Found"| VLog
        VLog --&gt;|"4. Random Read"| Kernel
    end
    
    style WAL fill:#f9f,stroke:#333,stroke-width:2px
    style SST fill:#bfb,stroke:#333,stroke-width:2px
    style VLog fill:#bfb,stroke:#333,stroke-width:2px
</pre>

<h2 id="4-æ€»ç»“"><a class="header" href="#4-æ€»ç»“">4. æ€»ç»“</a></h2>
<p>NoKV çš„ I/O é€‰å‹ç­–ç•¥æ˜¯ <strong>â€œè¯»å†™åˆ†æ²»ï¼Œç¨³å®šä¸ºç‹â€</strong>ï¼š</p>
<ol>
<li><strong>è¯»å¯†é›† (SST)</strong>ï¼šé€‰ <code>mmap</code>ï¼Œæ¦¨å¹²å†…å­˜å¸¦å®½ï¼Œå‡å°‘ CPU å¼€é”€ã€‚</li>
<li><strong>å†™æ•æ„Ÿ (WAL)</strong>ï¼šé€‰ <code>Standard IO</code>ï¼Œç¡®ä¿æ•°æ®å®‰å…¨å’Œè¿½åŠ æ€§èƒ½ã€‚</li>
<li><strong>å¤§å®¹é‡ (VLog)</strong>ï¼šé€‰ <code>mmap</code> + <code>madvise</code>ï¼Œåˆ©ç”¨åˆ‡ç‰‡è¯»å–çš„ä¾¿åˆ©æ€§ï¼ŒåŒæ—¶ä¸»åŠ¨ç®¡ç†ç¼“å­˜æ±¡æŸ“ã€‚</li>
</ol>
<p>ç†è§£è¿™äº›æƒè¡¡ï¼Œæ˜¯æŒæ¡å­˜å‚¨å¼•æ“åº•å±‚æ€§èƒ½ä¼˜åŒ–çš„å…³é”®ã€‚</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="2026-01-16-hotring-design"><a class="header" href="#2026-01-16-hotring-design">2026-01-16 hotring design</a></h1>
<p>æœ¬æ–‡æ¡£è¯¦ç»†è®°å½•äº† NoKV ä¸­ <code>hotring</code> æ¨¡å—çš„è®¾è®¡çµæ„Ÿã€æ¶æ„å®šä½ã€æ ¸å¿ƒå®ç°ä»¥åŠæœªæ¥å±•æœ›ã€‚è¿™æ˜¯ä¸€ä¸ªä»å­¦æœ¯è®ºæ–‡æ±²å–çµæ„Ÿï¼Œå¹¶è½¬åŒ–ä¸ºå·¥ä¸šçº§â€œçƒ­ç‚¹æ¢æµ‹å™¨â€çš„å…¸å‹æ¡ˆä¾‹ã€‚</p>
<p>å½“å‰å®ç°å·²æŠ½ç¦»ä¸ºç‹¬ç«‹ä»“åº“ï¼š<code>github.com/feichai0017/hotring</code>ã€‚</p>
<hr>
<h2 id="1-è®¾è®¡çµæ„Ÿå–å…¶ç¥è€Œå¼ƒå…¶å½¢"><a class="header" href="#1-è®¾è®¡çµæ„Ÿå–å…¶ç¥è€Œå¼ƒå…¶å½¢">1. è®¾è®¡çµæ„Ÿï¼šå–å…¶ç¥è€Œå¼ƒå…¶å½¢</a></h2>
<p><strong>æ¥æº</strong>ï¼š<a href="https://www.usenix.org/conference/fast20/presentation/chen-jiqiang">HotRing: A Hotspot-Aware In-Memory Key-Value Store (FAST â€™20)</a></p>
<h3 id="11-è®ºæ–‡è§£å†³çš„ç—›ç‚¹"><a class="header" href="#11-è®ºæ–‡è§£å†³çš„ç—›ç‚¹">1.1 è®ºæ–‡è§£å†³çš„ç—›ç‚¹</a></h3>
<p>åœ¨ä¼ ç»Ÿçš„ Hash ç´¢å¼•ï¼ˆé“¾åœ°å€æ³•ï¼‰ä¸­ï¼Œå¦‚æœé“¾è¡¨å¾ˆé•¿ä¸”çƒ­ç‚¹æ•°æ®ä½äºé“¾è¡¨å°¾éƒ¨ï¼Œæ¯æ¬¡è®¿é—®çƒ­ç‚¹éƒ½éœ€è¦éå†å¤§é‡å†·æ•°æ®ï¼Œé€ æˆä¸¥é‡çš„ CPU Cache Miss å’Œé•¿å°¾å»¶è¿Ÿã€‚HotRing æå‡ºå°†é“¾è¡¨æ”¹ä¸º<strong>ç¯å½¢ç»“æ„</strong>ï¼Œå¹¶è®© Head æŒ‡é’ˆæ™ºèƒ½æŒ‡å‘çƒ­ç‚¹èŠ‚ç‚¹ï¼Œä»è€Œå®ç° $O(1)$ çš„çƒ­ç‚¹è®¿é—®ã€‚</p>
<h3 id="12-nokv-çš„å·¥ç¨‹è½¬åŒ–"><a class="header" href="#12-nokv-çš„å·¥ç¨‹è½¬åŒ–">1.2 NoKV çš„å·¥ç¨‹è½¬åŒ–</a></h3>
<p>NoKV å¹¶æ²¡æœ‰ç…§æ¬è®ºæ–‡ä½œä¸ºä¸»ç´¢å¼•ï¼ˆå› ä¸ºä¸»ç´¢å¼•æ˜¯ LSM Treeï¼‰ï¼Œè€Œæ˜¯æå–äº† <strong>â€œçƒ­ç‚¹æ„ŸçŸ¥â€</strong> è¿™ä¸€æ ¸å¿ƒæ€æƒ³ï¼Œè®¾è®¡äº†ä¸€ä¸ª<strong>è½»é‡çº§ã€æ—è·¯å¼</strong>çš„çƒ­ç‚¹ç»Ÿè®¡æ¨¡å—ã€‚</p>
<ul>
<li><strong>å·®å¼‚ç‚¹</strong>ï¼š
<ul>
<li><strong>å®šä½</strong>ï¼šè®ºæ–‡æ˜¯å­˜æ•°æ®çš„<strong>ç´¢å¼•</strong>ï¼›NoKV æ˜¯è®°è´¦çš„<strong>ç»Ÿè®¡å™¨</strong>ã€‚</li>
<li><strong>ç»“æ„</strong>ï¼šè®ºæ–‡æ˜¯<strong>ç¯å½¢é“¾è¡¨ + æ™ºèƒ½æŒ‡é’ˆ</strong>ï¼›NoKV æ˜¯<strong>åˆ†ç‰‡ Hash + æœ‰åºé“¾è¡¨ + æ»‘åŠ¨çª—å£</strong>ã€‚</li>
</ul>
</li>
<li><strong>æ ¸å¿ƒä»·å€¼</strong>ï¼šåœ¨ç™¾ä¸‡çº§ QPS ä¸‹ï¼Œä»¥æä½çš„å¼€é”€ï¼ˆLock-Free Listï¼‰ç²¾å‡†è¯†åˆ«ç³»ç»Ÿä¸­çš„â€œçƒ­ç‚¹â€ï¼Œä¸ºç¼“å­˜ä¼˜åŒ–å’Œé™æµæä¾›æ•°æ®æ”¯æ’‘ã€‚</li>
</ul>
<hr>
<h2 id="2-æ ¸å¿ƒæ¶æ„åé¦ˆé©±åŠ¨è®¾è®¡-feedback-driven"><a class="header" href="#2-æ ¸å¿ƒæ¶æ„åé¦ˆé©±åŠ¨è®¾è®¡-feedback-driven">2. æ ¸å¿ƒæ¶æ„ï¼šåé¦ˆé©±åŠ¨è®¾è®¡ (Feedback-Driven)</a></h2>
<p>NoKV çš„ HotRing ä¸ä»…ä»…æ˜¯ä¸€ä¸ªç»Ÿè®¡å·¥å…·ï¼Œå®ƒæ˜¯æ•´ä¸ªç³»ç»Ÿâ€œè‡ªé€‚åº”ä¼˜åŒ–â€çš„å¤§è„‘ã€‚</p>
<h3 id="21-æ¶æ„å…¨æ™¯å›¾"><a class="header" href="#21-æ¶æ„å…¨æ™¯å›¾">2.1 æ¶æ„å…¨æ™¯å›¾</a></h3>
<pre class="mermaid">graph TD
    Client[Client Request] --&gt; DB[DB Layer]
    
    subgraph "HotRing Subsystem (The Brain)"
        Tracker[Hot Key Tracker]
        Window[Sliding Window]
        Decay[Decay Loop]
    end
    
    subgraph "Execution Layer"
        LSM[LSM Tree]
        Cache[Block Cache]
        Compaction[Compaction Picker]
        Limiter[Write Limiter]
    end
    
    DB --&gt;|"1. Touch(key)"| Tracker
    Tracker --&gt;|"2. Update Counters"| Window
    Decay -.-&gt;|"3. Age Out"| Window
    
    Tracker -.-&gt;|"4. TopN Report"| Compaction
    Compaction --&gt;|"5. Hot Score"| LSM
</pre>

<h3 id="22-å…³é”®äº¤äº’æµç¨‹"><a class="header" href="#22-å…³é”®äº¤äº’æµç¨‹">2.2 å…³é”®äº¤äº’æµç¨‹</a></h3>
<ol>
<li><strong>æ¢æµ‹ (Probe)</strong>ï¼š
<ul>
<li><strong>è¯»è·¯å¾„</strong>ï¼šæ¯æ¬¡ <code>Get</code> å‘½ä¸­æ—¶è°ƒç”¨ <code>Touch</code>ã€‚</li>
<li><strong>å†™è·¯å¾„</strong>ï¼šåªæœ‰å½“å¯ç”¨äº†é™æµï¼ˆ<code>WriteHotKeyLimit</code>ï¼‰æˆ–çªå‘æ£€æµ‹æ—¶ï¼Œæ‰ä¼šè°ƒç”¨ <code>TouchAndClamp</code>ã€‚</li>
</ul>
</li>
<li><strong>è®¡ç®— (Compute)</strong>ï¼šHotRing å†…éƒ¨åˆ©ç”¨<strong>æ»‘åŠ¨çª—å£</strong>ç®—æ³•è®¡ç®—å®æ—¶ QPSã€‚</li>
<li><strong>åé¦ˆ (Feedback)</strong>ï¼š
<ul>
<li><strong>Compaction è¯„åˆ†</strong>ï¼š<code>lsm/compact</code> åœ¨é€‰æ‹©å‹ç¼©å±‚çº§æ—¶ï¼Œä¼šå‚è€ƒ <code>HotRing.TopN</code>ã€‚å¦‚æœæŸä¸€å±‚åŒ…å«å¤§é‡çƒ­ç‚¹ Keyï¼Œä¼šä¼˜å…ˆå‹ç¼©è¯¥å±‚ï¼ˆHot Overlap Scoreï¼‰ï¼Œå‡å°‘çƒ­ç‚¹æ•°æ®çš„è¯»æ”¾å¤§ã€‚</li>
<li><strong>ç¼“å­˜é¢„å– (Prefetch)</strong>ï¼šDB å±‚ä¼šæ ¹æ® TopN ç»“æœè§¦å‘é¢„å–é€»è¾‘ã€‚è™½ç„¶ HotRing ä¸ç›´æ¥æ§åˆ¶ Cacheï¼Œä½†å®ƒæä¾›çš„çƒ­ç‚¹åå•æ˜¯é¢„å–ç­–ç•¥çš„é‡è¦è¾“å…¥ã€‚</li>
<li><strong>å†™å…¥é™æµ</strong>ï¼šå¯¹äºå†™é¢‘ç‡è¿‡é«˜çš„ Keyï¼Œ<code>TouchAndClamp</code> ä¼šè§¦å‘é™æµä¿æŠ¤ã€‚</li>
</ul>
</li>
</ol>
<hr>
<h2 id="3-å®ç°ç»†èŠ‚æ·±åº¦è§£æ"><a class="header" href="#3-å®ç°ç»†èŠ‚æ·±åº¦è§£æ">3. å®ç°ç»†èŠ‚æ·±åº¦è§£æ</a></h2>
<h3 id="31-å¹¶å‘æ§åˆ¶lock-free-ä¸-spin-lock"><a class="header" href="#31-å¹¶å‘æ§åˆ¶lock-free-ä¸-spin-lock">3.1 å¹¶å‘æ§åˆ¶ï¼šLock-Free ä¸ Spin-Lock</a></h3>
<p>ä¸ºäº†æ”¯æ’‘é«˜å¹¶å‘ï¼ŒHotRing é‡‡ç”¨äº†æ··åˆå¹¶å‘ç­–ç•¥ï¼š</p>
<ul>
<li><strong>ä¸»é“¾è¡¨ (Buckets &amp; List)</strong>ï¼šé‡‡ç”¨ <strong>Lock-Free</strong> çš„ CAS æ“ä½œè¿›è¡ŒèŠ‚ç‚¹æ’å…¥ã€‚
<ul>
<li><strong>Ordered List</strong>ï¼šé“¾è¡¨èŠ‚ç‚¹æŒ‰ <code>(Tag, Key)</code> æ’åºï¼ŒæŸ¥æ‰¾å¤±è´¥å¯æå‰ç»ˆæ­¢ã€‚</li>
</ul>
</li>
<li><strong>æ»‘åŠ¨çª—å£ (Window Counters)</strong>ï¼šç”±äºæ¶‰åŠå¤æ‚çš„çª—å£æ»šåŠ¨å’Œæ•°ç»„æ›´æ–°ï¼Œä½¿ç”¨äº†è½»é‡çº§çš„ <strong>Spin-Lock (è‡ªæ—‹é”)</strong> ä¿æŠ¤ã€‚
<ul>
<li><code>node.lockWindow()</code>: <code>CAS(&amp;lock, 0, 1)</code>ã€‚</li>
</ul>
</li>
<li><strong>è¡°å‡ (Decay)</strong>ï¼šåå°åç¨‹å®šæœŸè¡°å‡æ—¶ï¼Œä¼šæœ‰äº’æ–¥é”ä¿æŠ¤ <code>decayMu</code>ï¼Œä½†å®é™…çš„è®¡æ•°å™¨è¡°å‡æ˜¯åŸå­æ“ä½œã€‚</li>
</ul>
<h3 id="32-ç»Ÿè®¡ç®—æ³•æ»‘åŠ¨çª—å£ä¸è¡°å‡"><a class="header" href="#32-ç»Ÿè®¡ç®—æ³•æ»‘åŠ¨çª—å£ä¸è¡°å‡">3.2 ç»Ÿè®¡ç®—æ³•ï¼šæ»‘åŠ¨çª—å£ä¸è¡°å‡</a></h3>
<p>å¦‚ä½•åŒºåˆ†â€œå†å²çƒ­ç‚¹â€å’Œâ€œçªå‘çƒ­ç‚¹â€ï¼Ÿ</p>
<ol>
<li><strong>æ»‘åŠ¨çª—å£ (Sliding Window)</strong>ï¼š
<ul>
<li>å°†æ—¶é—´åˆ‡åˆ†ä¸ºå¤šä¸ª Slotï¼ˆå¦‚ 8 ä¸ª Slotï¼Œæ¯ä¸ª 250msï¼‰ã€‚</li>
<li><code>Touch</code> æ—¶æ ¹æ® <code>Timestamp % Slots</code> å†™å…¥å¯¹åº” Slotã€‚</li>
<li><strong>æ•ˆæœ</strong>ï¼šèƒ½å¤Ÿç²¾å‡†åæ˜ â€œæœ€è¿‘ 2 ç§’â€çš„çƒ­åº¦ï¼Œè¿‡æœŸæ•°æ®è‡ªåŠ¨å¤±æ•ˆã€‚</li>
</ul>
</li>
<li><strong>è¡°å‡ (Decay)</strong>ï¼š
<ul>
<li>åå°åç¨‹å®šæœŸå°†æ‰€æœ‰ Counter å³ç§»ä¸€ä½ï¼ˆ<code>count &gt;&gt; 1</code>ï¼‰ã€‚</li>
<li><strong>æ•ˆæœ</strong>ï¼šæ¨¡æ‹Ÿçƒ­åº¦çš„â€œåŠè¡°æœŸâ€ï¼Œè®©ä¸å†è®¿é—®çš„æ—§çƒ­ç‚¹é€æ¸å†·å´ã€‚</li>
</ul>
</li>
</ol>
<hr>
<h2 id="33-ä¸è®ºæ–‡ç®—æ³•çš„å…³é”®å·®å¼‚å·¥ç¨‹åŒ–æ”¹åŠ¨"><a class="header" href="#33-ä¸è®ºæ–‡ç®—æ³•çš„å…³é”®å·®å¼‚å·¥ç¨‹åŒ–æ”¹åŠ¨">3.3 ä¸è®ºæ–‡/ç®—æ³•çš„å…³é”®å·®å¼‚ï¼ˆå·¥ç¨‹åŒ–æ”¹åŠ¨ï¼‰</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th style="text-align: left">å¯¹æ¯”ç‚¹</th><th style="text-align: left">è®ºæ–‡ / ç»å…¸ç®—æ³•</th><th style="text-align: left">NoKV HotRing</th></tr>
</thead>
<tbody>
<tr><td style="text-align: left">ç›®æ ‡</td><td style="text-align: left">ä½œä¸ºç´¢å¼•æˆ–ä¸¥æ ¼é¢‘ç‡ä¼°è®¡</td><td style="text-align: left"><strong>ä½œä¸ºç³»ç»Ÿçº§çƒ­ç‚¹åé¦ˆä¿¡å·</strong></td></tr>
<tr><td style="text-align: left">æ•°æ®ç»“æ„</td><td style="text-align: left">ç¯å½¢é“¾è¡¨/Sketch</td><td style="text-align: left"><strong>å“ˆå¸Œåˆ†æ¡¶ + æœ‰åºé“¾è¡¨</strong></td></tr>
<tr><td style="text-align: left">è¯¯å·®æ§åˆ¶</td><td style="text-align: left">æ˜ç¡®è¯¯å·®ç•Œ</td><td style="text-align: left"><strong>å·¥ç¨‹å¯æ¥å—èŒƒå›´</strong></td></tr>
<tr><td style="text-align: left">å¹¶å‘</td><td style="text-align: left">å¤æ‚é”æˆ–å…¨å±€ç»“æ„</td><td style="text-align: left"><strong>Lock-Free + è½»é‡è‡ªæ—‹é”</strong></td></tr>
<tr><td style="text-align: left">æ—¶é—´ç»´åº¦</td><td style="text-align: left">å¸¸æ€ç´¯è®¡</td><td style="text-align: left"><strong>æ»‘åŠ¨çª—å£ + è¡°å‡</strong></td></tr>
</tbody>
</table>
</div>
<p>ç»“è®ºï¼šNoKV HotRing æ˜¯â€œ<strong>å·¥ç¨‹å¯ç”¨</strong>â€ä¼˜å…ˆçš„å®ç°ï¼Œè€Œä¸æ˜¯â€œ<strong>æ•°å­¦æœ€ä¼˜</strong>â€ä¼˜å…ˆã€‚</p>
<hr>
<h2 id="4-å®é™…åº”ç”¨åœºæ™¯"><a class="header" href="#4-å®é™…åº”ç”¨åœºæ™¯">4. å®é™…åº”ç”¨åœºæ™¯</a></h2>
<h3 id="41-å¯è§‚æµ‹æ€§-observability"><a class="header" href="#41-å¯è§‚æµ‹æ€§-observability">4.1 å¯è§‚æµ‹æ€§ (Observability)</a></h3>
<p>è¿ç»´äººå‘˜å¯ä»¥é€šè¿‡ CLI å®æ—¶æŸ¥çœ‹ç³»ç»Ÿçƒ­ç‚¹ï¼Œç¬é—´å®šä½â€œè°åœ¨æ‰“æŒ‚æ•°æ®åº“â€ã€‚</p>
<pre><code class="language-bash"># ä½¿ç”¨ stats å‘½ä»¤æŸ¥çœ‹
$ go run cmd/nokv/main.go stats --workdir ./work_test
...
Hot Keys:
  key: user:1001, count: 52000
  key: config:global, count: 12000
</code></pre>
<h3 id="42-ç¼“å­˜ä¸æ€§èƒ½-performance"><a class="header" href="#42-ç¼“å­˜ä¸æ€§èƒ½-performance">4.2 ç¼“å­˜ä¸æ€§èƒ½ (Performance)</a></h3>
<ul>
<li><strong>VIP ç¼“å­˜åŒº (Hot Tier)</strong>ï¼šLSM Cache å†…éƒ¨ç»´æŠ¤äº†ä¸€ä¸ªå°å‹çš„ <code>Clock-Pro</code> ç¼“å­˜ï¼ˆHot Tierï¼‰ã€‚è™½ç„¶å®ƒä¸æ˜¯ç»å¯¹çš„â€œå…æ­»é‡‘ç‰Œâ€ï¼ˆä»å¯èƒ½è¢«æ›´çƒ­çš„æ•°æ®æŒ¤å‡ºï¼‰ï¼Œä½†å®ƒä¸ºçƒ­ç‚¹ Block æä¾›äº†æ¯”æ™®é€š LRU æ›´å¼ºçš„ä¿æŠ¤ã€‚</li>
<li><strong>çƒ­ç‚¹å‹ç¼©ä¼˜å…ˆ</strong>ï¼šé€šè¿‡ HotRing çš„åé¦ˆï¼Œç³»ç»Ÿèƒ½ä¸»åŠ¨å°†çƒ­ç‚¹æ•°æ®æ‰€åœ¨çš„é‡å  SSTable è¿›è¡Œåˆå¹¶ï¼Œå°†çƒ­ç‚¹æ•°æ®çš„æŸ¥è¯¢è·¯å¾„å‹ç¼©åˆ°æœ€çŸ­ã€‚</li>
</ul>
<hr>
<h2 id="5-æœªæ¥å±•æœ›"><a class="header" href="#5-æœªæ¥å±•æœ›">5. æœªæ¥å±•æœ›</a></h2>
<p>åŸºäºç›®å‰çš„ HotRing åŸºç¡€ï¼ŒNoKV æœªæ¥å¯ä»¥å®ç°æ›´é«˜çº§çš„ç‰¹æ€§ï¼š</p>
<ol>
<li><strong>å†™å¸æ”¶ (Write Absorption)</strong>ï¼š
<ul>
<li>å¯¹äºè¶…é«˜é¢‘å†™å…¥çš„çƒ­ç‚¹ï¼ˆå¦‚è®¡æ•°å™¨ï¼‰ï¼Œå¯ä»¥åœ¨å†…å­˜ä¸­èšåˆ 100 æ¬¡æ›´æ–°ä¸º 1 æ¬¡ VLog å†™å…¥ï¼Œå¤§å¹…é™ä½ LSM å†™æ”¾å¤§ã€‚</li>
</ul>
</li>
<li><strong>åŠ¨æ€æ•°æ®è¿ç§»</strong>ï¼š
<ul>
<li>åœ¨åˆ†å¸ƒå¼åœºæ™¯ä¸‹ï¼Œå‘ç°æŸä¸ª Region å‡ºç°çƒ­ç‚¹ï¼Œè‡ªåŠ¨è§¦å‘ Region Split æˆ–å°†è¯¥çƒ­ç‚¹ Key è¿ç§»åˆ°ä¸“ç”¨èŠ‚ç‚¹ã€‚</li>
</ul>
</li>
</ol>
<h2 id="6-æ€»ç»“"><a class="header" href="#6-æ€»ç»“">6. æ€»ç»“</a></h2>
<p>NoKV çš„ <code>hotring</code> æ˜¯ä¸€ä¸ª <strong>â€œå­¦æœ¯çµæ„Ÿ + å·¥ç¨‹åŠ¡å®â€</strong> çš„å…¸èŒƒã€‚å®ƒæ²¡æœ‰è¿½æ±‚ç†è®ºä¸Šå®Œç¾çš„ç¯å½¢ç´¢å¼•ç»“æ„ï¼Œè€Œæ˜¯æŠ“ä½äº†â€œçƒ­ç‚¹æ„ŸçŸ¥â€è¿™ä¸€æ ¸å¿ƒä»·å€¼ï¼Œç”¨æ··åˆå¹¶å‘ç»“æ„ï¼ˆLock-Free + SpinLockï¼‰è§£å†³äº†å·¥ç¨‹ä¸­æœ€å¤´ç–¼çš„<strong>ç›‘æ§ç›²åŒº</strong>é—®é¢˜ï¼Œå¹¶æˆåŠŸåå“ºäº† Compaction è°ƒåº¦ã€‚</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="2026-02-01-compaction-and-ingest"><a class="header" href="#2026-02-01-compaction-and-ingest">2026-02-01 compaction and ingest</a></h1>
<p>æœ¬æ–‡æ¡£æ·±å…¥è§£æ NoKV çš„ <strong>Compactionï¼ˆå‹ç¼©ï¼‰</strong> æœºåˆ¶ä¸ <strong>Ingest Bufferï¼ˆå¯¼å…¥ç¼“å†²ï¼‰</strong> çš„ååŒè®¾è®¡ã€‚è¿™æ˜¯ NoKV è§£å†³ LSM Tree ç»å…¸çš„â€œå†™åœé¡¿ï¼ˆWrite Stallï¼‰â€é—®é¢˜çš„æ ¸å¿ƒæ­¦å™¨ï¼Œä¹Ÿæ˜¯ä½“ç°å…¶å·¥ä¸šçº§ç¨³å®šæ€§çš„å…³é”®è®¾è®¡ã€‚</p>
<hr>
<h2 id="1-è®¾è®¡ç†å¿µæ‹’ç»å†™åœé¡¿"><a class="header" href="#1-è®¾è®¡ç†å¿µæ‹’ç»å†™åœé¡¿">1. è®¾è®¡ç†å¿µï¼šæ‹’ç»â€œå†™åœé¡¿â€</a></h2>
<p>åœ¨ LSM Tree æ¶æ„ä¸­ï¼Œæ•°æ®ä» MemTable åˆ·å…¥ L0 å±‚ã€‚ç”±äº L0 å±‚çš„ SSTable ä¹‹é—´ Key æ˜¯é‡å çš„ï¼Œå½“ L0 æ–‡ä»¶æ•°é‡è¾¾åˆ°ä¸Šé™ï¼ˆå¦‚ 15 ä¸ªï¼‰æ—¶ï¼Œå¿…é¡»è§¦å‘ L0 -&gt; L1 çš„ Compactionã€‚</p>
<ul>
<li><strong>ä¼ ç»Ÿç—›ç‚¹</strong>ï¼šL0 -&gt; L1 çš„ Compaction éœ€è¦å°† L0 æ–‡ä»¶ä¸ L1 ä¸­æ‰€æœ‰é‡å çš„æ–‡ä»¶è¯»å‡ºï¼Œè¿›è¡Œå½’å¹¶æ’åºï¼ˆMerge Sortï¼‰ï¼Œç„¶åé‡å†™ã€‚è¿™ä¸ªè¿‡ç¨‹æ¶‰åŠå¤§é‡ IO å’Œ CPUï¼Œè€—æ—¶è¾ƒé•¿ã€‚</li>
<li><strong>åæœ</strong>ï¼šå¦‚æœå†™å…¥é€Ÿåº¦è¶…è¿‡äº† L0 -&gt; L1 çš„å‹ç¼©é€Ÿåº¦ï¼ŒL0 å°±ä¼šè¢«å¡«æ»¡ï¼Œç³»ç»Ÿè¢«è¿«è§¦å‘ <strong>Write Stall</strong>ï¼ˆé™åˆ¶ç”šè‡³åœæ­¢å†™å…¥ï¼‰ï¼Œå¯¼è‡´ä¸¥é‡çš„æ€§èƒ½æŠ–åŠ¨ã€‚</li>
</ul>
<p><strong>NoKV çš„å“²å­¦</strong>ï¼š</p>
<blockquote>
<p><strong>â€œå…ˆæ”¶ä¸‹ï¼Œå†æ•´ç†ã€‚â€</strong>
å½“ L0 æ‹¥å µæ—¶ï¼Œä¸è¦é˜»å¡å†™å…¥å»ç­‰å¾…æ¼«é•¿çš„æ’åºï¼Œè€Œæ˜¯å…ˆæŠŠ L0 çš„æ–‡ä»¶â€œç”©â€ç»™ä¸‹ä¸€å±‚ï¼Œè®©ä¸‹ä¸€å±‚æš‚æ—¶â€œä¿ç®¡â€ï¼Œç­‰æœ‰ç©ºäº†å†æ…¢æ…¢æ•´ç†ã€‚</p>
</blockquote>
<hr>
<h2 id="11-å‚è€ƒè®ºæ–‡ä¸å·¥ç¨‹å¯¹æ ‡"><a class="header" href="#11-å‚è€ƒè®ºæ–‡ä¸å·¥ç¨‹å¯¹æ ‡">1.1 å‚è€ƒè®ºæ–‡ä¸å·¥ç¨‹å¯¹æ ‡</a></h2>
<p>ä»¥ä¸‹è®ºæ–‡/ç³»ç»Ÿæ˜¯ NoKV compaction ä¸ ingest buffer è®¾è®¡çš„ä¸»è¦å‚è€ƒåæ ‡ï¼ˆæŒ‰ä¸»é¢˜åˆ†ç±»ï¼‰ï¼š</p>
<ul>
<li><strong>LSM è®¾è®¡ä¸è°ƒå‚ç†è®º</strong>ï¼š
<ul>
<li><a href="https://stratos.seas.harvard.edu/publications/monkey-optimal-navigable-key-value-store">Monkey (SIGMOD 2017)</a> â€”â€” å…¨å±€è°ƒå‚ã€Bloom è¿‡æ»¤å™¨ä¸åˆå¹¶ç­–ç•¥çš„æƒè¡¡æ¨¡å‹ã€‚</li>
<li><a href="https://stratos.seas.harvard.edu/publications/dostoevsky-better-space-time-trade-offs-lsm-tree-based-key-value-stores">Dostoevsky (SIGMOD 2018)</a> â€”â€” Lazy Leveling / ä½åˆå¹¶æˆæœ¬çš„å±‚çº§ç­–ç•¥ã€‚</li>
</ul>
</li>
<li><strong>å†™åœé¡¿ä¸ç¨³å®šæ€§</strong>ï¼š
<ul>
<li><a href="https://dblp.uni-trier.de/rec/conf/sigmod/SearsR12.html">bLSM (SIGMOD 2012)</a> â€”â€” å¼ºè°ƒå†™å…¥ååç¨³å®šä¸ tail latencyã€‚</li>
<li><a href="https://arxiv.org/abs/1906.09667">Performance Stability in LSM-based Storage Systems</a> â€”â€” compaction æŠ–åŠ¨ä¸å†™åœé¡¿æˆå› åˆ†æã€‚</li>
</ul>
</li>
<li><strong>å·¥ç¨‹ç³»ç»Ÿå®è·µ</strong>ï¼š
<ul>
<li><a href="https://github.com/facebook/rocksdb/wiki/Compaction">RocksDB Compaction (å®˜æ–¹æ–‡æ¡£)</a> â€”â€” leveled/tiered/universal ä¸ L0 å¤„ç†ç­–ç•¥ã€‚</li>
<li><a href="https://utsaslab.github.io/pebblesdb/">PebblesDB</a> â€”â€” ç¢ç‰‡åŒ–/åˆ†ç‰‡æ€è·¯é™ä½å†™æ”¾å¤§ã€‚</li>
<li><a href="https://arxiv.org/abs/1807.04151">Co-KV</a> â€”â€” æŠŠ compaction è§†ä½œæ ¸å¿ƒç“¶é¢ˆçš„ç³»ç»Ÿç ”ç©¶ã€‚</li>
</ul>
</li>
</ul>
<hr>
<h2 id="2-æ ¸å¿ƒç»„ä»¶ingest-buffer"><a class="header" href="#2-æ ¸å¿ƒç»„ä»¶ingest-buffer">2. æ ¸å¿ƒç»„ä»¶ï¼šIngest Buffer</a></h2>
<p>ä¸ºäº†å®ç°ä¸Šè¿°å“²å­¦ï¼ŒNoKV ä¸ºæ¯ä¸€å±‚ï¼ˆLevel 1+ï¼‰å¼•å…¥äº†ä¸€ä¸ªç‰¹æ®Šçš„ç»“æ„ï¼š<strong>Ingest Buffer</strong>ã€‚</p>
<h3 id="21-ç»“æ„å®šä¹‰-lsmingestgo"><a class="header" href="#21-ç»“æ„å®šä¹‰-lsmingestgo">2.1 ç»“æ„å®šä¹‰ (<code>lsm/ingest.go</code>)</a></h3>
<p>å®ƒä¸æ˜¯ä¸€ä¸ªç®€å•çš„é˜Ÿåˆ—ï¼Œè€Œæ˜¯ä¸€ä¸ª<strong>åˆ†ç‰‡åŒ–</strong>çš„å®¹å™¨ï¼š</p>
<pre><code class="language-go">type ingestBuffer struct {
    shards []ingestShard // é»˜è®¤ 4 ä¸ªåˆ†ç‰‡
}

type ingestShard struct {
    tables    []*table   // æš‚å­˜åœ¨è¿™é‡Œçš„ SSTable åˆ—è¡¨
    ranges    []tableRange // å¯¹åº”çš„ Key èŒƒå›´ç´¢å¼•
}
</code></pre>
<ul>
<li><strong>åˆ†ç‰‡ (Sharding)</strong>ï¼šæ ¹æ® Key çš„å‰ç¼€å°†æš‚å­˜çš„è¡¨åˆ†é…åˆ°ä¸åŒçš„ Shardã€‚</li>
<li><strong>å¹¶è¡Œæ€§</strong>ï¼šè¿™å…è®¸åå°çš„å¤šä¸ª Compactor çº¿ç¨‹å¹¶è¡Œåœ°å¤„ç†ä¸åŒ Key èŒƒå›´çš„ç§¯å‹æ•°æ®ã€‚</li>
</ul>
<hr>
<h2 id="3-äº¤äº’é€»è¾‘æ•‘ç«ä¸è¿˜å€º"><a class="header" href="#3-äº¤äº’é€»è¾‘æ•‘ç«ä¸è¿˜å€º">3. äº¤äº’é€»è¾‘ï¼šæ•‘ç«ä¸è¿˜å€º</a></h2>
<p>NoKV çš„ Compaction æµç¨‹è¢«è®¾è®¡ä¸ºâ€œå¿«æ…¢åŒè½¨â€åˆ¶ã€‚</p>
<h3 id="31-å¿«è·¯å¾„l0-æº¢å‡ºå¸è½½-offloading"><a class="header" href="#31-å¿«è·¯å¾„l0-æº¢å‡ºå¸è½½-offloading">3.1 å¿«è·¯å¾„ï¼šL0 æº¢å‡ºå¸è½½ (Offloading)</a></h3>
<p>è¿™æ˜¯åº”å¯¹ Write Stall çš„â€œæ•‘ç«â€æœºåˆ¶ã€‚</p>
<ul>
<li><strong>è§¦å‘</strong>ï¼šL0 æ–‡ä»¶æ•°è¿‡å¤šã€‚</li>
<li><strong>åŠ¨ä½œ (<code>moveToIngest</code>)</strong>ï¼š
<ol>
<li>ä¸è¿›è¡Œæ•°æ®åˆå¹¶ã€‚</li>
<li>ç›´æ¥å°† L0 çš„ SSTable æ–‡ä»¶ä» L0 åˆ—è¡¨ä¸­ç§»é™¤ã€‚</li>
<li>å°†è¿™äº›æ–‡ä»¶åŠ å…¥åˆ° L1 çš„ <code>Ingest Buffer</code> ä¸­ã€‚</li>
</ol>
</li>
<li><strong>ä»£ä»·</strong>ï¼šçº¯å…ƒæ•°æ®æ“ä½œï¼Œ<strong>å¾®ç§’çº§</strong>å®Œæˆã€‚</li>
<li><strong>ç»“æœ</strong>ï¼šL0 ç¬é—´æ¸…ç©ºï¼Œå†™åœé¡¿è§£é™¤ã€‚L1 æš‚æ—¶æŒæœ‰è¿™äº›æœªæ’åºçš„æ–‡ä»¶ã€‚</li>
</ul>
<pre class="mermaid">graph TD
    subgraph Before_L0_Congested["Before: L0 Congested"]
        L0["L0: 15 SSTables (Full)"]
        L1["L1: Sorted SSTables"]
    end

    subgraph Action_Offload_Fast["Action: Offload (Fast)"]
        Move["Move to Ingest"]
    end

    subgraph After_L0_Empty["After: L0 Empty"]
        L0_New["L0: Empty"]
        L1_New["L1: Sorted SSTables"]
        L1_Ingest["L1 Ingest Buffer: 15 Unsorted Tables"]
    end

    L0 --&gt; Move --&gt; L1_Ingest
</pre>

<h3 id="32-æ…¢è·¯å¾„åå°å¼‚æ­¥å½’å¹¶-merge"><a class="header" href="#32-æ…¢è·¯å¾„åå°å¼‚æ­¥å½’å¹¶-merge">3.2 æ…¢è·¯å¾„ï¼šåå°å¼‚æ­¥å½’å¹¶ (Merge)</a></h3>
<p>è¿™æ˜¯â€œè¿˜å€ºâ€æœºåˆ¶ï¼Œç¡®ä¿å­˜å‚¨ç»“æ„çš„æœ€ç»ˆæœ‰åºæ€§ã€‚</p>
<ul>
<li><strong>è§¦å‘</strong>ï¼šCompactor å‘ç°æŸå±‚çš„ <code>Ingest Buffer</code> ç§¯å‹ä¸¥é‡ï¼ˆ<code>Score &gt; 1</code>ï¼‰ã€‚</li>
<li><strong>æ¨¡å¼é€‰æ‹© (IngestMode)</strong>ï¼š
<ul>
<li><strong>IngestDrain</strong>ï¼šå°† Ingest Shard åˆå¹¶è¿› Main Tablesï¼Œå½»åº•æ¸…ç©ºç¼“å†²ã€‚</li>
<li><strong>IngestKeep</strong>ï¼šåˆå¹¶ Shardï¼Œä½†å¦‚æœä¸‹æ¸¸å‹åŠ›ä¹Ÿå¤§ï¼Œå¯èƒ½ä¼šå°†è¾“å‡ºç»“æœç»§ç»­ä¿ç•™åœ¨ Ingest Buffer ä¸­ï¼ˆæš‚å­˜ç»“æœï¼‰ï¼Œä»¥é¿å…å†™å…¥æ”¾å¤§çš„çº§è”æ•ˆåº”ã€‚</li>
</ul>
</li>
<li><strong>åŠ¨ä½œ (<code>fillTablesIngestShard</code>)</strong>ï¼š
<ol>
<li>æŒ‘é€‰ä¸€ä¸ªç§¯å‹æœ€ä¸¥é‡çš„ <code>Shard</code>ã€‚</li>
<li>é”å®šè¯¥ Shard å’Œ L1 ä¸­ä¸å…¶ Key èŒƒå›´é‡å çš„ <code>Main Tables</code>ã€‚</li>
<li>æ‰§è¡Œæ ‡å‡†çš„å½’å¹¶æ’åºã€‚</li>
<li>ç”Ÿæˆæ–°çš„ <code>Main Tables</code>ï¼Œæ¸…ç©ºè¯¥ Shardã€‚</li>
</ol>
</li>
</ul>
<hr>
<h2 id="4-è¯»è·¯å¾„çš„æƒè¡¡"><a class="header" href="#4-è¯»è·¯å¾„çš„æƒè¡¡">4. è¯»è·¯å¾„çš„æƒè¡¡</a></h2>
<p>è¿™ç§è®¾è®¡æœ¬è´¨ä¸Šæ˜¯ <strong>â€œç©ºé—´æ¢æ—¶é—´â€</strong> å’Œ <strong>â€œè¯»å†™æƒè¡¡â€</strong>ã€‚æˆ‘ä»¬ç‰ºç‰²äº†ä¸€ç‚¹ç‚¹è¯»æ€§èƒ½ï¼Œæ¢å–äº†æè‡´çš„å†™ç¨³å®šæ€§ã€‚</p>
<p><strong>æŸ¥è¯¢æµç¨‹ (<code>Get</code>)</strong>ï¼š</p>
<ol>
<li><strong>æŸ¥ MemTable</strong>ã€‚</li>
<li><strong>æŸ¥ L0</strong>ã€‚</li>
<li><strong>æŸ¥ L1</strong>ï¼š
<ul>
<li><strong>å…ˆæŸ¥ L1 Ingest Buffer</strong>ï¼šå› ä¸ºè¿™é‡Œé¢æ˜¯ä» L0 åˆšâ€œç”©â€ä¸‹æ¥çš„æ–°æ•°æ®ï¼Œç‰ˆæœ¬æ›´æ–°ã€‚
<ul>
<li>éœ€è¦åœ¨ Shard å†…è¿›è¡ŒäºŒåˆ†æŸ¥æ‰¾ï¼ˆå› ä¸º buffer å†…çš„è¡¨ä¹‹é—´å¯èƒ½æœ‰é‡å ï¼‰ã€‚</li>
</ul>
</li>
<li><strong>åæŸ¥ L1 Main Tables</strong>ï¼šè¿™æ˜¯æ ‡å‡†çš„æœ‰åºæ•°æ®ï¼ŒæŸ¥æ‰¾å¾ˆå¿«ã€‚</li>
</ul>
</li>
<li><strong>æŸ¥ L2â€¦</strong></li>
</ol>
<hr>
<h2 id="5-ååŒè®¾è®¡value-aware-compaction"><a class="header" href="#5-ååŒè®¾è®¡value-aware-compaction">5. ååŒè®¾è®¡ï¼šValue-Aware Compaction</a></h2>
<p>é™¤äº†å¤„ç†å†™æŠ–åŠ¨ï¼ŒCompaction è¿˜æ‰¿æ‹…äº†<strong>å›æ”¶ VLog ç©ºé—´</strong>çš„ä»»åŠ¡ã€‚</p>
<ul>
<li><strong>ç—›ç‚¹</strong>ï¼šåœ¨ KV åˆ†ç¦»æ¶æ„ä¸­ï¼ŒLSM é‡Œçš„åˆ é™¤åªæ˜¯å†™äº†ä¸€ä¸ª Tombstoneï¼ŒVLog é‡Œçš„æ—§ Value ä¾ç„¶å ç€ç£ç›˜ã€‚</li>
<li><strong>æ–¹æ¡ˆ</strong>ï¼š
<ul>
<li><strong>Value Density (ä»·å€¼å¯†åº¦)</strong>ï¼šCompaction Picker ä¼šè®¡ç®—æ¯ä¸€å±‚çš„ <code>TotalValueBytes / TotalSizeBytes</code>ã€‚</li>
<li><strong>Discard Stats (å¤±æ•ˆç»Ÿè®¡)</strong>ï¼šè™½ç„¶ VLog GC ä¾èµ–ä¸“é—¨çš„ discard statsï¼Œä½† Compaction å¿…é¡»è´Ÿè´£é€šè¿‡é‡å†™ SSTable æ¥ä¸¢å¼ƒé‚£äº›æŒ‡å‘æ— æ•ˆ Value çš„æŒ‡é’ˆã€‚</li>
<li><strong>ç­–ç•¥</strong>ï¼šCompaction ä¼šä¼˜å…ˆé€‰æ‹© Value å¯†åº¦å¼‚å¸¸ï¼ˆæˆ–è€…åŒ…å«å¤§é‡ Stale æ•°æ®ï¼‰çš„å±‚çº§è¿›è¡Œå‹ç¼©ï¼Œä¸»åŠ¨è§¦å‘æŒ‡é’ˆæ¸…ç†ã€‚</li>
</ul>
</li>
</ul>
<h2 id="6-æ€»ç»“-1"><a class="header" href="#6-æ€»ç»“-1">6. æ€»ç»“</a></h2>
<p>NoKV çš„ Compaction å’Œ Ingest Buffer è®¾è®¡è§£å†³äº†ä¸€ç»„å¤æ‚çš„å·¥ç¨‹çŸ›ç›¾ï¼š</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th style="text-align: left">é—®é¢˜</th><th style="text-align: left">ä¼ ç»Ÿæ–¹æ¡ˆ</th><th style="text-align: left">NoKV æ–¹æ¡ˆ</th><th style="text-align: left">æ”¶ç›Š</th></tr>
</thead>
<tbody>
<tr><td style="text-align: left"><strong>L0 æ‹¥å µ</strong></td><td style="text-align: left">é˜»å¡å†™å…¥ï¼Œå¼ºåˆ¶åˆå¹¶</td><td style="text-align: left"><strong>L0 -&gt; Ingest Buffer</strong> (å¿«é€Ÿå¸è½½)</td><td style="text-align: left"><strong>é›¶å†™åœé¡¿ (Zero Write Stall)</strong></td></tr>
<tr><td style="text-align: left"><strong>åˆå¹¶å¡é¡¿</strong></td><td style="text-align: left">å•çº¿ç¨‹å¤§åˆå¹¶</td><td style="text-align: left"><strong>Sharding + Subcompaction</strong></td><td style="text-align: left">å¹¶è¡Œå¤„ç†ï¼Œåˆ©ç”¨å¤šæ ¸/SSD ä¼˜åŠ¿</td></tr>
<tr><td style="text-align: left"><strong>VLog è†¨èƒ€</strong></td><td style="text-align: left">è¢«åŠ¨ç­‰å¾…</td><td style="text-align: left"><strong>Value-Aware Scoring</strong></td><td style="text-align: left">ä¸»åŠ¨å‡ºå‡»ï¼ŒåŠ é€Ÿç©ºé—´å›æ”¶</td></tr>
</tbody>
</table>
</div>
<p>è¿™æ˜¯ä¸€ä¸ªéå¸¸æˆç†Ÿçš„å·¥ä¸šçº§è®¾è®¡ï¼Œå®ƒä¸ä»…å…³æ³¨â€œå­˜å¾—ä¸‹â€ï¼Œæ›´å…³æ³¨â€œå†™å¾—ç¨³â€å’Œâ€œåˆ å¾—æ‰â€ã€‚</p>
<hr>
<h2 id="7-ä¸è®ºæ–‡åŸå§‹è®¾è®¡çš„å…³é”®å¯¹æ¯”æˆ‘ä»¬åšäº†å“ªäº›æ”¹åŠ¨"><a class="header" href="#7-ä¸è®ºæ–‡åŸå§‹è®¾è®¡çš„å…³é”®å¯¹æ¯”æˆ‘ä»¬åšäº†å“ªäº›æ”¹åŠ¨">7. ä¸è®ºæ–‡åŸå§‹è®¾è®¡çš„å…³é”®å¯¹æ¯”ï¼ˆæˆ‘ä»¬åšäº†å“ªäº›æ”¹åŠ¨ï¼‰</a></h2>
<h3 id="71-ä¸-blsm--performance-stability-çš„å¯¹æ¯”"><a class="header" href="#71-ä¸-blsm--performance-stability-çš„å¯¹æ¯”">7.1 ä¸ bLSM / Performance Stability çš„å¯¹æ¯”</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th style="text-align: left">è®ºæ–‡è§‚ç‚¹</th><th style="text-align: left">åŸæ–‡ä¾§é‡ç‚¹</th><th style="text-align: left">NoKV æ”¹åŠ¨</th><th style="text-align: left">å®é™…å½±å“</th></tr>
</thead>
<tbody>
<tr><td style="text-align: left">å†™åœé¡¿ä¸»å› æ˜¯ L0 æ‹¥å µ + Compaction è¿‡æ…¢</td><td style="text-align: left">å¼ºè°ƒç¨³å®šåå</td><td style="text-align: left"><strong>Ingest Buffer + å¿«é€Ÿå¸è½½</strong></td><td style="text-align: left">å†™åœé¡¿å‡ ä¹æ¶ˆå¤±</td></tr>
<tr><td style="text-align: left">éœ€è¦æŠŠåå°ä»»åŠ¡èŠ‚å¥â€œæ‹‰å¹³â€</td><td style="text-align: left">å…³æ³¨ tail latency</td><td style="text-align: left"><strong>åˆ†ç‰‡ + å¹¶è¡Œ compaction + åŠ¨æ€è°ƒåº¦</strong></td><td style="text-align: left">æŠŠæŠ–åŠ¨å‹åœ¨åå°</td></tr>
</tbody>
</table>
</div>
<h3 id="72-ä¸-monkey--dostoevsky-çš„å¯¹æ¯”"><a class="header" href="#72-ä¸-monkey--dostoevsky-çš„å¯¹æ¯”">7.2 ä¸ Monkey / Dostoevsky çš„å¯¹æ¯”</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th style="text-align: left">è®ºæ–‡è§‚ç‚¹</th><th style="text-align: left">åŸæ–‡ä¾§é‡ç‚¹</th><th style="text-align: left">NoKV æ”¹åŠ¨</th><th style="text-align: left">å®é™…å½±å“</th></tr>
</thead>
<tbody>
<tr><td style="text-align: left">LSM å‚æ•°éœ€å…¨å±€æƒè¡¡ï¼ˆè¯»/å†™/ç©ºé—´ï¼‰</td><td style="text-align: left">ç†è®ºæ¨¡å‹</td><td style="text-align: left"><strong>å¼•å…¥ ingest buffer ä½œä¸ºå·¥ç¨‹ç¼“å†²å±‚</strong></td><td style="text-align: left">å®é™…è°ƒå‚æ›´ç¨³å®š</td></tr>
<tr><td style="text-align: left">Lazy leveling é™ä½åˆå¹¶æˆæœ¬</td><td style="text-align: left">å‡å°‘å†™æ”¾å¤§</td><td style="text-align: left"><strong>IngestKeep/Drain æ¨¡å¼</strong></td><td style="text-align: left">çƒ­ç‚¹æ—¶å»¶é™ä½</td></tr>
</tbody>
</table>
</div>
<h3 id="73-ä¸-rocksdb--pebblesdb-çš„å¯¹æ¯”"><a class="header" href="#73-ä¸-rocksdb--pebblesdb-çš„å¯¹æ¯”">7.3 ä¸ RocksDB / PebblesDB çš„å¯¹æ¯”</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th style="text-align: left">ç³»ç»Ÿ</th><th style="text-align: left">åŸå§‹è®¾è®¡</th><th style="text-align: left">NoKV æ”¹åŠ¨</th><th style="text-align: left">è¯´æ˜</th></tr>
</thead>
<tbody>
<tr><td style="text-align: left">RocksDB</td><td style="text-align: left">L0 â†’ leveledï¼Œuniversal ä½œä¸ºå¯é€‰</td><td style="text-align: left"><strong>å¼•å…¥æ¯å±‚ ingest ç¼“å†²åŒº</strong></td><td style="text-align: left">æ›´é€‚åˆ burst åœºæ™¯</td></tr>
<tr><td style="text-align: left">PebblesDB</td><td style="text-align: left">ç¢ç‰‡åŒ– LSM</td><td style="text-align: left"><strong>æŒ‰å‰ç¼€åˆ†ç‰‡ shard</strong></td><td style="text-align: left">ä¿æŒèŒƒå›´å±€éƒ¨æ€§</td></tr>
</tbody>
</table>
</div>
<h3 id="74-ä¸è®ºæ–‡åŸå‹ä¸åŒçš„å·¥ç¨‹åŒ–ç‚¹"><a class="header" href="#74-ä¸è®ºæ–‡åŸå‹ä¸åŒçš„å·¥ç¨‹åŒ–ç‚¹">7.4 ä¸è®ºæ–‡åŸå‹ä¸åŒçš„å·¥ç¨‹åŒ–ç‚¹</a></h3>
<ul>
<li><strong>åˆ†ç‰‡å¹¶è¡Œ</strong>ï¼šæŒ‰ key å‰ç¼€ shardï¼Œä½¿ ingest ä¸ compaction å¯å¹¶è¡Œè€Œä¸äº’ç›¸è¦†ç›–ã€‚</li>
<li><strong>IngestKeep / IngestDrain</strong>ï¼šæŠŠâ€œå¿«é€Ÿæ­¢è¡€â€å’Œâ€œæ…¢é€Ÿè¿˜å€ºâ€æ‹†æˆä¸¤æ¡è·¯å¾„ã€‚</li>
<li><strong>Value-aware compaction</strong>ï¼šä¸ VLog discard stats è”åŠ¨ï¼ŒæŠŠæ— æ•ˆæŒ‡é’ˆå°½å¿«æ¸…æ‰ã€‚</li>
<li><strong>è°ƒåº¦åŸºäº backlog/score</strong>ï¼šä¼˜å…ˆå¤„ç†æœ€æ€¥çš„ shardï¼Œè€ŒééšæœºæŒ‘é€‰ã€‚</li>
</ul>
<blockquote>
<p>ç®€å•æ€»ç»“ï¼šè®ºæ–‡è§£å†³çš„æ˜¯â€œç†è®ºæœ€ä¼˜è§£â€ï¼ŒNoKV åšçš„æ˜¯â€œå·¥ç¨‹ç¨³å®šæ€§ + å¯è¿ç»´â€ã€‚</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="2026-02-05-vlog-è®¾è®¡ä¸-gcwisckey--hashkv-å·¥ç¨‹åŒ–"><a class="header" href="#2026-02-05-vlog-è®¾è®¡ä¸-gcwisckey--hashkv-å·¥ç¨‹åŒ–">2026-02-05 vlog è®¾è®¡ä¸ GCï¼ˆWiscKey + HashKV å·¥ç¨‹åŒ–ï¼‰</a></h1>
<p>è¿™ä»½ç¬”è®°æŠŠ NoKV çš„ ValueLogï¼ˆvlogï¼‰è®¾è®¡ã€GC æœºåˆ¶ã€ä»¥åŠæœ€è¿‘çš„å¹¶è¡ŒåŒ–ä¸çƒ­å†·åˆ†æµä¼˜åŒ–æ•´ç†æˆä¸€ä»½å®Œæ•´ç‰ˆæœ¬ã€‚å†…å®¹èåˆ <strong>WiscKey</strong>ï¼ˆKV åˆ†ç¦»ï¼‰ä¸ <strong>HashKV</strong>ï¼ˆå“ˆå¸Œåˆ†åŒº/çƒ­å†·åˆ†ç¦»ï¼‰ä¸¤æ¡ä¸»çº¿ï¼Œå¹¶ç»“åˆå½“å‰å®ç°ç»†èŠ‚ä¸å‚æ•°ç­–ç•¥ã€‚</p>
<hr>
<h2 id="ä¸€é¡µæ‘˜è¦tldr"><a class="header" href="#ä¸€é¡µæ‘˜è¦tldr">ä¸€é¡µæ‘˜è¦ï¼ˆTL;DRï¼‰</a></h2>
<p><strong>æ ¸å¿ƒæ€è·¯</strong>ï¼šLSM åªä¿å­˜ Key+ValuePtrï¼Œå¤§ Value é¡ºåºå†™å…¥ vlogï¼›å†ç”¨ <strong>å¤šæ¡¶ + çƒ­å†·åˆ†æµ</strong> æŠŠçƒ­ç‚¹æ›´æ–°å±€éƒ¨åŒ–ï¼Œå¹¶é€šè¿‡ <strong>å¹¶è¡Œ GC + å‹åŠ›æ§åˆ¶</strong> æŠŠ GC å¼€é”€ç¨³å®šåœ¨å¯æ§èŒƒå›´ã€‚</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th style="text-align: left">è®¾è®¡ç‚¹</th><th style="text-align: left">å€Ÿé‰´</th><th style="text-align: left">NoKV å®ç°</th><th style="text-align: left">ç›´æ¥æ”¶ç›Š</th></tr>
</thead>
<tbody>
<tr><td style="text-align: left">KV åˆ†ç¦»</td><td style="text-align: left">WiscKey</td><td style="text-align: left">vlog + ValuePtr</td><td style="text-align: left">LSM æ›´å°ã€å†™å…¥æ›´é¡ºåº</td></tr>
<tr><td style="text-align: left">å“ˆå¸Œåˆ†åŒº</td><td style="text-align: left">HashKV</td><td style="text-align: left"><code>ValueLogBucketCount</code></td><td style="text-align: left">åƒåœ¾å±€éƒ¨åŒ–</td></tr>
<tr><td style="text-align: left">çƒ­å†·åˆ†æµ</td><td style="text-align: left">HashKV</td><td style="text-align: left">HotRing è·¯ç”±</td><td style="text-align: left">çƒ­ç‚¹ä¸æ±¡æŸ“å†·æ•°æ®</td></tr>
<tr><td style="text-align: left">GC å¹¶è¡Œ</td><td style="text-align: left">å·¥ç¨‹åŒ–</td><td style="text-align: left"><code>ValueLogGCParallelism</code></td><td style="text-align: left">æå‡æ¸…ç†åå</td></tr>
<tr><td style="text-align: left">å‹åŠ›æ§åˆ¶</td><td style="text-align: left">å·¥ç¨‹åŒ–</td><td style="text-align: left">reduce/skip é˜ˆå€¼</td><td style="text-align: left">ä¸ä¸ compaction æŠ¢èµ„æº</td></tr>
</tbody>
</table>
</div>
<hr>
<h2 id="1-è®ºæ–‡å€Ÿé‰´è¦ç‚¹"><a class="header" href="#1-è®ºæ–‡å€Ÿé‰´è¦ç‚¹">1. è®ºæ–‡å€Ÿé‰´è¦ç‚¹</a></h2>
<h3 id="11-wisckey"><a class="header" href="#11-wisckey">1.1 WiscKey</a></h3>
<ul>
<li><strong>KV åˆ†ç¦»</strong>ï¼šLSM åªå­˜ Key + ValuePtrï¼Œå¤§ Value å†™å…¥ vlogã€‚</li>
<li><strong>é¡ºåºå†™</strong>ï¼šå†™å…¥èµ°æ—¥å¿—è¿½åŠ ï¼Œå»¶è¿Ÿç¨³å®šã€‚</li>
<li><strong>GC å¿…è¦æ€§</strong>ï¼šæ—§å€¼åªèƒ½é€šè¿‡æ¬è¿+åˆ é™¤å›æ”¶ã€‚</li>
</ul>
<h3 id="12-hashkv"><a class="header" href="#12-hashkv">1.2 HashKV</a></h3>
<ul>
<li><strong>å“ˆå¸Œåˆ†åŒº</strong>ï¼šValueLog åˆ†æ¡¶ï¼Œkey çš„å†å²ç‰ˆæœ¬é›†ä¸­ã€‚</li>
<li><strong>çƒ­å†·åˆ†ç¦»</strong>ï¼šçƒ­ç‚¹æ›´æ–°å½±å“å±€éƒ¨æ¡¶ï¼Œå†·æ•°æ®ä¿æŒç¨³å®šã€‚</li>
<li><strong>è½» GC</strong>ï¼šçƒ­ç‚¹æ¡¶é«˜é¢‘å›æ”¶ï¼Œå†·æ¡¶ä½é¢‘ç»´æŠ¤ã€‚</li>
</ul>
<h3 id="13-å‚è€ƒè®ºæ–‡æ ‡é¢˜"><a class="header" href="#13-å‚è€ƒè®ºæ–‡æ ‡é¢˜">1.3 å‚è€ƒè®ºæ–‡ï¼ˆæ ‡é¢˜ï¼‰</a></h3>
<ul>
<li><strong><a href="https://www.usenix.org/conference/fast16/technical-sessions/presentation/lu">WiscKey: Separating Keys from Values in SSD-conscious Storage</a></strong></li>
<li><strong><a href="https://www.usenix.org/conference/atc18/presentation/chan">HashKV: Enabling Efficient Updates in KV Storage via Hashing</a></strong></li>
</ul>
<hr>
<h2 id="2-è®¾è®¡ç›®æ ‡å·¥ç¨‹åŒ–è§†è§’"><a class="header" href="#2-è®¾è®¡ç›®æ ‡å·¥ç¨‹åŒ–è§†è§’">2. è®¾è®¡ç›®æ ‡ï¼ˆå·¥ç¨‹åŒ–è§†è§’ï¼‰</a></h2>
<ol>
<li><strong>å†™è·¯å¾„æç®€</strong>ï¼šé¡ºåºè¿½åŠ ä¸ºä¸»ï¼Œä¸å¼•å…¥å¤æ‚ç´¢å¼•ç»“æ„ã€‚</li>
<li><strong>GC ä¸æ‰°åŠ¨ä¸»è·¯å¾„</strong>ï¼šå¹¶è¡Œä½†å—æ§ï¼Œé¿å…å’Œ compaction äº‰ IOã€‚</li>
<li><strong>çƒ­ç‚¹æ›´æ–°å±€éƒ¨åŒ–</strong>ï¼šå°½é‡æŠŠåƒåœ¾é™åˆ¶åœ¨çƒ­æ¡¶ã€‚</li>
<li><strong>å¯è§‚æµ‹ + å¯è°ƒå‚</strong>ï¼šè®©è°ƒå‚æ˜¯â€œçœ‹å¾—è§çš„ç³»ç»Ÿå·¥ç¨‹â€ã€‚</li>
</ol>
<hr>
<h2 id="21-è®¾è®¡çº¦æŸä¸å‡è®¾"><a class="header" href="#21-è®¾è®¡çº¦æŸä¸å‡è®¾">2.1 è®¾è®¡çº¦æŸä¸å‡è®¾</a></h2>
<ul>
<li><strong>Crash Recovery å¿…é¡»å¯é </strong>ï¼švlog çš„ head/åˆ é™¤çŠ¶æ€å¿…é¡»å¯æ¢å¤ã€‚</li>
<li><strong>å†™æ”¾å¤§ä¼˜å…ˆäºè¯»æ”¾å¤§</strong>ï¼šæ›´å€¾å‘æŠŠå†™æˆæœ¬å‹ä½ï¼Œè¯»è·¯å¾„å¯å®¹å¿ä¸€æ¬¡é¢å¤–è·³è½¬ã€‚</li>
<li><strong>GC å¯é€€è®©</strong>ï¼šGC æ˜¯â€œåå°ç»´æŠ¤â€ï¼Œä¸èƒ½æŠŠ compaction å‹æ­»ã€‚</li>
</ul>
<hr>
<h2 id="3-æ¶æ„æ€»è§ˆåˆ†å±‚æ¨¡å‹"><a class="header" href="#3-æ¶æ„æ€»è§ˆåˆ†å±‚æ¨¡å‹">3. æ¶æ„æ€»è§ˆï¼ˆåˆ†å±‚æ¨¡å‹ï¼‰</a></h2>
<pre class="mermaid">flowchart TD
  subgraph DB["DB Policy å±‚"]
    VlogGo["vlog.go / vlog_gc.go&lt;br/&gt;å†™å…¥è·¯ç”± + GC è°ƒåº¦"]
  end
  subgraph Mgr["ValueLog Manager"]
    MgrGo["vlog/manager.go&lt;br/&gt;åˆ†æ®µ/è½®è½¬/è¯»å†™"]
  end
  subgraph IO["IO Layer"]
    File["file/ (mmap)&lt;br/&gt;LogFile"]
  end

  DB --&gt; Mgr --&gt; IO
</pre>

<hr>
<h2 id="4-ç›®å½•å¸ƒå±€ä¸åˆ†æ¡¶ç»“æ„"><a class="header" href="#4-ç›®å½•å¸ƒå±€ä¸åˆ†æ¡¶ç»“æ„">4. ç›®å½•å¸ƒå±€ä¸åˆ†æ¡¶ç»“æ„</a></h2>
<pre><code class="language-text">&lt;workdir&gt;/
  vlog/
    bucket-000/
      00000.vlog
      00001.vlog
    bucket-001/
      00000.vlog
      00001.vlog
    ...
</code></pre>
<ul>
<li><code>ValueLogBucketCount &gt; 1</code> å¯ç”¨åˆ†æ¡¶ã€‚</li>
<li>ValuePtr ç°åœ¨åŒ…å« <code>Bucket/Fid/Offset/Len</code>ï¼ŒLSM å¯ä»¥ç²¾ç¡®å®šä½ã€‚</li>
</ul>
<hr>
<h2 id="41-è®°å½•æ ¼å¼ä¸-valueptr-å¸ƒå±€"><a class="header" href="#41-è®°å½•æ ¼å¼ä¸-valueptr-å¸ƒå±€">4.1 è®°å½•æ ¼å¼ä¸ ValuePtr å¸ƒå±€</a></h2>
<p><strong>vlog è®°å½•æ ¼å¼</strong>ï¼ˆä¸ WAL ä¸€è‡´ï¼‰ï¼š</p>
<pre><code>+--------+----------+------+-------------+-----------+-------+
| KeyLen | ValueLen | Meta | ExpiresAt   | Key bytes | Value |
+--------+----------+------+-------------+-----------+-------+
                                             + CRC32 (4B)
</code></pre>
<p><strong>ValuePtr å¸ƒå±€</strong>ï¼š</p>
<pre><code>+------+--------+-----+--------+
| Len  | Offset | Fid | Bucket |
+------+--------+-----+--------+
| 4B   | 4B     | 4B  | 4B     |
</code></pre>
<p>è¿™ä¿è¯äº†ï¼š<strong>LSM ç´¢å¼•åªéœ€æŒæœ‰ ValuePtr å³å¯å®šä½åˆ°å…·ä½“æ¡¶ + æ–‡ä»¶ + åç§»</strong>ã€‚</p>
<hr>
<h2 id="42-manifest-ä¸æ¢å¤å…³ç³»nokv-ç‰¹æœ‰å·¥ç¨‹ç‚¹"><a class="header" href="#42-manifest-ä¸æ¢å¤å…³ç³»nokv-ç‰¹æœ‰å·¥ç¨‹ç‚¹">4.2 Manifest ä¸æ¢å¤å…³ç³»ï¼ˆNoKV ç‰¹æœ‰å·¥ç¨‹ç‚¹ï¼‰</a></h2>
<p>ä¸è®ºæ–‡åŸå‹ä¸åŒï¼ŒNoKV <strong>æŠŠ vlog çš„ head ä¸åˆ é™¤äº‹ä»¶å†™å…¥ manifest</strong>ï¼š</p>
<pre class="mermaid">flowchart LR
  A["vlog append"] --&gt; B["update head"]
  B --&gt; C["manifest edit"]
  C --&gt; D["crash recovery"]
  D --&gt; E["rebuild vlog state"]
</pre>

<p>è¿™æ ·æ¢å¤æ—¶ä¸ä¾èµ–å®Œæ•´ç›®å½•æ‰«æï¼Œé¿å…è¯¯åˆ /è¯¯å¼€æ®µã€‚</p>
<hr>
<h2 id="5-å†™å…¥è·¯å¾„é¡ºåºè¿½åŠ "><a class="header" href="#5-å†™å…¥è·¯å¾„é¡ºåºè¿½åŠ ">5. å†™å…¥è·¯å¾„ï¼ˆé¡ºåºè¿½åŠ ï¼‰</a></h2>
<pre class="mermaid">sequenceDiagram
  participant C as commitWorker
  participant V as vlog.Manager
  participant W as WAL
  participant M as MemTable
  C-&gt;&gt;V: AppendEntries(entries)
  V--&gt;&gt;C: ValuePtr list
  C-&gt;&gt;W: Append(entries+ptrs)
  C-&gt;&gt;M: Apply to memtable
</pre>

<p>å…³é”®ä¿è¯ï¼š<strong>vlog å†™å…¥åœ¨ WAL ä¹‹å‰</strong>ï¼Œå´©æºƒæ¢å¤æ—¶ä¸ä¼šå‡ºç°â€œæŒ‡é’ˆæ‚¬ç©ºâ€ã€‚</p>
<hr>
<h2 id="6-è¯»è·¯å¾„æŒ‡é’ˆè§£å¼•ç”¨"><a class="header" href="#6-è¯»è·¯å¾„æŒ‡é’ˆè§£å¼•ç”¨">6. è¯»è·¯å¾„ï¼ˆæŒ‡é’ˆè§£å¼•ç”¨ï¼‰</a></h2>
<pre class="mermaid">flowchart LR
  K["Get(key)"] --&gt; LSM["LSM æŸ¥ç´¢å¼•"]
  LSM --&gt;|inline value| V["ç›´æ¥è¿”å›"]
  LSM --&gt;|ValuePtr| P["å®šä½ bucket/fid/offset"]
  P --&gt; R["vlog è¯»å– (mmap)"]
  R --&gt; V
</pre>

<p>è¯»è·¯å¾„çš„ä»£ä»·åœ¨äºä¸€æ¬¡é¢å¤–çš„ vlog å®šä½ï¼Œä½†æ¢æ¥æ›´å°çš„ LSM ä¸æ›´é¡ºåºçš„å†™å…¥ã€‚</p>
<hr>
<h2 id="6-çƒ­å†·åˆ†æµhotring-é©±åŠ¨"><a class="header" href="#6-çƒ­å†·åˆ†æµhotring-é©±åŠ¨">6. çƒ­å†·åˆ†æµï¼ˆHotRing é©±åŠ¨ï¼‰</a></h2>
<p>çƒ­åº¦ç»Ÿè®¡åªçœ‹å†™è·¯å¾„ï¼ˆå†™çƒ­ç‚¹ï¼‰ï¼Œé¿å…è¯»çƒ­ç‚¹æ±¡æŸ“ï¼š</p>
<pre class="mermaid">flowchart TD
  E["Entry å†™å…¥"] --&gt; H["HotRing Touch"]
  H --&gt;|hot| B1["çƒ­æ¡¶ 0..H-1"]
  H --&gt;|cold| B2["å†·æ¡¶ H..N-1"]
  B1 --&gt; V["vlog append"]
  B2 --&gt; V
</pre>

<p>é»˜è®¤é…ç½®ï¼ˆå¯è°ƒï¼‰ï¼š</p>
<ul>
<li><code>ValueLogBucketCount = 16</code></li>
<li><code>ValueLogHotBucketCount = 4</code></li>
<li><code>ValueLogHotKeyThreshold = 8</code></li>
</ul>
<hr>
<h2 id="7-gc-æœºåˆ¶é‡‡æ ·--é‡å†™"><a class="header" href="#7-gc-æœºåˆ¶é‡‡æ ·--é‡å†™">7. GC æœºåˆ¶ï¼ˆé‡‡æ · + é‡å†™ï¼‰</a></h2>
<pre class="mermaid">sequenceDiagram
  participant GC as GC Thread
  participant Stats as Discard Stats
  participant Old as Old Segment
  participant LSM as LSM
  participant New as Active Segment

  GC-&gt;&gt;Stats: é€‰æ‹©å€™é€‰æ–‡ä»¶
  GC-&gt;&gt;Old: Sample 10%
  GC-&gt;&gt;LSM: æ ¡éªŒæŒ‡é’ˆæ˜¯å¦ä»æŒ‡å‘æ—§å€¼
  alt discard è¿‡é˜ˆå€¼
    loop éå†æ—§æ–‡ä»¶
      GC-&gt;&gt;Old: Read Entry
      GC-&gt;&gt;LSM: Double Check
      alt still live
        GC-&gt;&gt;New: Rewrite
      end
    end
    GC-&gt;&gt;Old: åˆ é™¤æ—§æ–‡ä»¶
  else discardä¸è¶³
    GC--&gt;&gt;Stats: è·³è¿‡
  end
</pre>

<hr>
<h2 id="8-å¹¶è¡Œ-gc--å‹åŠ›æ§åˆ¶æ ¸å¿ƒå·¥ç¨‹åŒ–"><a class="header" href="#8-å¹¶è¡Œ-gc--å‹åŠ›æ§åˆ¶æ ¸å¿ƒå·¥ç¨‹åŒ–">8. å¹¶è¡Œ GC + å‹åŠ›æ§åˆ¶ï¼ˆæ ¸å¿ƒå·¥ç¨‹åŒ–ï¼‰</a></h2>
<h3 id="81-å¹¶è¡Œè°ƒåº¦"><a class="header" href="#81-å¹¶è¡Œè°ƒåº¦">8.1 å¹¶è¡Œè°ƒåº¦</a></h3>
<ul>
<li><code>ValueLogGCParallelism</code> æ§åˆ¶å¹¶å‘æ•°ï¼ˆé»˜è®¤è‡ªåŠ¨ï¼‰ã€‚</li>
<li><strong>åŒæ¡¶äº’æ–¥</strong>ï¼šåŒä¸€æ¡¶ä¸ä¼šå¹¶å‘ GCï¼ˆæ— é” CASï¼‰ã€‚</li>
<li>å…¨å±€ semaphore é™åˆ¶åŒæ—¶ GC æ•°é‡ã€‚</li>
</ul>
<h3 id="82-å‹åŠ›æ§åˆ¶"><a class="header" href="#82-å‹åŠ›æ§åˆ¶">8.2 å‹åŠ›æ§åˆ¶</a></h3>
<p>å½“ compaction å‹åŠ›è¿‡é«˜æ—¶ï¼ŒGC è‡ªåŠ¨é™çº§æˆ–è·³è¿‡ï¼š</p>
<pre class="mermaid">flowchart LR
  A["Compaction Stats"] --&gt; B{"å‹åŠ›è¯„ä¼°"}
  B --&gt;|ä½| C["å¹¶è¡Œ GC"]
  B --&gt;|ä¸­| D["å¹¶è¡Œåº¦å‡åŠ"]
  B --&gt;|é«˜| E["è·³è¿‡æœ¬è½® GC"]
</pre>

<p>é˜ˆå€¼å‚æ•°ï¼š</p>
<ul>
<li><code>ValueLogGCReduceScore / ValueLogGCReduceBacklog</code></li>
<li><code>ValueLogGCSkipScore / ValueLogGCSkipBacklog</code></li>
</ul>
<hr>
<h2 id="83-ä¸è®ºæ–‡å®ç°çš„å…³é”®å·®å¼‚é‡ç‚¹å¯¹æ¯”"><a class="header" href="#83-ä¸è®ºæ–‡å®ç°çš„å…³é”®å·®å¼‚é‡ç‚¹å¯¹æ¯”">8.3 ä¸è®ºæ–‡å®ç°çš„å…³é”®å·®å¼‚ï¼ˆé‡ç‚¹å¯¹æ¯”ï¼‰</a></h2>
<h3 id="wisckey-vs-nokv"><a class="header" href="#wisckey-vs-nokv">WiscKey vs NoKV</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th style="text-align: left">ç»´åº¦</th><th style="text-align: left">WiscKey</th><th style="text-align: left">NoKV</th></tr>
</thead>
<tbody>
<tr><td style="text-align: left">vlog å…ƒæ•°æ®</td><td style="text-align: left">è®ºæ–‡åŸå‹ä¸å¼ºè°ƒ manifest</td><td style="text-align: left"><strong>manifest è®°å½• head/åˆ é™¤</strong></td></tr>
<tr><td style="text-align: left">GC è§¦å‘</td><td style="text-align: left">ä¾èµ–æ‰«æä¸ stale ratio</td><td style="text-align: left"><strong>æ¥è‡ª LSM discard stats</strong></td></tr>
<tr><td style="text-align: left">GC å¹¶è¡Œ</td><td style="text-align: left">æœªå¼ºè°ƒ</td><td style="text-align: left"><strong>å¤šæ¡¶å¹¶è¡Œ + å‹åŠ›æ§åˆ¶</strong></td></tr>
<tr><td style="text-align: left">çƒ­ç‚¹å¤„ç†</td><td style="text-align: left">æ— æ˜¾å¼çƒ­å†·</td><td style="text-align: left"><strong>HotRing é©±åŠ¨çƒ­/å†·æ¡¶</strong></td></tr>
</tbody>
</table>
</div>
<h3 id="hashkv-vs-nokv"><a class="header" href="#hashkv-vs-nokv">HashKV vs NoKV</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th style="text-align: left">ç»´åº¦</th><th style="text-align: left">HashKV</th><th style="text-align: left">NoKV</th></tr>
</thead>
<tbody>
<tr><td style="text-align: left">åˆ†åŒºç­–ç•¥</td><td style="text-align: left">å“ˆå¸Œåˆ†åŒº</td><td style="text-align: left"><strong>å“ˆå¸Œåˆ†æ¡¶ + çƒ­/å†·åˆ†æµ</strong></td></tr>
<tr><td style="text-align: left">ç›®æ ‡</td><td style="text-align: left">é™ä½æ›´æ–°æ”¾å¤§</td><td style="text-align: left"><strong>é™ä½ GC æ³¢åŠ¨ + write amp</strong></td></tr>
<tr><td style="text-align: left">GC è°ƒåº¦</td><td style="text-align: left">ä»¥åˆ†åŒºä¸ºå•ä½</td><td style="text-align: left"><strong>åˆ†æ¡¶å¹¶è¡Œ + compaction å‹åŠ›æ§åˆ¶</strong></td></tr>
</tbody>
</table>
</div>
<blockquote>
<p>ç»“è®ºï¼šNoKV ä¿ç•™è®ºæ–‡çš„â€œæ ¸å¿ƒæ€æƒ³â€ï¼Œä½†åœ¨<strong>æ¢å¤ä¸€è‡´æ€§ã€è°ƒåº¦ç­–ç•¥ã€è§‚æµ‹æ€§</strong>ä¸Šåšäº†å·¥ç¨‹åŒ–å¼ºåŒ–ã€‚</p>
</blockquote>
<hr>
<h2 id="9-å¯è§‚æµ‹æ€§ä¸è°ƒå‚æŠ“æ‰‹"><a class="header" href="#9-å¯è§‚æµ‹æ€§ä¸è°ƒå‚æŠ“æ‰‹">9. å¯è§‚æµ‹æ€§ä¸è°ƒå‚æŠ“æ‰‹</a></h2>
<p>å…³é”®æŒ‡æ ‡ï¼ˆexpvarï¼‰ï¼š</p>
<ul>
<li><code>NoKV.ValueLog.GcParallelism</code></li>
<li><code>NoKV.ValueLog.GcActive</code></li>
<li><code>NoKV.ValueLog.GcScheduled</code></li>
<li><code>NoKV.ValueLog.GcThrottled</code></li>
<li><code>NoKV.ValueLog.GcSkipped</code></li>
<li><code>NoKV.ValueLog.GcRejected</code></li>
</ul>
<p>ç®€å•è°ƒå‚å»ºè®®ï¼š</p>
<ul>
<li>ä½è´Ÿè½½ï¼šè°ƒé«˜ <code>ValueLogGCParallelism</code></li>
<li>é«˜è´Ÿè½½ï¼šé™ä½ <code>ReduceScore</code> æˆ– <code>ReduceBacklog</code>ï¼Œæ›´å¿«é™çº§</li>
</ul>
<hr>
<h2 id="10-ä»£ä»·ä¸è¾¹ç•Œ"><a class="header" href="#10-ä»£ä»·ä¸è¾¹ç•Œ">10. ä»£ä»·ä¸è¾¹ç•Œ</a></h2>
<ul>
<li>æ¡¶æ•°è¿‡å¤š â†’ æ–‡ä»¶ç¢ç‰‡åŒ–ã€head è¿½è¸ªæˆæœ¬ä¸Šå‡</li>
<li>çƒ­æ¡¶è¿‡å° â†’ è½®è½¬é¢‘ç¹ã€å†™æ”¾å¤§å‡é«˜</li>
<li>å¹¶è¡Œ GC è¿‡é«˜ â†’ å¯èƒ½ä¸ compaction äº‰æŠ¢ IO</li>
</ul>
<hr>
<h2 id="11-å°ç»“"><a class="header" href="#11-å°ç»“">11. å°ç»“</a></h2>
<p>NoKV çš„ vlog è®¾è®¡æ˜¯å…¸å‹çš„ â€œ<strong>WiscKey + HashKV + å·¥ç¨‹åŒ–è°ƒåº¦</strong>â€ï¼š</p>
<ul>
<li><strong>å†™è·¯å¾„ä¿æŒé¡ºåº</strong>ï¼Œå»¶è¿Ÿç¨³å®š</li>
<li><strong>å¤šæ¡¶ + çƒ­å†·åˆ†æµ</strong> æŠŠåƒåœ¾å±€éƒ¨åŒ–</li>
<li><strong>å¹¶è¡Œ GC + å‹åŠ›æ§åˆ¶</strong> æŠŠç³»ç»Ÿç¨³å®šæ€§å’Œååå¹³è¡¡èµ·æ¥</li>
</ul>
<p>è¿™ä½¿å¾— vlog ä»â€œå¯ç”¨â€èµ°å‘â€œå¯è¿ç»´ + å¯æ‰©å±•â€ã€‚</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="2026-02-09-memory-craft-memtable-arena-skiplist-art"><a class="header" href="#2026-02-09-memory-craft-memtable-arena-skiplist-art">2026-02-09-memory-craft-memtable-arena-skiplist-art</a></h1>
<p>æœ¬æ–‡æ¡£é¢å‘ç¬¬ä¸€æ¬¡è¯» NoKV çš„åŒå­¦ï¼Œä¹Ÿè®°å½•æˆ‘è‡ªå·±åœ¨è¿™å—å®ç°é‡Œçš„å·¥ç¨‹åŒ–æ€è·¯ã€‚ä¸»é¢˜æ˜¯ MemTable å±‚çš„ä¸‰ä»¶äº‹ï¼š</p>
<ol>
<li>MemTable ä½œä¸ºâ€œå¯æ¢å¤å†™å…¥é˜¶æ®µâ€çš„è®¾è®¡æ„ä¹‰ã€‚</li>
<li>Arena ä¸ºä»€ä¹ˆæ˜¯æ€§èƒ½ä¸å¯æ§æ€§çš„å…³é”®ã€‚</li>
<li>Skiplist / ART ä¸¤ç§ç´¢å¼•åœ¨çœŸå®å·¥ç¨‹é‡Œçš„å–èˆã€‚</li>
</ol>
<hr>
<h2 id="1-è®¾è®¡ç†å¿µmemtable-ä¸æ˜¯ç¼“å­˜è€Œæ˜¯å†™å…¥é˜¶æ®µæœº"><a class="header" href="#1-è®¾è®¡ç†å¿µmemtable-ä¸æ˜¯ç¼“å­˜è€Œæ˜¯å†™å…¥é˜¶æ®µæœº">1. è®¾è®¡ç†å¿µï¼šMemTable ä¸æ˜¯ç¼“å­˜ï¼Œè€Œæ˜¯â€œå†™å…¥é˜¶æ®µæœºâ€</a></h2>
<p>å¾ˆå¤šäººç¬¬ä¸€æ¬¡çœ‹ LSM ä¼šæŠŠ MemTable ç†è§£æˆâ€œå†…å­˜ç¼“å­˜å±‚â€ã€‚åœ¨ NoKV é‡Œï¼Œè¿™ä¸ªç†è§£ä¸å¤Ÿå‡†ç¡®ã€‚</p>
<p>æ›´å‡†ç¡®çš„è¯´æ³•æ˜¯ï¼š</p>
<ul>
<li>MemTable æ˜¯ <strong>WAL ä¹‹åã€SST ä¹‹å‰</strong> çš„æœ‰åºå†™å…¥é˜¶æ®µã€‚</li>
<li>å®ƒå¿…é¡»åŒæ—¶æ»¡è¶³â€œé©¬ä¸Šå¯è¯»â€å’Œâ€œå´©æºƒå¯æ¢å¤â€ã€‚</li>
<li>å®ƒçš„ç”Ÿå‘½å‘¨æœŸç”± flush èŠ‚å¥é©±åŠ¨ï¼Œè€Œä¸æ˜¯ç”± GC è‡ªå‘å›æ”¶ã€‚</li>
</ul>
<p>è¿™å†³å®šäº†å®ç°ä¸èƒ½åªè¿½æ±‚å•æ¬¡æ“ä½œå¿«ï¼Œè¿˜è¦è¿½æ±‚çŠ¶æ€è½¬æ¢å¯è¯æ˜ã€‚</p>
<hr>
<h2 id="2-æ ¸å¿ƒç»“æ„ä¸€å¼ å›¾çœ‹æ‡‚ç”Ÿå‘½å‘¨æœŸ"><a class="header" href="#2-æ ¸å¿ƒç»“æ„ä¸€å¼ å›¾çœ‹æ‡‚ç”Ÿå‘½å‘¨æœŸ">2. æ ¸å¿ƒç»“æ„ï¼šä¸€å¼ å›¾çœ‹æ‡‚ç”Ÿå‘½å‘¨æœŸ</a></h2>
<pre class="mermaid">flowchart TD
  W["Write Request"] --&gt; A["active memtable"]
  A --&gt; B{"walSize over threshold?"}
  B --&gt;|No| A
  B --&gt;|Yes| R["rotate: active -&gt; immutable"]
  R --&gt; F["flush immutable to L0 SST"]
  F --&gt; M["manifest: add file + advance log pointer"]
  M --&gt; G["remove eligible wal segments"]
</pre>

<p>è¿™æ¡é“¾è·¯çš„å·¥ç¨‹é‡ç‚¹æ˜¯ï¼š<strong>å…ˆæœ‰å¯æ¢å¤è®°å½•ï¼Œå†æœ‰å†…å­˜å¯è§çŠ¶æ€ï¼Œå†æœ‰æŒä¹…å±‚å®‰è£…ã€‚</strong></p>
<hr>
<h2 id="3-memtable-ä¸-wal-çš„ç»‘å®šå…³ç³»"><a class="header" href="#3-memtable-ä¸-wal-çš„ç»‘å®šå…³ç³»">3. MemTable ä¸ WAL çš„ç»‘å®šå…³ç³»</a></h2>
<p><code>lsm/memtable.go</code> é‡Œçš„ <code>memTable</code> ç»“æ„åŒ…å« <code>segmentID</code> å’Œ <code>walSize</code>ï¼Œè¿™ä¸æ˜¯â€œé¡ºæ‰‹æ”¾è¿›æ¥â€çš„å­—æ®µï¼Œè€Œæ˜¯çŠ¶æ€ä¸€è‡´æ€§çš„é”šç‚¹ã€‚</p>
<ul>
<li><code>segmentID</code>ï¼šæŠŠæŸä¸€ä»£ memtable ä¸ WAL segment ç»‘å®šã€‚</li>
<li><code>walSize</code>ï¼šé©±åŠ¨ rotate çš„ç›´æ¥ä¿¡å·ã€‚</li>
<li><code>maxVersion</code>ï¼šé…åˆå†…éƒ¨ key ç‰ˆæœ¬åºã€‚</li>
</ul>
<p>å†™å…¥æ—¶åºï¼š</p>
<ol>
<li><code>wal.Append</code> æˆåŠŸã€‚</li>
<li><code>index.Add</code> æ›´æ–°å†…å­˜ç´¢å¼•ã€‚</li>
</ol>
<p>è¿™ä¸ªé¡ºåºä¿è¯äº†ï¼šâ€œèƒ½è¯»åˆ°çš„æ•°æ®ï¼Œä¸€å®šèƒ½ä»æ—¥å¿—é‡æ”¾å›æ¥â€ã€‚</p>
<hr>
<h2 id="4-arenaæŠŠåˆ†é…æˆæœ¬ä»æ¯æ¬¡å†™å…¥ç§»åˆ°é˜¶æ®µå›æ”¶"><a class="header" href="#4-arenaæŠŠåˆ†é…æˆæœ¬ä»æ¯æ¬¡å†™å…¥ç§»åˆ°é˜¶æ®µå›æ”¶">4. Arenaï¼šæŠŠåˆ†é…æˆæœ¬ä»â€œæ¯æ¬¡å†™å…¥â€ç§»åˆ°â€œé˜¶æ®µå›æ”¶â€</a></h2>
<h3 id="41-ä¸ºä»€ä¹ˆå¿…é¡»æœ‰-arena"><a class="header" href="#41-ä¸ºä»€ä¹ˆå¿…é¡»æœ‰-arena">4.1 ä¸ºä»€ä¹ˆå¿…é¡»æœ‰ Arena</a></h3>
<p>å¦‚æœ key/value/node éƒ½ç›´æ¥èµ° Go heapï¼Œå†™é«˜å³°ä¼šå¸¦æ¥ä¸¤ä¸ªæ˜æ˜¾é—®é¢˜ï¼š</p>
<ul>
<li>å¤§é‡å°å¯¹è±¡åˆ†é…å¯¼è‡´ GC é¢‘ç¹æ‰«æã€‚</li>
<li>æŒ‡é’ˆå¯¹è±¡ç¦»æ•£ï¼ŒCPU cache å‘½ä¸­ç‡å·®ã€‚</li>
</ul>
<p>Arena çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š</p>
<ul>
<li>ç”¨ offset å–ä»£å¤§å¤šæ•°æŒ‡é’ˆã€‚</li>
<li>ç”¨ bump åˆ†é…æ›¿ä»£é€šç”¨åˆ†é…å™¨è·¯å¾„ã€‚</li>
<li>ç”¨ memtable ç”Ÿå‘½å‘¨æœŸå›æ”¶ï¼Œæ›¿ä»£ç»†ç²’åº¦ freeã€‚</li>
</ul>
<h3 id="42-å¯¹é½æ˜¯æ­£ç¡®æ€§è¦æ±‚ä¸æ˜¯ä¼˜åŒ–é€‰é¡¹"><a class="header" href="#42-å¯¹é½æ˜¯æ­£ç¡®æ€§è¦æ±‚ä¸æ˜¯ä¼˜åŒ–é€‰é¡¹">4.2 å¯¹é½æ˜¯æ­£ç¡®æ€§è¦æ±‚ï¼Œä¸æ˜¯ä¼˜åŒ–é€‰é¡¹</a></h3>
<p>åœ¨ skiplist é‡Œ value å…ƒæ•°æ®æ˜¯ <code>uint64</code> åŸå­è¯»å†™ã€‚Arena çš„å¯¹é½ä¿éšœå†³å®šäº†è¿™é‡Œæ˜¯å¦å­˜åœ¨æœªå®šä¹‰è¡Œä¸ºé£é™©ã€‚</p>
<p>ç®€å•è¯´ï¼šæ²¡æœ‰å¯¹é½ä¿éšœï¼Œè¿™ä¸æ˜¯â€œæ…¢ä¸€ç‚¹â€ï¼Œè€Œæ˜¯â€œå¯èƒ½é”™â€ã€‚</p>
<hr>
<h2 id="5-skiplist-è®¾è®¡å·¥ç¨‹å¯ç»´æŠ¤åŸºçº¿"><a class="header" href="#5-skiplist-è®¾è®¡å·¥ç¨‹å¯ç»´æŠ¤åŸºçº¿">5. Skiplist è®¾è®¡ï¼ˆå·¥ç¨‹å¯ç»´æŠ¤åŸºçº¿ï¼‰</a></h2>
<h3 id="51-æ•°æ®ç»“æ„è¦ç‚¹"><a class="header" href="#51-æ•°æ®ç»“æ„è¦ç‚¹">5.1 æ•°æ®ç»“æ„è¦ç‚¹</a></h3>
<ul>
<li>éšæœºå±‚é«˜ <code>randomHeight</code>ï¼Œä¸Šé™ <code>maxHeight</code>ã€‚</li>
<li>tower æ¯å±‚ç”¨ CAS é“¾æ¥ã€‚</li>
<li>key/value/node å­˜åœ¨ Arenaï¼ŒèŠ‚ç‚¹å†…éƒ¨ç”¨ offsetã€‚</li>
</ul>
<pre class="mermaid">flowchart LR
  E["Entry"] --&gt; K["Arena.putKey"]
  E --&gt; V["Arena.putVal"]
  K --&gt; N["new node(height=h)"]
  V --&gt; N
  N --&gt; L["CAS link level 0..h-1"]
</pre>

<h3 id="52-å†™å…¥æ¨¡å‹add"><a class="header" href="#52-å†™å…¥æ¨¡å‹add">5.2 å†™å…¥æ¨¡å‹ï¼ˆAddï¼‰</a></h3>
<p><code>Add</code> çš„é€»è¾‘ä¸æ˜¯â€œç›´æ¥æ’å…¥â€ï¼Œè€Œæ˜¯â€œå…ˆå®šä½ï¼Œå†æ¡ä»¶æ›´æ–°ï¼Œå†åˆ†å±‚å®‰è£…â€ï¼š</p>
<ol>
<li><code>findSpliceForLevel</code> ä»é«˜åˆ°ä½æ‰¾åˆ°æ¯å±‚ <code>prev/next</code>ã€‚</li>
<li>å¦‚æœå‘ç°åŒ keyï¼Œç›´æ¥åŸå­è¦†ç›– valueã€‚</li>
<li>ä¸åŒ key æ‰åˆ›å»ºæ–°èŠ‚ç‚¹ã€‚</li>
<li>ä» level0 å¼€å§‹ CAS å®‰è£…ï¼Œå¤±è´¥é‡è¯•ã€‚</li>
</ol>
<p>è¿™ç§æµç¨‹çš„ä»·å€¼æ˜¯ï¼šå¹¶å‘å†²çªå±€éƒ¨åŒ–ï¼Œä¸éœ€è¦å…¨å±€å¤§é”ã€‚</p>
<h3 id="53-è¯»ä¸è¿­ä»£"><a class="header" href="#53-è¯»ä¸è¿­ä»£">5.3 è¯»ä¸è¿­ä»£</a></h3>
<p><code>Search</code> é€šè¿‡ <code>findNear</code> æ‰¾ <code>&gt;= key</code> çš„å€™é€‰ï¼Œå†ç”¨ <code>kv.SameKey</code> æ ¡éªŒã€‚è¿­ä»£å™¨æ”¯æŒ <code>Seek/SeekForPrev/Next/Prev</code>ï¼Œå¹¶é€šè¿‡ refcount é¿å…å¹¶å‘ flush æ—¶æå‰é‡Šæ”¾ã€‚</p>
<h3 id="54-ä½•æ—¶ä¼˜å…ˆé€‰-skiplist"><a class="header" href="#54-ä½•æ—¶ä¼˜å…ˆé€‰-skiplist">5.4 ä½•æ—¶ä¼˜å…ˆé€‰ Skiplist</a></h3>
<ul>
<li>ä¼˜å…ˆç¨³å®šæ€§ä¸å¯æ’éšœæ€§ã€‚</li>
<li>å›¢é˜Ÿå¸Œæœ›é™ä½è®¤çŸ¥è´Ÿæ‹…ã€‚</li>
<li>éœ€è¦ä¸€ä¸ªç¨³å¥é»˜è®¤å®ç°åšå›å½’åŸºçº¿ã€‚</li>
</ul>
<hr>
<h2 id="6-art-è®¾è®¡æ€§èƒ½ä¸Šé™è·¯å¾„"><a class="header" href="#6-art-è®¾è®¡æ€§èƒ½ä¸Šé™è·¯å¾„">6. ART è®¾è®¡ï¼ˆæ€§èƒ½ä¸Šé™è·¯å¾„ï¼‰</a></h2>
<h3 id="61-ç»“æ„æ ¸å¿ƒ"><a class="header" href="#61-ç»“æ„æ ¸å¿ƒ">6.1 ç»“æ„æ ¸å¿ƒ</a></h3>
<ul>
<li>Node4/16/48/256 è‡ªé€‚åº”å‡çº§ã€‚</li>
<li>å‰ç¼€å‹ç¼©å‡å°‘é‡å¤è·¯å¾„ã€‚</li>
<li>leaf ä¿å­˜å®Œæ•´ key + valueã€‚</li>
</ul>
<pre class="mermaid">flowchart LR
  N4["Node4"] --&gt; N16["Node16"]
  N16 --&gt; N48["Node48"]
  N48 --&gt; N256["Node256"]
</pre>

<h3 id="62-å¹¶å‘æ¨¡å‹"><a class="header" href="#62-å¹¶å‘æ¨¡å‹">6.2 å¹¶å‘æ¨¡å‹</a></h3>
<p>NoKV ART çš„å…³é”®ä¸æ˜¯â€œæ ‘ç»“æ„æœ¬èº«â€ï¼Œè€Œæ˜¯ COW + CAS å®‰è£…ï¼š</p>
<ul>
<li>è¯»è·¯å¾„è¯»ä¸å¯å˜å¿«ç…§ã€‚</li>
<li>å†™è·¯å¾„å¤åˆ¶ payload å CAS æ›¿æ¢ã€‚</li>
<li>å†²çªæ—¶é‡è¯• <code>tryInsert</code>ã€‚</li>
</ul>
<p>è¿™è®© ART åœ¨é«˜å¹¶å‘è¯»å†™åœºæ™¯ä¸‹é€šå¸¸èƒ½æ‹¿åˆ°æ›´ä½å»¶è¿Ÿã€‚</p>
<h3 id="63-æŸ¥è¯¢ä¸èŒƒå›´æ‰«æ"><a class="header" href="#63-æŸ¥è¯¢ä¸èŒƒå›´æ‰«æ">6.3 æŸ¥è¯¢ä¸èŒƒå›´æ‰«æ</a></h3>
<p><code>lowerBound</code> ç»Ÿä¸€äº† <code>Search</code> ä¸ <code>Seek</code> çš„è¡Œä¸ºè¯­ä¹‰ï¼Œä¹Ÿè®©èŒƒå›´æ‰«æè·¯å¾„æ›´è‡ªç„¶ã€‚</p>
<hr>
<h2 id="7-skiplist-vs-artä¸æ˜¯è°æ›´å…ˆè¿›è€Œæ˜¯è°æ›´åˆèº«"><a class="header" href="#7-skiplist-vs-artä¸æ˜¯è°æ›´å…ˆè¿›è€Œæ˜¯è°æ›´åˆèº«">7. Skiplist vs ARTï¼šä¸æ˜¯â€œè°æ›´å…ˆè¿›â€ï¼Œè€Œæ˜¯â€œè°æ›´åˆèº«â€</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th style="text-align: left">ç»´åº¦</th><th style="text-align: left">Skiplist</th><th style="text-align: left">ART</th></tr>
</thead>
<tbody>
<tr><td style="text-align: left">å¤æ‚åº¦</td><td style="text-align: left">ä¸­ç­‰ï¼Œç»“æ„ç›´è§‚</td><td style="text-align: left">é«˜ï¼Œè·¯å¾„åˆ†å‰å¤š</td></tr>
<tr><td style="text-align: left">å¯ç»´æŠ¤æ€§</td><td style="text-align: left">å¼º</td><td style="text-align: left">ä¸­</td></tr>
<tr><td style="text-align: left">å¸¸è§è¯»å»¶è¿Ÿ</td><td style="text-align: left">ä¸­</td><td style="text-align: left">ä½ï¼ˆå¸¸è§è´Ÿè½½ï¼‰</td></tr>
<tr><td style="text-align: left">èŒƒå›´æ‰«æ</td><td style="text-align: left">å¥½</td><td style="text-align: left">å¾ˆå¥½</td></tr>
<tr><td style="text-align: left">å¹¶å‘å†™å†²çªè¡Œä¸º</td><td style="text-align: left">CAS é‡è¯•ã€ç®€å•</td><td style="text-align: left">COW+CASã€å®ç°å¤æ‚</td></tr>
<tr><td style="text-align: left">è°ƒè¯•æˆæœ¬</td><td style="text-align: left">ä½</td><td style="text-align: left">é«˜</td></tr>
</tbody>
</table>
</div>
<p>å·¥ç¨‹å»ºè®®ï¼š</p>
<ul>
<li>é»˜è®¤ä»¥ Skiplist èµ·æ­¥ï¼Œå…ˆæŠŠç³»ç»Ÿè¡Œä¸ºè·‘ç¨³ã€‚</li>
<li>æ˜ç¡®è¯»çƒ­ç‚¹ä¸èŒƒå›´æ‰«æå æ¯”åï¼Œå†åˆ‡ ART å¹¶åšä¸“é¡¹ benchmarkã€‚</li>
</ul>
<hr>
<h2 id="8-å¸¸è§è¯¯åŒºæ–°äººæœ€å®¹æ˜“è¸©çš„å‘"><a class="header" href="#8-å¸¸è§è¯¯åŒºæ–°äººæœ€å®¹æ˜“è¸©çš„å‘">8. å¸¸è§è¯¯åŒºï¼ˆæ–°äººæœ€å®¹æ˜“è¸©çš„å‘ï¼‰</a></h2>
<ol>
<li>
<p>è¯¯åŒºï¼š<code>MemTableSize</code> ç›´æ¥ç­‰äºå®é™…å†…å­˜å ç”¨ã€‚
äº‹å®ï¼šå½“å‰ rotate æ›´è´´è¿‘ WAL å­—èŠ‚ï¼Œç´¢å¼•çœŸå®å†…å­˜ä¸ WAL å­—èŠ‚ä¸ä¸¥æ ¼çº¿æ€§ã€‚</p>
</li>
<li>
<p>è¯¯åŒºï¼šç”¨äº† Arena å°±æ²¡æœ‰å†…å­˜å‹åŠ›ã€‚
äº‹å®ï¼šArena åªæ˜¯æŠŠé‡Šæ”¾ç²’åº¦å˜ç²—ï¼Œå‹åŠ›ä»â€œå°å¯¹è±¡ GCâ€å˜æˆâ€œé˜¶æ®µå³°å€¼â€ã€‚</p>
</li>
<li>
<p>è¯¯åŒºï¼šART ä¸€å®šå…¨é¢ä¼˜äº Skiplistã€‚
äº‹å®ï¼šART çš„æ”¶ç›Šä¾èµ–è´Ÿè½½å½¢æ€ä¸å®ç°ç»†èŠ‚ï¼Œä¸æ˜¯æ— æ¡ä»¶æˆç«‹ã€‚</p>
</li>
</ol>
<hr>
<h2 id="9-å·¥ç¨‹åŒ–æ£€æŸ¥æ¸…å•ä¸Šçº¿å‰"><a class="header" href="#9-å·¥ç¨‹åŒ–æ£€æŸ¥æ¸…å•ä¸Šçº¿å‰">9. å·¥ç¨‹åŒ–æ£€æŸ¥æ¸…å•ï¼ˆä¸Šçº¿å‰ï¼‰</a></h2>
<ol>
<li>è§‚å¯Ÿ flush backlog æ˜¯å¦é•¿æœŸä¸Šå‡ã€‚</li>
<li>è§‚å¯Ÿ rotate é¢‘ç‡æ˜¯å¦å¼‚å¸¸ï¼ˆè¿‡å¿«/è¿‡æ…¢ï¼‰ã€‚</li>
<li>å¯¹æ¯” <code>mem_table_engine=skiplist/art</code> çš„ P99 è¯»å†™å»¶è¿Ÿã€‚</li>
<li>æ£€æŸ¥é‡å¯æ¢å¤æ—¶é—´æ˜¯å¦éšå‚æ•°å˜åŒ–å¼‚å¸¸æ”¾å¤§ã€‚</li>
</ol>
<hr>
<h2 id="10-æ€»ç»“"><a class="header" href="#10-æ€»ç»“">10. æ€»ç»“</a></h2>
<p>MemTable è¿™ä¸€å±‚çœŸæ­£çš„ä»·å€¼ï¼Œä¸åªæ˜¯â€œæŠŠå†™å…ˆæ”¾å†…å­˜â€ï¼Œè€Œæ˜¯æŠŠâ€œå†™å…¥ååã€å´©æºƒæ¢å¤ã€åå°æ•´ç†â€ä¸‰ä»¶äº‹æ”¶æ•›åˆ°ä¸€ä¸ªå¯è¯æ˜çš„çŠ¶æ€æœºé‡Œã€‚</p>
<p>åœ¨è¿™ä¸ªçŠ¶æ€æœºä¸­ï¼š</p>
<ul>
<li>Arena å†³å®šä¸Šé™æ€§èƒ½æ˜¯å¦ç¨³å®šã€‚</li>
<li>Skiplist å†³å®šåŸºçº¿æ˜¯å¦ç¨³å¥å¯æ§ã€‚</li>
<li>ART å†³å®šæ˜¯å¦èƒ½è¿›ä¸€æ­¥é€¼è¿‘å»¶è¿Ÿå’Œååä¸Šé™ã€‚</li>
</ul>
<p>NoKV çš„è¿™å¥—å®ç°æ˜¯å¾ˆå…¸å‹çš„å·¥ç¨‹ç­”æ¡ˆï¼šå…ˆä¿è¯­ä¹‰ï¼Œå†åšæ€§èƒ½ï¼Œå†ç•™æ’æ‹”ç©ºé—´ã€‚</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="2026-02-09-rhythm-of-writes-commit-worker-batch-ringbuffer"><a class="header" href="#2026-02-09-rhythm-of-writes-commit-worker-batch-ringbuffer">2026-02-09-rhythm-of-writes-commit-worker-batch-ringbuffer</a></h1>
<p>æœ¬æ–‡æ¡£é¢å‘ç¬¬ä¸€æ¬¡ç†è§£ NoKV å†™è·¯å¾„çš„åŒå­¦ï¼Œä¹Ÿè®°å½•è¿™å—å®ç°é‡Œçš„å·¥ç¨‹åŒ–è®¾è®¡æ–¹æ³•ã€‚æˆ‘ä»¬è®¨è®ºä¸‰ä»¶äº‹ï¼š</p>
<ol>
<li><code>commit worker</code> ä¸ºä»€ä¹ˆæ˜¯å†™è·¯å¾„ä¸­æ¢ã€‚</li>
<li><code>write batch</code> å¦‚ä½•åœ¨å»¶è¿Ÿä¸ååä¹‹é—´åšåŠ¨æ€å¹³è¡¡ã€‚</li>
<li><code>ringbuffer</code> å¦‚ä½•æä¾›ä½å¼€é”€å¹¶å‘é˜Ÿåˆ—åŸºç¡€ã€‚</li>
</ol>
<hr>
<h2 id="1-è®¾è®¡ç†å¿µå†™è·¯å¾„è¦åƒèŠ‚æ‹å™¨ä¸æ˜¯ç¢°ç¢°è¿æ°”"><a class="header" href="#1-è®¾è®¡ç†å¿µå†™è·¯å¾„è¦åƒèŠ‚æ‹å™¨ä¸æ˜¯ç¢°ç¢°è¿æ°”">1. è®¾è®¡ç†å¿µï¼šå†™è·¯å¾„è¦åƒâ€œèŠ‚æ‹å™¨â€ï¼Œä¸æ˜¯â€œç¢°ç¢°è¿æ°”â€</a></h2>
<p>å†™è·¯å¾„å¦‚æœæ²¡æœ‰èŠ‚æ‹æ§åˆ¶ï¼Œä¼šå‡ºç°ä¸‰ç§å…¸å‹é—®é¢˜ï¼š</p>
<ul>
<li>çªå‘æµé‡æŠŠé˜Ÿåˆ—é¡¶çˆ†ï¼Œå†…å­˜é£™å‡ã€‚</li>
<li>å•è¯·æ±‚æäº¤æŠ–åŠ¨å¤§ï¼Œå°¾å»¶è¿Ÿå¤±æ§ã€‚</li>
<li>é”™è¯¯å½’å› ç²—ç³™ï¼Œå®¢æˆ·ç«¯é‡å¤é‡è¯•æ”¾å¤§å‹åŠ›ã€‚</li>
</ul>
<p>NoKV çš„æ–¹æ¡ˆæ˜¯æŠŠå†™è·¯å¾„æ‹†æˆâ€œå‰å°å…¥é˜Ÿ + åå°æ‰¹å¤„ç† + æ˜ç¡®å®Œæˆè¯­ä¹‰â€ï¼Œè®©ç³»ç»Ÿè¡Œä¸ºæ›´åƒç¨³å®šèŠ‚æ‹è€Œä¸æ˜¯éšæœºæ³¢åŠ¨ã€‚</p>
<hr>
<h2 id="2-æ€»è§ˆå›¾ä»è¯·æ±‚åˆ°è½ç›˜"><a class="header" href="#2-æ€»è§ˆå›¾ä»è¯·æ±‚åˆ°è½ç›˜">2. æ€»è§ˆå›¾ï¼šä»è¯·æ±‚åˆ°è½ç›˜</a></h2>
<pre class="mermaid">sequenceDiagram
  participant C as Client
  participant Q as commitQueue
  participant W as commitWorker
  participant V as ValueLog
  participant L as LSM
  participant S as WAL Sync

  C-&gt;&gt;Q: enqueue request
  Q-&gt;&gt;W: item signal
  W-&gt;&gt;Q: pop a batch
  W-&gt;&gt;V: vlog.write
  W-&gt;&gt;L: applyRequests / SetBatch
  opt SyncWrites=true
    W-&gt;&gt;S: wal.Sync
  end
  W--&gt;&gt;C: per-request result
</pre>

<p>å…³é”®æ˜¯é¡ºåºï¼šå…ˆ <code>vlog.write</code>ï¼Œå† <code>LSM apply</code>ï¼Œæœ€åæŒ‰éœ€ <code>wal.Sync</code>ã€‚è¿™ä¿è¯ ValuePtr ä¸ä¼šæŒ‡å‘ä¸å­˜åœ¨çš„æ•°æ®ã€‚</p>
<hr>
<h2 id="3-commitqueueä¸‰å±‚ç»„åˆè€Œä¸æ˜¯åªæœ‰ä¸€ä¸ª-ring"><a class="header" href="#3-commitqueueä¸‰å±‚ç»„åˆè€Œä¸æ˜¯åªæœ‰ä¸€ä¸ª-ring">3. commitQueueï¼šä¸‰å±‚ç»„åˆè€Œä¸æ˜¯â€œåªæœ‰ä¸€ä¸ª ringâ€</a></h2>
<p><code>commitQueue</code> çš„è®¾è®¡ä¸æ˜¯å•ä¸€ç»“æ„ï¼Œè€Œæ˜¯ä¸‰ä»¶å¥—ï¼š</p>
<ol>
<li><code>Ring[*commitRequest]</code> è´Ÿè´£æ•°æ®é¢é«˜æ•ˆ push/popã€‚</li>
<li><code>spaces</code> é€šé“è´Ÿè´£å®¹é‡ç¥¨æ®ï¼Œå½¢æˆç¡¬ä¸Šé™èƒŒå‹ã€‚</li>
<li><code>items</code> é€šé“è´Ÿè´£å¯æ¶ˆè´¹äº‹ä»¶ï¼Œé¿å… worker å¿™ç­‰ã€‚</li>
</ol>
<pre class="mermaid">flowchart LR
  P["Producer"] --&gt; T["acquire spaces token"]
  T --&gt; R["ring.Push(req)"]
  R --&gt; I["items signal"]
  I --&gt; W["worker wakeup"]
  W --&gt; O["ring.Pop"]
  O --&gt; RT["release spaces token"]
</pre>

<p>è¿™ä¸‰å±‚å åŠ åï¼Œç³»ç»ŸåŒæ—¶å¾—åˆ°ï¼šå¹¶å‘æ•ˆç‡ã€å†…å­˜ä¸Šé™ã€å¯æ§é˜»å¡è¯­ä¹‰ã€‚</p>
<hr>
<h2 id="4-write-batchåŠ¨æ€ç­–ç•¥è€Œéå›ºå®šæ‰¹æ¬¡"><a class="header" href="#4-write-batchåŠ¨æ€ç­–ç•¥è€Œéå›ºå®šæ‰¹æ¬¡">4. write batchï¼šåŠ¨æ€ç­–ç•¥è€Œéå›ºå®šæ‰¹æ¬¡</a></h2>
<p><code>nextCommitBatch</code> çš„æ ¸å¿ƒæ˜¯â€œçœ‹ç°åœºè°ƒèŠ‚â€ï¼Œä¸æ˜¯æ­»é…é˜ˆå€¼ï¼š</p>
<ul>
<li>backlog é«˜ï¼šæ”¾å¤§ <code>limitCount</code>ã€<code>limitSize</code>ã€‚</li>
<li>æ£€æµ‹åˆ° hot writeï¼šåº”ç”¨ <code>HotWriteBatchMultiplier</code>ã€‚</li>
<li>é˜Ÿåˆ—çŸ­æš‚å‘ç©ºä½†æ‰¹æœªæ»¡ï¼šç­‰å¾… <code>WriteBatchWait</code> åš coalesceã€‚</li>
</ul>
<pre class="mermaid">flowchart TD
  A["start batch"] --&gt; B{"backlog high?"}
  B --&gt;|Yes| C["increase batch limits"]
  B --&gt;|No| D["use base limits"]
  C --&gt; E{"hot write?"}
  D --&gt; E
  E --&gt;|Yes| F["apply hot multiplier"]
  E --&gt;|No| G["keep current limits"]
  F --&gt; H["collect until limit or timeout"]
  G --&gt; H
</pre>

<p>è¿™å¥—ç­–ç•¥æŠŠè½»è½½ä½å»¶è¿Ÿä¸é‡è½½é«˜ååæ”¾åœ¨ä¸€ä¸ªæ¡†æ¶é‡Œã€‚</p>
<hr>
<h2 id="5-æœ€è¿‘å…³é”®ä¿®å¤é”™è¯¯å½’å› ä»æ•´æ‰¹åŒé”™å˜æˆé€è¯·æ±‚å‡†ç¡®"><a class="header" href="#5-æœ€è¿‘å…³é”®ä¿®å¤é”™è¯¯å½’å› ä»æ•´æ‰¹åŒé”™å˜æˆé€è¯·æ±‚å‡†ç¡®">5. æœ€è¿‘å…³é”®ä¿®å¤ï¼šé”™è¯¯å½’å› ä»â€œæ•´æ‰¹åŒé”™â€å˜æˆâ€œé€è¯·æ±‚å‡†ç¡®â€</a></h2>
<p>å†å²é£é™©ï¼š<code>applyRequests</code> ä¸­é€”å¤±è´¥æ—¶ï¼Œæ•´æ‰¹è¯·æ±‚è¢«åŒä¸€ä¸ªé”™è¯¯è¦†ç›–ï¼Œå¯¼è‡´å·²ç»æˆåŠŸçš„è¯·æ±‚è¢«è¯¯åˆ¤å¤±è´¥ã€‚</p>
<p>ä¿®å¤åçš„è¯­ä¹‰ï¼š</p>
<ol>
<li><code>applyRequests</code> è¿”å›å¤±è´¥ä½ç½® <code>failedAt</code>ã€‚</li>
<li><code>commitWorker</code> åªæ ‡è®° <code>failedAt</code> åŠä¹‹åè¯·æ±‚å¤±è´¥ã€‚</li>
<li><code>finishCommitRequests</code> æ”¯æŒé€è¯·æ±‚å›å¡«é”™è¯¯ã€‚</li>
</ol>
<pre class="mermaid">flowchart LR
  A["r0 ok"] --&gt; B["r1 ok"] --&gt; C["r2 fail"] --&gt; D["r3 not applied"]
</pre>

<p>è¿™ä¸ªæ”¹åŠ¨çš„ä»·å€¼ä¸åœ¨â€œå¿«â€ï¼Œè€Œåœ¨â€œè¯­ä¹‰æ­£ç¡®â€ã€‚</p>
<hr>
<h2 id="6-ringbuffermpmc-åºå·åè®®ä¸å†…å­˜ä¿æ´»æ§åˆ¶"><a class="header" href="#6-ringbuffermpmc-åºå·åè®®ä¸å†…å­˜ä¿æ´»æ§åˆ¶">6. RingBufferï¼šMPMC åºå·åè®®ä¸å†…å­˜ä¿æ´»æ§åˆ¶</a></h2>
<p><code>utils/ringbuffer.go</code> é‡‡ç”¨ seq åè®®ï¼š</p>
<ul>
<li><code>Push</code> è§‚å¯Ÿ <code>slot.seq == pos</code> æ‰èƒ½å†™ã€‚</li>
<li><code>Pop</code> è§‚å¯Ÿ <code>slot.seq == pos+1</code> æ‰èƒ½è¯»ã€‚</li>
<li><code>Pop</code> åæ¨è¿› <code>seq</code> åˆ°ä¸‹ä¸€è½®å¹¶æ¸…ç©º <code>slot.val</code>ã€‚</li>
</ul>
<pre class="mermaid">flowchart LR
  F["free(seq=pos)"] --&gt; P["push CAS tail"]
  P --&gt; R["ready(seq=pos+1)"]
  R --&gt; C["pop CAS head"]
  C --&gt; N["next free(seq=pos+cap)"]
</pre>

<p>æ¸…ç©º <code>slot.val</code> æ˜¯å…³é”®å·¥ç¨‹ç‚¹ï¼šå®ƒå‡å°‘å¯¹è±¡è¢« ring æ§½ä½é•¿æœŸå¼•ç”¨è€Œå»¶è¿Ÿå›æ”¶ã€‚</p>
<hr>
<h2 id="7-ä¸-hot-ç»Ÿè®¡çš„è€¦åˆç‚¹å†™è·¯å¾„è¦é¿å…ç»Ÿè®¡åç½®"><a class="header" href="#7-ä¸-hot-ç»Ÿè®¡çš„è€¦åˆç‚¹å†™è·¯å¾„è¦é¿å…ç»Ÿè®¡åç½®">7. ä¸ Hot ç»Ÿè®¡çš„è€¦åˆç‚¹ï¼šå†™è·¯å¾„è¦é¿å…ç»Ÿè®¡åç½®</a></h2>
<p>è¿™å—æœ€å®¹æ˜“è¢«å¿½ç•¥çš„é£é™©æ˜¯â€œç»Ÿè®¡å£å¾„ä¸ä¸€è‡´â€ä¸â€œåŒé‡è®¡æ•°â€ã€‚</p>
<p>å½“å‰æ–¹å‘ï¼ˆä½ å‰é¢å®šä¸‹çš„ç­–ç•¥ï¼‰æ˜¯å¯¹çš„ï¼š</p>
<ul>
<li>è¯»å†™ ring åˆ†ç¦»ï¼Œé¿å…é«˜è¯»çƒ­ç‚¹è¯¯è§¦å‘å†™é™æµã€‚</li>
<li><code>isHotWrite</code> ä»…åš <code>Frequency</code> åˆ¤æ–­ï¼Œä¸å†äºŒæ¬¡ <code>Touch</code>ã€‚</li>
</ul>
<p>è¿™ä¼šæ˜¾è‘—é™ä½è¯¯åˆ¤å’Œè¿‡åº¦é™æµã€‚</p>
<hr>
<h2 id="8-å‚æ•°å»ºè®®æ–°äººå¯ç›´æ¥èµ·æ­¥"><a class="header" href="#8-å‚æ•°å»ºè®®æ–°äººå¯ç›´æ¥èµ·æ­¥">8. å‚æ•°å»ºè®®ï¼ˆæ–°äººå¯ç›´æ¥èµ·æ­¥ï¼‰</a></h2>
<ol>
<li><code>WriteBatchMaxCount</code>: 64~128ã€‚</li>
<li><code>WriteBatchMaxSize</code>: 1~4MiBã€‚</li>
<li><code>WriteBatchWait</code>: 100~300usï¼Œä½å»¶è¿Ÿå¯è®¾ 0ã€‚</li>
<li><code>HotWriteBatchMultiplier</code>: 2 èµ·æ­¥ï¼Œé€šå¸¸ä¸å»ºè®®è¶…è¿‡ 4ã€‚</li>
<li><code>SyncWrites=true</code> æ—¶é‡ç‚¹è§‚å¯Ÿ <code>AvgApplyMs</code> ä¸ <code>AvgRequestWaitMs</code>ã€‚</li>
</ol>
<hr>
<h2 id="9-å¸¸è§è¯¯åŒº"><a class="header" href="#9-å¸¸è§è¯¯åŒº">9. å¸¸è§è¯¯åŒº</a></h2>
<ol>
<li>
<p>è¯¯åŒºï¼šbatch è¶Šå¤§è¶Šå¥½ã€‚
äº‹å®ï¼šååä¼šä¸Šå»ï¼Œä½† P99 å¯èƒ½æ›´å·®ã€‚</p>
</li>
<li>
<p>è¯¯åŒºï¼šring æ˜¯æ— é”å°±ç­‰äºæ²¡æœ‰é˜»å¡ã€‚
äº‹å®ï¼šä¸Šå±‚ <code>spaces/items</code> è¯­ä¹‰å†³å®šäº†é˜»å¡ä¸èƒŒå‹è¡Œä¸ºã€‚</p>
</li>
<li>
<p>è¯¯åŒºï¼šå†™è·¯å¾„ä¼˜åŒ–åªçœ‹ QPSã€‚
äº‹å®ï¼šé”™è¯¯å½’å› ã€æ¢å¤ä¸€è‡´æ€§ã€å°¾å»¶è¿ŸåŒæ ·æ˜¯ä¸€ç­‰æŒ‡æ ‡ã€‚</p>
</li>
</ol>
<hr>
<h2 id="10-å·¥ç¨‹åŒ–æ£€æŸ¥æ¸…å•"><a class="header" href="#10-å·¥ç¨‹åŒ–æ£€æŸ¥æ¸…å•">10. å·¥ç¨‹åŒ–æ£€æŸ¥æ¸…å•</a></h2>
<ol>
<li>è§‚å¯Ÿé˜Ÿåˆ—é•¿åº¦æ˜¯å¦é•¿æœŸè´´è¿‘ä¸Šé™ã€‚</li>
<li>è§‚å¯Ÿ batch size åˆ†å¸ƒæ˜¯å¦æç«¯ä¸¤æåŒ–ã€‚</li>
<li>è§‚å¯Ÿå¤±è´¥è¯·æ±‚æ˜¯å¦éƒ½å…·å¤‡å‡†ç¡®é”™è¯¯æ¥æºã€‚</li>
<li>åšä¸€æ¬¡é«˜å¹¶å‘å‹æµ‹ç¡®è®¤ prefetch ä¸å†™è·¯å¾„ä¸ä¼šç©ºè½¬æŠ¢ CPUã€‚</li>
</ol>
<hr>
<h2 id="11-æ€»ç»“"><a class="header" href="#11-æ€»ç»“">11. æ€»ç»“</a></h2>
<p>NoKV è¿™æ¡å†™è·¯å¾„çš„æ ¸å¿ƒä¸æ˜¯æŸä¸ªâ€œå•ç‚¹ç®—æ³•â€ï¼Œè€Œæ˜¯ä¸‰éƒ¨åˆ†ååŒï¼š</p>
<ul>
<li><code>commit worker</code> ç®¡èŠ‚å¥ã€‚</li>
<li><code>write batch</code> ç®¡æ•ˆç‡æ›²çº¿ã€‚</li>
<li><code>ringbuffer</code> ç®¡å¹¶å‘æˆæœ¬ã€‚</li>
</ul>
<p>æŠŠè¿™ä¸‰ä»¶äº‹æ”¾åœ¨ä¸€èµ·ï¼Œå†™è·¯å¾„æ‰èƒ½åŒæ—¶åšåˆ°ï¼šæœ‰ä¸Šé™ã€æœ‰ååã€å¯è§£é‡Šã€‚</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <template id=fa-eye><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144s64.5-144 144-144s144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64c-11.5 0-22.3-3-31.6-8.4c-.2 2.8-.4 5.5-.4 8.4c0 53 43 96 96 96s96-43 96-96s-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6z"/></svg></span></template>
        <template id=fa-eye-slash><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M38.8 5.1C28.4-3.1 13.3-1.2 5.1 9.2S-1.2 34.7 9.2 42.9l592 464c10.4 8.2 25.5 6.3 33.7-4.1s6.3-25.5-4.1-33.7L525.6 386.7c39.6-40.6 66.4-86.1 79.9-118.4c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C465.5 68.8 400.8 32 320 32c-68.2 0-125 26.3-169.3 60.8L38.8 5.1zM223.1 149.5C248.6 126.2 282.7 112 320 112c79.5 0 144 64.5 144 144c0 24.9-6.3 48.3-17.4 68.7L408 294.5c5.2-11.8 8-24.8 8-38.5c0-53-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6c0 10.2-2.4 19.8-6.6 28.3l-90.3-70.8zm223.1 298L373 389.9c-16.4 6.5-34.3 10.1-53 10.1c-79.5 0-144-64.5-144-144c0-6.9 .5-13.6 1.4-20.2L83.1 161.5C60.3 191.2 44 220.8 34.5 243.7c-3.3 7.9-3.3 16.7 0 24.6c14.9 35.7 46.2 87.7 93 131.1C174.5 443.2 239.2 480 320 480c47.8 0 89.9-12.9 126.2-32.5z"/></svg></span></template>
        <template id=fa-copy><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M502.6 70.63l-61.25-61.25C435.4 3.371 427.2 0 418.7 0H255.1c-35.35 0-64 28.66-64 64l.0195 256C192 355.4 220.7 384 256 384h192c35.2 0 64-28.8 64-64V93.25C512 84.77 508.6 76.63 502.6 70.63zM464 320c0 8.836-7.164 16-16 16H255.1c-8.838 0-16-7.164-16-16L239.1 64.13c0-8.836 7.164-16 16-16h128L384 96c0 17.67 14.33 32 32 32h47.1V320zM272 448c0 8.836-7.164 16-16 16H63.1c-8.838 0-16-7.164-16-16L47.98 192.1c0-8.836 7.164-16 16-16H160V128H63.99c-35.35 0-64 28.65-64 64l.0098 256C.002 483.3 28.66 512 64 512h192c35.2 0 64-28.8 64-64v-32h-47.1L272 448z"/></svg></span></template>
        <template id=fa-play><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M73 39c-14.8-9.1-33.4-9.4-48.5-.9S0 62.6 0 80V432c0 17.4 9.4 33.4 24.5 41.9s33.7 8.1 48.5-.9L361 297c14.3-8.7 23-24.2 23-41s-8.7-32.2-23-41L73 39z"/></svg></span></template>
        <template id=fa-clock-rotate-left><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M75 75L41 41C25.9 25.9 0 36.6 0 57.9V168c0 13.3 10.7 24 24 24H134.1c21.4 0 32.1-25.9 17-41l-30.8-30.8C155 85.5 203 64 256 64c106 0 192 86 192 192s-86 192-192 192c-40.8 0-78.6-12.7-109.7-34.4c-14.5-10.1-34.4-6.6-44.6 7.9s-6.6 34.4 7.9 44.6C151.2 495 201.7 512 256 512c141.4 0 256-114.6 256-256S397.4 0 256 0C185.3 0 121.3 28.7 75 75zm181 53c-13.3 0-24 10.7-24 24V256c0 6.4 2.5 12.5 7 17l72 72c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-65-65V152c0-13.3-10.7-24-24-24z"/></svg></span></template>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr-ef4e11c1.min.js"></script>
        <script src="mark-09e88c2c.min.js"></script>
        <script src="searcher-c2a407aa.js"></script>

        <script src="clipboard-1626706a.min.js"></script>
        <script src="highlight-abc7f01d.js"></script>
        <script src="book-a0b12cfe.js"></script>

        <!-- Custom JS scripts -->
        <script src="docs/mermaid-init-8a66ee6c.js"></script>

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
